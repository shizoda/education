{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO291YPQr8g/MTKB5ITyotg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/agent/LangChain(2)_PromptTemplate_LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📘 第2回：プロンプトの構造化と LCEL パイプライン\n",
        "\n",
        "第1回では、LLM へのリクエストが最終的に「JSON形式のテキスト」になることを確認しました。\n",
        "しかし、複雑なアプリケーションを作る際、毎回 JSON や辞書のリストを手動で組み立てるのは効率が悪く、保守性も低いです。\n",
        "\n",
        "第2回では、以下の技術を学び、LLM アプリケーションの「標準的な構築パターン」を習得します。\n",
        "\n",
        "1.  **Prompt Template:** プロンプトを「単なる文字列」ではなく、変数を持つ「構造化されたオブジェクト」として定義する。\n",
        "2.  **LCEL (LangChain Expression Language):** UNIXのパイプ (`|`) のように処理を連結する構文。\n",
        "3.  **Output Parser:** LLM の出力オブジェクトから、必要なデータ（文字列など）を自動で抽出する。\n",
        "\n",
        "### 🎯 今回の学習目標\n",
        "* Python 標準の f-string と LangChain の Template の違いをコードレベルで理解する。\n",
        "* `|` 演算子を使って、コンポーネント（Prompt, Model, Parser）を接続する。\n",
        "* **Runnable Protocol**（データフローの統一規格）を理解する。"
      ],
      "metadata": {
        "id": "xLol5418QGMQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGZZRE3aP24U"
      },
      "outputs": [],
      "source": [
        "# 📦 ライブラリの準備\n",
        "!pip install -qU langchain-openai langchain-core termcolor\n",
        "\n",
        "# 🔑 API キーの準備（Colab シークレットから読み込み）\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "try:\n",
        "    if \"OPENROUTER_API_KEY\" not in os.environ:\n",
        "        os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "    print(\"✅ API Key loaded.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Error: Please set OPENROUTER_API_KEY in secrets.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ プロンプト構築：Python 標準 vs LangChain\n",
        "\n",
        "まずは、動的にプロンプトを作る場面を考えます。\n",
        "例えば、「役割（Role）」と「話題（Topic）」を変数として受け取り、メッセージリストを作る関数です。\n",
        "\n",
        "#### 【A】🐍 Python 標準機能 (f-string) での直書き\n",
        "\n",
        "LangChain の `PromptTemplate` を理解するために、まずは Python 標準の f-string を使って同様の処理を記述します。\n",
        "ここでは関数化を行わず、**「辞書を要素に持つリスト」** から **「プロンプト（文字列）のリスト」** を生成する過程を可視化します。\n",
        "\n",
        "以下のコードを実行し、データの流れを確認してください。"
      ],
      "metadata": {
        "id": "1TQusNs7QU1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from termcolor import cprint\n",
        "\n",
        "# 1. テンプレート（ひな形）の定義\n",
        "template = \"私の名前は{name}です。職業は{occupation}です。\"\n",
        "\n",
        "# 2. データの準備（辞書のリスト）\n",
        "data_list = [\n",
        "    {\"name\": \"田中\", \"occupation\": \"エンジニア\"},\n",
        "    {\"name\": \"佐藤\", \"occupation\": \"データサイエンティスト\"},\n",
        "    {\"name\": \"鈴木\", \"occupation\": \"プロジェクトマネージャー\"},\n",
        "]\n",
        "\n",
        "# 3. f-string による置換処理（直書き）\n",
        "print(\"--- プロンプト ---\")\n",
        "generated_prompts = []\n",
        "\n",
        "for item in data_list:\n",
        "    # 辞書のキーを指定して f-string に埋め込む\n",
        "    # **item でアンパックする方法もありますが、ここでは明示的にキーを指定しています\n",
        "    prompt = f\"私の名前は{item['name']}です。職業は{item['occupation']}です。\"\n",
        "\n",
        "    generated_prompts.append(prompt)\n",
        "\n",
        "    # 確認用出力\n",
        "    cprint(f\"Input: {item} => Output: {prompt}\", \"cyan\")\n",
        "\n",
        "print(\"\\n--- 結果のリスト ---\")\n",
        "print(generated_prompts)"
      ],
      "metadata": {
        "id": "rVi30WdLQZ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🦜 【B】 LangChain の PromptTemplate での実装\n",
        "\n",
        "Python 標準機能では、`for` ループや `format` 関数を自分で記述する必要がありました。\n",
        "LangChain を使用すると、これらの処理をより構造化し、簡潔に記述できます。\n",
        "\n",
        "特に大量のデータを処理する場合、LangChain の **`batch`** 機能を使うことで、ループ処理を書かずに「辞書のリスト」を一括で「プロンプトのリスト」に変換できる点が大きなメリットです。\n",
        "\n",
        "#### 1. ChatPromptTemplate の基本\n",
        "ここでは `ChatPromptTemplate` を使用します。これは、単なる文字列置換だけでなく、LLM に渡すための「メッセージ構造（System, Human など）」を管理するクラスです。"
      ],
      "metadata": {
        "id": "1ZAuOWovQiRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# 1. テンプレートの定義\n",
        "# from_template で文字列から簡易に作成できます\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"私の名前は {name} です。職業は {occupation} です。\"\n",
        ")\n",
        "\n",
        "# 中身を確認\n",
        "print(f\"Input Variables: {prompt_template.input_variables}\")"
      ],
      "metadata": {
        "id": "iII9t0pRQhwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. batch による一括処理\n",
        "先ほど Python で `for` 文を使って書いた処理は、LangChain では **`.batch()`** メソッド 1 つで完結します。\n",
        "\n",
        "* **Python 手動実装**: リストをループ → 1つずつ置換 → リストに追加\n",
        "* **LangChain**: `prompt_template.batch(辞書リスト)`\n",
        "\n",
        "データ（辞書のリスト）をそのまま渡すだけで、並列処理を考慮した効率的な変換が行われます。"
      ],
      "metadata": {
        "id": "IlDeKFZbUpaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. データの準備（先ほどと同じ辞書のリスト）\n",
        "data_list = [\n",
        "    {\"name\": \"田中\", \"occupation\": \"エンジニア\"},\n",
        "    {\"name\": \"佐藤\", \"occupation\": \"データサイエンティスト\"},\n",
        "    {\"name\": \"鈴木\", \"occupation\": \"プロジェクトマネージャー\"},\n",
        "]\n",
        "\n",
        "# 3. 一括変換 (batch実行)\n",
        "# for文は不要です。リストをそのまま渡します。\n",
        "generated_messages = prompt_template.batch(data_list)\n",
        "\n",
        "# 結果の確認\n",
        "print(\"--- .batch() の結果 ---\")\n",
        "for i, msg in enumerate(generated_messages):\n",
        "    # ChatPromptTemplate の出力は \"ChatPromptValue\" という特殊な型ですが\n",
        "    # ここでは可読性のため文字列化して表示します\n",
        "    content = msg.to_string()\n",
        "    cprint(f\"[{i}] {content}\", \"cyan\")"
      ],
      "metadata": {
        "id": "bh44VtMRUrfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 解説: 何が便利になったのか？\n",
        "\n",
        "比較すると以下の点が効率化されています。\n",
        "\n",
        "1.  **ループ処理の隠蔽**: `for` 文を書く必要がなく、コードの記述量が減り、可読性が向上しました。\n",
        "2.  **構造化データの扱い**: 単なる文字列置換ではなく、チャットモデル（ChatGPT 等）が理解しやすいメッセージオブジェクト（`HumanMessage` 等）として自動的に生成されています。\n",
        "\n",
        "次節では、このプロンプトを使って実際に LLM を呼び出してみましょう。"
      ],
      "metadata": {
        "id": "DpkZHSEUUygT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ LCEL: パイプラインによる処理の連結\n",
        "\n",
        "ここからが LangChain の核心部分です。\n",
        "LangChain では、`Prompt` や `Model` などのコンポーネントを **`|` (パイプ) 演算子** で繋ぐことができます。\n",
        "これを **LCEL (LangChain Expression Language)** と呼びます。\n",
        "\n",
        "数式のように書くことができます：\n",
        "$$Chain = Prompt \\mid Model$$\n",
        "\n",
        "この書き方をすると、**「Prompt の出力」が自動的に「Model の入力」として渡されます。**"
      ],
      "metadata": {
        "id": "_Wi-a9srSE2V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "\n",
        "# 1. モデルの準備\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek/deepseek-chat-v3-0324\",\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "# 2. プロンプトテンプレートの準備\n",
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"あなたはプロのライターです。ユーザーの情報を元に、SNS用の魅力的なプロフィール文を考案してください。\"),\n",
        "    (\"human\", \"私の名前は {name} です。職業は {occupation} です。絵文字を使って親しみやすく書いてください。\"),\n",
        "])\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 【課題】 チェーンの実行\n",
        "# ------------------------------------------------------------------\n",
        "# 作成した `chain` に対して .invoke() を実行してください。\n",
        "# 引数には、前のステップと同様の辞書（例: {\"name\": \"...\", \"occupation\": \"...\"}）を1つ渡します。\n",
        "\n",
        "# ↓ ここにコードを記述し、実行結果(content)を表示してください\n",
        "\n",
        "# 3. チェーンの構築\n",
        "chain = ■■■\n",
        "\n",
        "# 実行に必要なデータを辞書で用意\n",
        "input_data = {\"name\": \"田中\", \"occupation\": \"エンジニア\"}\n",
        "\n",
        "print(f\"Running chain with: {input_data} ...\\n\")\n",
        "\n",
        "# チェーンの実行\n",
        "response = chain.invoke(input_data)\n",
        "\n",
        "# 結果の表示\n",
        "print(\"--- AIの生成結果 ---\")\n",
        "print(response.■■■)"
      ],
      "metadata": {
        "id": "IyWINtcqSIRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3️⃣ OutputParser: 出力の加工\n",
        "\n",
        "`chain.invoke` の結果は `AIMessage` オブジェクトでした。しかし、多くのアプリケーションでは、メタデータを含まない「純粋なテキスト（文字列）」だけが必要です。\n",
        "\n",
        "そこで、チェーンの最後に **`StrOutputParser`** を接続します。\n",
        "\n",
        "$$Chain = Prompt \\mid Model \\mid Parser$$\n",
        "\n",
        "これにより、入力から最終的な文字列出力までを一本のパイプラインとして定義できます。"
      ],
      "metadata": {
        "id": "QsvQvM1lSLjn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Parser の初期化\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# 【演習 4】 完全なチェーンの構築\n",
        "# ------------------------------------------------------------------\n",
        "# 1. template\n",
        "# 2. llm\n",
        "# 3. parser\n",
        "# この3つを `|` で繋いで、新しい `text_chain` を作成してください。\n",
        "# その後、invoke を実行し、戻り値が `AIMessage` ではなく `str` (文字列) になっていることを確認してください。\n",
        "\n",
        "# ↓ ここにコードを記述してください"
      ],
      "metadata": {
        "id": "GGCaH2F-SOCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. チェーンの再構築\n",
        "# template (入力作成) -> llm (生成) -> parser (出力整形)\n",
        "text_chain = ■■■\n",
        "\n",
        "# 2. 実行 (前回と同じデータを使用)\n",
        "input_data = {\"name\": \"田中\", \"occupation\": \"エンジニア\"}\n",
        "\n",
        "print(f\"Running text_chain with: {input_data} ...\\n\")\n",
        "result = ■■■\n",
        "\n",
        "# 3. 結果の確認\n",
        "# AIMessage ではなく、純粋な str (文字列) が返ってきていることを確認します\n",
        "print(f\"--- Result Type: {type(result)} ---\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "b42Rw5B1W_O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧠 なぜ `|` で繋がるのか？ (Runnable Protocol)\n",
        "\n",
        "Python の標準機能に `|` でクラス同士を繋ぐ機能はありません。LangChain がこれを可能にしているのは、すべてのコンポーネント（Prompt, Model, Parserなど）が **`Runnable`** という共通の親クラスを継承しているからです。\n",
        "\n",
        "`Runnable` プロトコルに従うオブジェクトは、以下のルールを守っています。\n",
        "\n",
        "1.  **入力と出力の型が決まっている:**\n",
        "    * Prompt: `辞書` → `PromptValue`\n",
        "    * Model: `PromptValue` (or list) → `ChatMessage`\n",
        "    * Parser: `ChatMessage` → `文字列`\n",
        "2.  **`invoke` メソッドを持つ:** すべて共通の方法で呼び出せる。\n",
        "3.  **`|` 演算子 (`__or__`) を実装している:** 前の出力を次の入力に渡す処理（Linux のパイプと同様）を行う。\n",
        "\n",
        "この統一規格があるため、部品（Model や Prompt）を自由に入れ替えてもコードが壊れにくくなります。\n",
        "\n",
        "---\n",
        "\n",
        "### 次回の予告\n",
        "今回は「文字列」を入力し「文字列」を出力するチェーンを作りました。\n",
        "しかし、実務では **「JSON データを出力させて、プログラムで計算に使いたい」** という場面が多々あります。\n",
        "次回は、LLM の出力を構造化データ（JSON）として取り出す **Output Parser の応用** と、複数のチェーンを並列に動かす方法を学びます。"
      ],
      "metadata": {
        "id": "Fp0v1f7ySQWb"
      }
    }
  ]
}