{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpw1OpNW9m5/Z/mbTLZVtH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/agent/LangChain(3)_StructuredOutput_ToolCalling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📘 第3回：構造化出力とツール利用\n",
        "\n",
        "LangGraph などのエージェントシステムを作る際には、LLM と外部プログラムの接続が重要です。今回は、そのための2つの技術を学びます。\n",
        "\n",
        "1. **Structured Output (構造化出力):** LLM のふわっとした言葉を、システムで使える「確定したデータ型」に変換する。\n",
        "2. **Tool Calling (ツール利用):** LLM が自ら「計算したい」「検索したい」と判断し、Python 関数を呼び出せるようにする。\n",
        "\n",
        "### 🎯 今回の学習目標\n",
        "* 第1〜2回の知識（Prompt, Chain）が定着しているか確認する。\n",
        "* **Pydantic** を使い、LLM から JSON データを抽出する方法を学ぶ。\n",
        "* **`@tool`** デコレータと **`.bind_tools()`** を使い、LLM に Python 関数を認識させる。"
      ],
      "metadata": {
        "id": "YB8bMxVJ2kfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ⚡ 環境構築とAPIキー設定\n",
        "\n",
        "いつものセットアップを行います。\n",
        "必要なライブラリに加え、今回はデータ定義のために `pydantic` も確認しますが、これはColabには標準で入っています。"
      ],
      "metadata": {
        "id": "XZdWY2nP2tQT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU_nMuut2job"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain-openai langchain-core termcolor pydantic\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from termcolor import cprint\n",
        "\n",
        "try:\n",
        "    if \"OPENROUTER_API_KEY\" not in os.environ:\n",
        "        os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "    cprint(\"✅ API Key loaded.\", \"green\")\n",
        "except Exception as e:\n",
        "    cprint(\"❌ Error: Please set OPENROUTER_API_KEY in secrets.\", \"red\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1️⃣ 【復習】 基礎知識チェック（穴埋め課題）\n",
        "\n",
        "LangChain の基礎となる「プロンプト」と「LCEL」の理解度を確認しましょう。\n",
        "以下のコードの `___` の部分を書き換えて、正常に動くコードを完成させてください。\n",
        "\n",
        "**課題の要件:**\n",
        "1. `ChatPromptTemplate` を使って、「料理名 {dish} のレシピを教えて」というテンプレートを作る。\n",
        "2. LCEL のパイプ `|` を使って、 `prompt` → `llm` → `parser` を繋ぐ。\n",
        "3. `invoke` で実行する。"
      ],
      "metadata": {
        "id": "coM2UXqx24HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# モデルの準備\n",
        "llm = ChatOpenAI(\n",
        "    model=\"deepseek/deepseek-chat-v3-0324\", # または \"openai/gpt-4o-mini\"\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.5\n",
        ")\n",
        "\n",
        "# --- 📝 ここから修正してください ---\n",
        "\n",
        "# 1. プロンプトテンプレートの作成\n",
        "# ヒント: 文字列からテンプレートを作るメソッドは .from_template(...)\n",
        "prompt = ChatPromptTemplate.___( \"{dish} の美味しい作り方を一言で教えて。\" )\n",
        "\n",
        "# 2. 文字列出力パーサーの準備\n",
        "parser = StrOutputParser()\n",
        "\n",
        "# 3. チェーンの構築 (LCEL)\n",
        "# ヒント: パイプ演算子 | で繋ぎます\n",
        "chain = prompt ___ llm ___ parser\n",
        "\n",
        "# 4. 実行\n",
        "# ヒント: 実行メソッドは .invoke(...)\n",
        "result = chain.___(\n",
        "    {\"dish\": \"カレーライス\"}\n",
        ")\n",
        "\n",
        "# --- 修正ここまで ---\n",
        "\n",
        "print(f\"▼ 結果:\\n{result}\")"
      ],
      "metadata": {
        "id": "SQoCkUA9270C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2️⃣ Structured Output（構造化出力）\n",
        "\n",
        "### なぜ必要なのか？\n",
        "通常のチャット (`StrOutputParser`) では、LLM は「文字列」を返します。しかし、システム開発では以下のような状況が頻発します。\n",
        "\n",
        "* 「ユーザーのプロフィール文から、 **名前** と **年齢** と **趣味** をデータベースに保存したい」\n",
        "* 「長文のニュースから、 **重要キーワード** をリスト形式で取り出したい」\n",
        "\n",
        "これを「正規表現」や「文字列操作」で行うのはバグの元です。\n",
        "LangChain では **Pydantic** (Python のデータ定義ライブラリ) と **`.with_structured_output()`** を使うことで、LLM に強制的に指定した型で出力させることができます。\n",
        "\n",
        "### 実践：ユーザー情報の抽出\n",
        "以下の自己紹介文から、データを取り出してみましょう。\n",
        "\n",
        "> 「こんにちは！私はケンです。30歳で、東京でエンジニアをしています。休日はサウナに行くのが好きです。」"
      ],
      "metadata": {
        "id": "McgkvIOCA42K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional, List\n",
        "\n",
        "# 1. 設計図 (スキーマ) を作る\n",
        "# Pydanticを使って「どんなデータが欲しいか」をクラスとして定義します。\n",
        "class UserProfile(BaseModel):\n",
        "    name: str = Field(description=\"ユーザーの名前\")\n",
        "    age: Optional[int] = Field(description=\"ユーザーの年齢。不明な場合はNone\")\n",
        "    job: str = Field(description=\"職業\")\n",
        "    hobbies: List[str] = Field(description=\"趣味のリスト\")\n",
        "\n",
        "# 2. モデルに構造化機能を付与する\n",
        "# .with_structured_output(クラス名) を使うと、出力がそのクラスのインスタンスになります。\n",
        "structured_llm = llm.with_structured_output(UserProfile)\n",
        "\n",
        "# 3. 実行\n",
        "text_input = \"こんにちは！私はケンです。30歳で、東京でエンジニアをしています。休日はサウナに行くのが好きです。\"\n",
        "profile = structured_llm.invoke(text_input)\n",
        "\n",
        "# 結果の確認\n",
        "print(f\"▼ 型の確認: {type(profile)}\")\n",
        "print(f\"▼ 名前: {profile.name}\")\n",
        "print(f\"▼ 年齢: {profile.age}\")\n",
        "print(f\"▼ 趣味: {profile.hobbies}\")\n",
        "\n",
        "# JSON形式 (辞書) に変換するのも簡単です\n",
        "print(f\"\\n▼ JSON形式:\\n{profile.model_dump()}\")"
      ],
      "metadata": {
        "id": "Xu9ObAL2BBCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 💡 ポイント\n",
        "もし入力テキストに「年齢」が含まれていなかったらどうなるでしょうか？\n",
        "上記の `text_input` を変更して（例：「私はケンです。」だけにする）、 `age` がどうなるか試してみてください。\n",
        "\n",
        "`Optional[int]` と定義し、 `Field` に説明を書いているため、LLM は「情報がない場合は None にする」という判断を自動で行います。"
      ],
      "metadata": {
        "id": "y--pFDa4BGdw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 【演習】 Pydantic による注文情報の抽出\n",
        "\n",
        "自己紹介文以外のパターンでも練習してみましょう。\n",
        "次は **「ECサイトのチャットボット」** を想定します。\n",
        "ユーザーは自然言語で注文を行いますが、システム側では「商品名」や「数量」などの確定したデータが必要です。\n",
        "\n",
        "以下の要件を満たす `Order` クラスを定義し、注文から:データを抽出してください。\n",
        "\n",
        "**抽出したいデータ（スキーマ）:**\n",
        "* `product_name` (str): 商品名。\n",
        "* `quantity` (int): 注文数量。\n",
        "* `express_delivery` (bool): お急ぎ便の希望有無。文脈から判断させます（デフォルトは False）。\n",
        "* `price_limit` (Optional[int]): 予算上限。指定がない場合は None。\n",
        "\n",
        "この演習を通して、 **「ライブラリのインポートから実行結果の取り出しまで」** の一連の流れを構築する力を養います。"
      ],
      "metadata": {
        "id": "ssicrMwnBkkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 📝 以下のコードの ___ を書き換えて完成させてください ---\n",
        "\n",
        "# 1. 必要なライブラリのインポート\n",
        "# ヒント: データ定義には BaseModel, Field が必要です\n",
        "# ヒント: 予算上限など「値がない場合」を扱うために Optional が必要です\n",
        "from pydantic import ___, ___\n",
        "from typing import ___\n",
        "\n",
        "# 2. データ構造 (スキーマ) の定義\n",
        "# ヒント: Pydanticのモデルは BaseModel を継承します\n",
        "class Order(___):\n",
        "    # 商品名: 文字列型。Fieldで説明を追加 (\"注文する商品の名前\")\n",
        "    product_name: str = ___\n",
        "\n",
        "    # 数量: 整数型\n",
        "    quantity: int = Field(description=\"注文する数量\")\n",
        "\n",
        "    # お急ぎ便: 真偽値型 (\"お急ぎ便や速達を希望している場合はTrue、そうでなければFalse\")\n",
        "    express_delivery: bool = ___\n",
        "\n",
        "    # 予算上限: 整数型だが、指定がない場合は None (Optional[int])\n",
        "    price_limit: ___ = Field(description=\"予算の上限金額。指定がなければNone\")\n",
        "\n",
        "# 3. LLMにスキーマを適用\n",
        "# ヒント: .with_structured_output() メソッドを使います\n",
        "order_llm = llm.___(Order)\n",
        "\n",
        "# 4. テストデータの実行\n",
        "user_order = \"来週のキャンプ用に、テントを2つ買いたいです。なるべく早く届けてほしい！予算はだいたい3万円以内で。\"\n",
        "\n",
        "# ヒント: invoke メソッドで実行します\n",
        "result = order_llm.___(user_order)\n",
        "\n",
        "# 5. 結果の表示\n",
        "# ヒント: 結果は Order クラスのインスタンスとして返ってきます。属性 (.product_name など) でアクセスします\n",
        "print(f\"▼ 注文商品: {result.___}\")\n",
        "print(f\"▼ 数量: {result.___} 個\")\n",
        "print(f\"▼ お急ぎ便: {result.___}\")\n",
        "print(f\"▼ 予算上限: {result.___} 円\")\n",
        "\n",
        "# --- 修正ここまで ---"
      ],
      "metadata": {
        "id": "bavqKOs1BpCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3️⃣ Tool Calling（ツール利用）\n",
        "\n",
        "### ツール利用とは\n",
        "LLM は計算が苦手ですし、インターネット検索も単体ではできません。\n",
        "LLM に Python の関数（ツール）を渡し、「必要ならこれを使ってください」と教える機能が **Tool Calling** です。\n",
        "\n",
        "LangGraph のエージェントは、この仕組みを使って、自分で考え、ツールを選び、実行するようなサイクルを回しています。\n",
        "\n",
        "### 例：計算ツール\n",
        "LLM は複雑な計算を間違えることがありますが、Python の関数を使えば正確です。"
      ],
      "metadata": {
        "id": "ZWIUE2rPCYub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# 1. ツールの定義\n",
        "# ＠tool デコレータをつけ、docstring（関数の説明）をしっかり書くのがコツです。\n",
        "# LLM はこの説明文を読んで「いつ使うべきか」を判断します。\n",
        "\n",
        "@tool\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"2つの整数を掛け算します。\"\"\"\n",
        "    return a * b\n",
        "\n",
        "# 確認：ツールには名前や説明が自動的に付与されます\n",
        "print(f\"Tool Name: {multiply.name}\")\n",
        "print(f\"Tool Description: {multiply.description}\")\n",
        "\n",
        "# 2. モデルにツールをバインド (紐づけ) する\n",
        "# bind_tools でリスト形式で渡します\n",
        "llm_with_tools = llm.bind_tools([multiply])\n",
        "\n",
        "# 3. 実行：ツールが必要な質問を投げる\n",
        "query = \"123 かける 456 はいくつ？\"\n",
        "ai_msg = llm_with_tools.invoke(query)\n",
        "\n",
        "# 重要：ここでの戻り値 ai_msg は「計算結果」ではありません！\n",
        "# 「計算関数を、引数(123, 456)で呼び出したい」という「リクエスト」が入っています。\n",
        "print(f\"\\n▼ AIの返答 (Message):\\n{ai_msg}\")\n",
        "print(f\"\\n▼ ツール呼び出しリクエスト (tool_calls):\\n{ai_msg.tool_calls}\")"
      ],
      "metadata": {
        "id": "uhgnX7xNCi0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 【追加演習 1】 Tool Calling による現在時刻の取得\n",
        "\n",
        "天気予報の代わりに、**「現在時刻」** を取得させてみましょう。\n",
        "LLM は学習した時点の知識で止まっているため、「今、何時？」と聞かれても答えることができません（あるいは適当な嘘をつきます）。\n",
        "\n",
        "そこで、Python の `datetime` モジュールを使って **「本当に現在の時刻を返す関数」** を作成し、それをツールとして LLM に持たせます。これならダミーデータではなく、実行するたびに結果が変わるリアルなシステムになります。\n",
        "\n",
        "**課題:**\n",
        "1. `@tool` デコレータを使って、時刻取得関数をツール化する。\n",
        "2. `bind_tools` で LLM にツールを認識させる。\n",
        "3. 「今の東京の時間は？」と質問し、LLM がツールを使おうとしたか確認する。"
      ],
      "metadata": {
        "id": "wT_Dr8t3C2Gv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 📝 以下のコードの ___ を書き換えて完成させてください ---\n",
        "\n",
        "# 1. 必要なライブラリのインポート\n",
        "from langchain_core.tools import ___\n",
        "from datetime import datetime\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "# 2. ツールの定義\n",
        "# ヒント: デコレータを使って関数をツール化します\n",
        "# ヒント: docstring (\"\"\"...\"\"\") はAIが使い方を判断するために重要です\n",
        "@___\n",
        "def get_current_time(timezone: str = \"Asia/Tokyo\") -> str:\n",
        "    \"\"\"\n",
        "    指定されたタイムゾーンの現在時刻を取得します。\n",
        "    引数 timezone には 'Asia/Tokyo' や 'UTC' などの文字列を指定します。\n",
        "    \"\"\"\n",
        "    # 実際に現在時刻を取得するコード（ダミーではありません！）\n",
        "    now = datetime.now(ZoneInfo(timezone))\n",
        "    return now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "# 3. モデルにツールをバインド (紐づけ)\n",
        "# ヒント: 定義した関数をリスト形式で渡します\n",
        "time_llm = llm.___( [___] )\n",
        "\n",
        "# 4. 実行\n",
        "# わざと少し複雑な聞き方をして、引数 (Asia/Tokyo) を推論させてみます\n",
        "query = \"今、東京は何時ですか？\"\n",
        "\n",
        "# ヒント: invoke で実行します\n",
        "ai_msg = time_llm.___(query)\n",
        "\n",
        "# 5. 結果の確認\n",
        "# ヒント: ツール呼び出しの情報は .tool_calls プロパティに入っています\n",
        "print(f\"▼ AIの返答オブジェクト:\\n{ai_msg}\")\n",
        "print(f\"\\n▼ ツール呼び出しリクエスト:\\n{ai_msg.___}\")\n",
        "\n",
        "# --- 修正ここまで ---\n",
        "\n",
        "# (参考) 正しく実装できていれば、tool_calls の中に\n",
        "# {'name': 'get_current_time', 'args': {'timezone': 'Asia/Tokyo'}, ...}\n",
        "# というデータが入っているはずです。"
      ],
      "metadata": {
        "id": "WXB_orh4C5kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 📝 【追加演習 2】 世界の都市の時刻推論\n",
        "\n",
        "LLM にツールを使わせる最大のメリットは、**「曖昧なユーザーの言葉を、正確な引数に変換してくれること」** です。\n",
        "\n",
        "先ほど定義した `get_current_time` 関数は、`Asia/Tokyo` や `America/New_York` といった正確な **Time Zone ID** を引数として受け取る必要があります。しかし、ユーザーはいちいちそんな ID を覚えていません。「ロンドン」や「NY」と入力するだけです。\n",
        "\n",
        "LLM が文脈を理解し、適切な ID を推論してツールに渡してくれることを確認するために、複数の都市について連続で問い合わせてみましょう。\n",
        "\n",
        "**課題:**\n",
        "1. 調査したい都市のリストを作成する（ロンドン、ニューヨーク、北京など）。\n",
        "2. `for` ループを使って、各都市の時刻を問い合わせる。\n",
        "3. LLM が生成したツール呼び出し引数 (`args`) が、正しいタイムゾーンIDになっているか確認する。"
      ],
      "metadata": {
        "id": "cpKIkRj_Dm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 📝 以下のコードの ___ を書き換えて完成させてください ---\n",
        "\n",
        "# 1. 調査したい都市や国名のリスト\n",
        "# ヒント: \"ロンドン\", \"New York\" のほかに \"北京\" や \"Beijing\"、\"ペキン\" なども試してみましょう\n",
        "target_cities = [\"ロンドン\", \"New York\", \"___\"]\n",
        "\n",
        "print(f\"--- 🌍 世界時計ツアー開始 ---\")\n",
        "\n",
        "for city in target_cities:\n",
        "    # 質問文を作成\n",
        "    query = f\"{city}の現在の時刻を教えてください。\"\n",
        "\n",
        "    # 2. LLMを実行\n",
        "    # ヒント: 先ほど作成した time_llm を再利用します\n",
        "    ai_msg = time_llm.___(query)\n",
        "\n",
        "    # 3. 推論結果の確認\n",
        "    if ai_msg.tool_calls:\n",
        "        # ツール呼び出しの引数を取り出す\n",
        "        args = ai_msg.tool_calls[0][\"args\"]\n",
        "        timezone_id = args.get(\"timezone\")\n",
        "\n",
        "        # 結果表示\n",
        "        print(f\"\\n都市名: {city}\")\n",
        "        print(f\" -> 🤖 推論されたタイムゾーン: {timezone_id}\")\n",
        "\n",
        "        # 実際にツールを動かして時刻を表示してみる（オプション）\n",
        "        # time_tool = get_current_time (関数の実体)\n",
        "        # print(f\" -> ⏰ 実際の時刻: {get_current_time.invoke(args)}\")\n",
        "    else:\n",
        "        print(f\"\\n都市名: {city} -> ⚠️ ツールが呼ばれませんでした\")\n",
        "\n",
        "# --- 修正ここまで ---\n",
        "\n",
        "# (解説)\n",
        "# \"北京\", \"Beijing\", \"ペキン\" のいずれを入力しても、\n",
        "# LLM は 'Asia/Shanghai' という正しいタイムゾーンIDを推論するはずです。\n",
        "# これが「LLMをインターフェースにする」利点です。"
      ],
      "metadata": {
        "id": "Q3-4ljb6Dop3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🔬 【補足】 Tool Calling における LLM の役割\n",
        "\n",
        "ここで重要な点は、`llm.bind_tools` を使ったものの、LLM が自分で関数を実行してくれたわけではないことです。\n",
        "\n",
        "LLM が行ったのは、あくまで **「この関数を、この引数で実行してください」という指示文（`tool_calls`）を作成しただけ** です。この指示文を受け取った **LangChain 側** が、実際にその関数を実行します。"
      ],
      "metadata": {
        "id": "3L46csb6FVJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 直前の実行結果 (ai_msg) から、ツール呼び出しの「中身」を取り出します\n",
        "if ai_msg.tool_calls:\n",
        "    # 1. LLMが作成したリクエストを取得 (リストの1つ目)\n",
        "    request = ai_msg.tool_calls[0]\n",
        "\n",
        "    # 2. 関数名と引数を確認\n",
        "    func_name = request[\"name\"]\n",
        "    args = request[\"args\"]\n",
        "\n",
        "    print(f\"🤖 LLMの指示: 「関数 {func_name} を 引数 {args} で実行せよ」\")\n",
        "\n",
        "    # 3. 人間（システム）が代わりに関数を実行\n",
        "    # ここでは手動で行いますが、エージェントシステムではここを自動化します\n",
        "    if func_name == \"get_current_time\":\n",
        "        # 定義しておいた関数に引数を渡して実行\n",
        "        tool_result = get_current_time.invoke(args)\n",
        "        print(f\"✅ 実行結果: {tool_result}\")\n",
        "\n",
        "else:\n",
        "    print(\"⚠️ ツール呼び出しのリクエストがありませんでした\")"
      ],
      "metadata": {
        "id": "WzBgu1VlFlhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏆 第1回〜第3回のまとめ：LangChain 基礎コース修了\n",
        "\n",
        "これまでの3回で、LangChain の重要な知識をすべてカバーしました。\n",
        "\n",
        "### 🎓 まとめ\n",
        "\n",
        "| 回 | テーマ | キーワード | 学んだこと |\n",
        "|:---:|:---|:---|:---|\n",
        "| **第1回** | **LLMの基礎** | `ChatModel`, `SystemMessage`, `invoke` | API を阿叩く上での **役割(Role)** を持たせた会話の基本構造を学びました。 |\n",
        "| **第2回** | **プロンプトとLCEL** | `PromptTemplate`, `OutputParser`, `\\|` (Pipe) | 入力から出力までを **パイプライン** としてつなぎ、効率的に処理する方法を学びました。 |\n",
        "| **第3回** | **システムとの接続** | `Structured Output`, `Tool Calling` | LLMをただのチャットボットではなく、外部のツールを呼ぶためのツールとして使うようになりました。 |\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 次は LangGraph へ\n",
        "\n",
        "これまでは、一本道の処理（チェーン）を作ってきました。\n",
        "しかし、現実の複雑なタスク（例：「検索してみて、見つからなかったら別の方法を試す」など）には、**ループ（繰り返し）** や **条件分岐** が必要です。次回からは **LangGraph** を使い、具体的な AI エージェントの構築に入ります。"
      ],
      "metadata": {
        "id": "AjacUDwJEN9I"
      }
    }
  ]
}