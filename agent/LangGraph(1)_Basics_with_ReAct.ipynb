{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0ciBQP+UkSp5l6GpnpEfi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/agent/LangGraph(1)_Basics_with_ReAct.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph (1): 基礎とReActエージェントの構築\n",
        "\n",
        "LangChain の基礎コースに続き、本ノートブックからは **LangGraph** を用いたエージェント構築を扱います。\n",
        "\n",
        "LangChain が一方向の処理連鎖（DAG）を主としていたのに対し、LangGraph はループを含む循環グラフ構造を定義可能です。これにより、LLM が自身の出力やツール実行結果に基づいて次の行動を決定する、自律的なエージェント機能（ReAct パターンなど）の実装が容易になります。\n",
        "\n",
        "### 学習目標\n",
        "* **State Management:** ノード間で共有される状態（State）の定義と更新メカニズムの理解。\n",
        "* **Graph Construction:** ノードとエッジによるグラフ構造の設計と可視化。\n",
        "* **ReAct Agent:** 条件付きエッジとループ構造を用いた、自己回帰的な検索エージェントの実装。"
      ],
      "metadata": {
        "id": "96V-PaXXls0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. 環境構築とAPI設定\n",
        "\n",
        "`langgraph` および関連ライブラリをインストールします。グラフ構造の可視化には `grandalf` を使用します。"
      ],
      "metadata": {
        "id": "p08WmnlWlv3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langgraph langchain-openai langchain-community tavily-python termcolor grandalf\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain_openai import ChatOpenAI\n",
        "from termcolor import cprint\n",
        "\n",
        "# APIキーの設定\n",
        "try:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "    os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "    cprint(\"API Keys loaded.\", \"green\")\n",
        "except Exception:\n",
        "    cprint(\"Error: Please set OPENROUTER_API_KEY and TAVILY_API_KEY in secrets.\", \"red\")\n",
        "\n",
        "# LLMの初期化\n",
        "# model は deepseek/deepseek-chat-v3-0324 を使用\n",
        "llm = ChatOpenAI(\n",
        "    base_url=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    model=\"deepseek/deepseek-chat-v3-0324\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "GQuXe0Vbl32j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. LangGraph の基本構造\n",
        "\n",
        "LangGraph を理解する上で重要なのが、システム全体で共有される「状態（ステート, State）」という概念です。\n",
        "\n",
        "これまでの手法では、ある処理の結果を次の処理へバケツリレーのように直接渡していました。一方、LangGraph では「現在の状況」を記録する場所を一つ用意します。それぞれの処理担当者（ノード）は、その共有された記録を見て自分の仕事を行い、結果をまたその記録場所に書き込みます。これにより、複雑なデータのやり取りや記憶の管理が容易になります。\n",
        "\n",
        "### 状態（ステート）の定義\n",
        "\n",
        "まず、エージェントがどのような情報を記憶しておくべきかを定義します。ここでは、ユーザーとの会話の履歴をリスト形式で保持するように設定します。また、新しい発言があった場合のルールとして、過去の履歴を消去して上書きするのではなく、既存の履歴の後ろに新しい内容を順番に追加していくように指定します。\n",
        "\n",
        "`TypedDict` を使用して State のスキーマを定義します。ここでは会話履歴を保持する `messages` フィールドを作成します。\n",
        "`Annotated` と `add_messages` リデューサを使用することで、ノードからの出力が既存リストに追記（append）される挙動を定義します。"
      ],
      "metadata": {
        "id": "JV3XJ1-q_wIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Annotated, TypedDict\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "class State(TypedDict):\n",
        "    # メッセージのリストを保持するState\n",
        "    # add_messages は、新しいメッセージが返されたときに既存のリストに追加する処理（Reducer）です\n",
        "    messages: Annotated[list, add_messages]\n",
        "\n",
        "print(\"State schema defined.\")"
      ],
      "metadata": {
        "id": "yIMXDB4nAqj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 処理担当（ノード）の実装\n",
        "\n",
        "「ノード」とは、グラフの中で実際に特定の作業を行う処理単位のことです。各ノードは現在の状況（ステート）を受け取り、自分の仕事の結果として更新分を返します。\n",
        "\n",
        "ここでは、AIモデルにこれまでの会話履歴を読ませ、適切な返答を生成させる処理を作成します。AIが生成した返答は、先ほど定義した共有の記録場所に追加されることになります。"
      ],
      "metadata": {
        "id": "-ArM13JPAyf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_node(state: State):\n",
        "    \"\"\"\n",
        "    現在の会話履歴を用いてLLMに応答を生成させるノード\n",
        "    \"\"\"\n",
        "    # 1. Stateから現在のメッセージ履歴を取得\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # 2. LLMを実行 (invoke)\n",
        "    response = llm.invoke(messages)\n",
        "\n",
        "    # 3. Stateの更新差分を返却\n",
        "    # ここで返したメッセージが、Stateのmessagesリストの末尾に追加されます\n",
        "    return {\"messages\": [response]}"
      ],
      "metadata": {
        "id": "amMPPA-FA01C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グラフの構築とコンパイル\n",
        "\n",
        "定義した処理単位（ノード）を配置し、それらを線（エッジ）で繋いで全体の流れを作ります。\n",
        "\n",
        "ここでは「開始地点」から「AIの処理」へ進み、処理が終わったら「終了地点」へ向かうという、最も単純な一本道の流れを構築します。最後に、この設計図をプログラムとして実行可能な形式に変換します。\n",
        "\n",
        "`StateGraph` クラスを用いてグラフを構築します。\n",
        "1. `add_node`: 定義した関数をノードとして登録。\n",
        "2. `add_edge`: ノード間の遷移を定義（START -> chatbot -> END）。\n",
        "3. `compile`: 実行可能な `CompiledGraph` オブジェクトを生成。"
      ],
      "metadata": {
        "id": "z7XzNNzUA1ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# グラフビルダーの初期化\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "# ノードとエッジの追加\n",
        "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
        "graph_builder.add_edge(START, \"chatbot\") # 開始 -> chatbot\n",
        "graph_builder.add_edge(\"chatbot\", END)   # chatbot -> 終了\n",
        "\n",
        "# コンパイル (実行可能オブジェクトの生成)\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "# グラフ構造の可視化 (Mermaid)\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception as e:\n",
        "    print(f\"Visualization failed: {e}\")"
      ],
      "metadata": {
        "id": "yHqSsw2WA2xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 実行確認\n",
        "\n",
        "`graph.stream` を使用して、初期状態を入力し、グラフを実行します。初期状態として最初の会話文を与えると、グラフの流れに従って各ステップでのノードの出力がストリームされます。"
      ],
      "metadata": {
        "id": "8B8jM-S_A6As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = {\"messages\": [(\"user\", \"LangGraphの学習を開始します。\")]}\n",
        "\n",
        "# streamメソッドでグラフを実行\n",
        "# event には各ノードの出力が含まれます\n",
        "for event in graph.stream(initial_state):\n",
        "    for node_name, values in event.items():\n",
        "        print(f\"--- Node: {node_name} ---\")\n",
        "\n",
        "        # values[\"messages\"] はそのノードが生成した新しいメッセージのリスト\n",
        "        last_msg = values[\"messages\"][-1]\n",
        "\n",
        "        # LLMの応答を表示\n",
        "        print(f\"Output: {last_msg.content}\")"
      ],
      "metadata": {
        "id": "HFDIRRQCA7BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ReAct エージェントの実装 (循環グラフ)\n",
        "\n",
        "LLM がツール実行の必要性を判断し、実行結果に基づいて再推論を行う ReAct (Reasoning and Acting) パターンを実装します。\n",
        "単純な一本道ではなく、条件によって進む道を変える仕組みと、納得いくまで処理を繰り返すためのループ構造を取り入れます。この構造には、条件に応じて遷移先を変える **Conditional Edge** と、処理を戻す **Cycle** が必要です。これにより、AIは検索結果を見て「情報が足りないからもう一度調べよう」といった試行錯誤ができるようになります。\n",
        "\n",
        "### ツールの設定\n",
        "\n",
        "LLMが外部の情報を調べるために使う検索機能を準備します。LLM自身はインターネットに直接接続できないため、検索専用の道具を持たせ、その使い方を認識させます。ここでは Tavily Search API をツールとして定義し、LLM にバインドします。"
      ],
      "metadata": {
        "id": "Rgcezr_RA8hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# 検索ツールの初期化 (最大3件取得)\n",
        "tool = TavilySearchResults(max_results=3)\n",
        "tools = [tool]\n",
        "\n",
        "# LLMにツールをバインド\n",
        "# これにより、LLMは回答の代わりに「ツール実行リクエスト (tool_calls)」を出力できるようになります\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ],
      "metadata": {
        "id": "VHbWcahvA825"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ノードと条件付き分岐の定義\n",
        "\n",
        "ここでは、「思考を担当するノード」と「道具の使用を担当するノード」の二つを用意します。\n",
        "\n",
        "重要なのは、思考担当ノードの後に設置する分岐点です。「AIがツールを使いたいと言ったかどうか」を判断基準にして、自動的に進む道が切り替わるように設定します。さらに、ツールを使った後は、その結果を持って再び思考担当ノードに戻るように道を繋ぎます。\n",
        "\n",
        "\n",
        "* **agent:** LLM が思考し、応答またはツール呼び出し（tool_calls）を生成します。\n",
        "* **tool:** `tool_calls` を解析し、実際にツールを実行します。LangGraph の `ToolNode` を使用します。\n",
        "* **conditional edge:** LLM の出力に `tool_calls` が含まれる場合は Tool Node へ、そうでなければ終了 (END) へ遷移します。"
      ],
      "metadata": {
        "id": "XP2YgTsqA-fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "\n",
        "def agent_node(state: State):\n",
        "    \"\"\"\n",
        "    現在のStateに基づいてLLMを実行し、次のアクション（回答 or ツール呼び出し）を決定するノード\n",
        "    \"\"\"\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # ツール情報付きのLLMを実行\n",
        "    # 結果には通常のテキスト、または tool_calls が含まれる\n",
        "    response = llm_with_tools.invoke(messages)\n",
        "\n",
        "    # 結果をStateに追加\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "# ツール実行用ノード (LangGraph提供)\n",
        "# 直前のメッセージに含まれる tool_calls を自動的に実行し、結果を ToolMessage として返します\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "# --- グラフ構築 ---\n",
        "agent_builder = StateGraph(State)\n",
        "\n",
        "# ノードの追加\n",
        "agent_builder.add_node(\"agent\", agent_node)\n",
        "agent_builder.add_node(\"tools\", tool_node)\n",
        "\n",
        "# エッジの定義\n",
        "agent_builder.add_edge(START, \"agent\")\n",
        "\n",
        "# 条件付きエッジ (Conditional Edge)\n",
        "# \"agent\" ノードの出力後に実行され、次の遷移先を動的に決定します\n",
        "# tools_condition は以下のロジックを持ちます：\n",
        "# - 直前のメッセージに tool_calls がある -> \"tools\" へ遷移\n",
        "# - ない -> END へ遷移\n",
        "agent_builder.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tools_condition,\n",
        "    {\"tools\": \"tools\", \"__end__\": END}\n",
        ")\n",
        "\n",
        "# 循環エッジ (Cycle)\n",
        "# ツール実行後は必ず agent に戻り、検索結果を踏まえて再考させます\n",
        "agent_builder.add_edge(\"tools\", \"agent\")\n",
        "\n",
        "agent_graph = agent_builder.compile()\n",
        "\n",
        "display(Image(agent_graph.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "6bVJtKQ5A_SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. エージェントの実行\n",
        "\n",
        "複雑なクエリを入力し、LLM がどのように判断（出力）し、ツールがどう実行されたかを確認します。\n",
        "中間出力を詳細に表示することで、グラフ内のデータの流れを追跡します。"
      ],
      "metadata": {
        "id": "KtgUz6ByBAts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from termcolor import colored\n",
        "\n",
        "def print_stream(graph, query):\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    inputs = {\"messages\": [HumanMessage(content=query)]}\n",
        "\n",
        "    # グラフをステップ実行\n",
        "    for event in graph.stream(inputs):\n",
        "        for node_name, values in event.items():\n",
        "            print(colored(f\"=== Node: {node_name} ===\", \"blue\", attrs=[\"bold\"]))\n",
        "\n",
        "            # このノードで生成されたメッセージを取得\n",
        "            messages = values[\"messages\"]\n",
        "            for msg in messages:\n",
        "                # 1. LLMがツール呼び出しを決定した場合\n",
        "                if hasattr(msg, \"tool_calls\") and len(msg.tool_calls) > 0:\n",
        "                    print(colored(\"decision: Tool Call Required\", \"magenta\"))\n",
        "                    for tc in msg.tool_calls:\n",
        "                        print(f\"  - Tool: {tc['name']}\")\n",
        "                        print(f\"  - Args: {tc['args']}\")\n",
        "\n",
        "                # 2. ツール実行結果の場合\n",
        "                elif msg.type == \"tool\":\n",
        "                    print(colored(\"Action: Tool Executed\", \"green\"))\n",
        "                    # 結果が長い場合は切り詰めて表示\n",
        "                    content_preview = msg.content[:200] + \"...\" if len(msg.content) > 200 else msg.content\n",
        "                    print(f\"  - Result: {content_preview}\")\n",
        "\n",
        "                # 3. 最終的な回答の場合\n",
        "                else:\n",
        "                    print(colored(\"Decision: Final Answer\", \"cyan\"))\n",
        "                    print(msg.content)\n",
        "            print(\"\\n\")\n",
        "\n",
        "# 実行\n",
        "query = \"LangGraphの主な機能と、LangChainとのアーキテクチャ上の違いを解説してください。\"\n",
        "print_stream(agent_graph, query)"
      ],
      "metadata": {
        "id": "R6nWycqYBBjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### まとめ\n",
        "\n",
        "本セクションでは LangGraph を用いて、自分で考えて道具を使うエージェントを作成しました。\n",
        "\n",
        "1.  **状態の共有:** 処理の間でデータを受け渡すための「記録場所」を定義しました。\n",
        "2.  **ループ構造:** 道具を使った後に再び思考に戻ることで、試行錯誤を可能にしました。\n",
        "3.  **条件分岐:** 状況に応じて、道具を使うか回答するかを自動で判断させました。\n",
        "\n",
        "次回は、会話の内容を長期的に覚えておくための記憶の仕組み（永続化）と、自分の回答を見直して修正する機能の実装に進みます。"
      ],
      "metadata": {
        "id": "ZL3fw1zuBCvK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. 【演習】 自作ツールの追加\n",
        "\n",
        "Tavily 検索以外のツールをエージェントに追加してみましょう。\n",
        "ここでは、入力されたテキストの文字数をカウントする単純なツール `count_chars` を作成し、エージェントに組み込みます。\n",
        "\n",
        "**課題:**\n",
        "以下のコードの `■■■` を埋めて完成させ、エージェントが「検索」と「文字数カウント」の2つのツールを適切に使い分けるか確認してください。"
      ],
      "metadata": {
        "id": "OBSs4JvsFxa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "# 1. 自作ツールの定義\n",
        "# 関数をツールとして LangChain に認識させるためのデコレータ\n",
        "@■■■\n",
        "def count_chars(text: str) -> int:\n",
        "    \"\"\"\n",
        "    指定されたテキストの文字数をカウントします。空白や改行も1文字として数えます。\n",
        "    \"\"\"\n",
        "    # 引数 text の長さを計算して返す\n",
        "    return ■■■\n",
        "\n",
        "# 2. ツールリストの更新\n",
        "# 既存の TavilySearchResults (max_results=1) と、上で作った count_chars をリストにする\n",
        "new_tools = [TavilySearchResults(max_results=1), ■■■]\n",
        "\n",
        "# 3. 新しいLLMとノードの作成\n",
        "# 定義済みの llm に対して、作成したツールリストをバインド (紐付け) する\n",
        "llm_with_new_tools = llm.■■■(new_tools)\n",
        "\n",
        "# ツールを実行するためのノード (ToolNode) を作成する\n",
        "new_tool_node = ■■■(new_tools)\n",
        "\n",
        "# エージェントノード (思考担当) の定義\n",
        "def new_agent_node(state: State):\n",
        "    # State の辞書から \"messages\" キーの値を取得する\n",
        "    messages = state[■■■]\n",
        "\n",
        "    # ツール情報を持った LLM を実行 (invoke) する\n",
        "    response = llm_with_new_tools.■■■(messages)\n",
        "\n",
        "    # 結果を State の形式 (辞書) で返す。キーは \"messages\"、値はリストにする\n",
        "    return {■■■: [response]}\n",
        "\n",
        "# 4. 新しいグラフの構築\n",
        "# StateGraph を State クラスを使って初期化する\n",
        "new_builder = ■■■(State)\n",
        "\n",
        "# ノードを登録する (\"agent\" という名前で new_agent_node を登録)\n",
        "new_builder.■■■(\"agent\", new_agent_node)\n",
        "# ノードを登録する (\"tools\" という名前で new_tool_node を登録)\n",
        "new_builder.■■■(\"tools\", new_tool_node)\n",
        "\n",
        "# 開始地点 (START) から agent ノードへのエッジ (線) を追加する\n",
        "new_builder.■■■(START, \"agent\")\n",
        "\n",
        "# 条件付きエッジ (Conditional Edge) を追加する\n",
        "# agent の出力に基づき、ツールを使うなら \"tools\" へ、そうでなければ終了 (END) へ分岐させる\n",
        "# 分岐判定ロジックには既定の tools_condition を使用する\n",
        "new_builder.■■■(\n",
        "    \"agent\",\n",
        "    ■■■,\n",
        "    {\"tools\": \"tools\", \"__end__\": END}\n",
        ")\n",
        "\n",
        "# 循環エッジ: ツール実行後は必ず agent に戻るようにエッジを追加する\n",
        "new_builder.■■■(\"tools\", \"agent\")\n",
        "\n",
        "# グラフをコンパイルして実行可能な状態にする\n",
        "new_graph = new_builder.■■■()\n",
        "\n",
        "# 5. 実行確認 (ここは記述済み)\n",
        "# 検索が必要な質問と、計算が必要な質問を組み合わせたクエリ\n",
        "test_query = \"「LangGraph」という単語の文字数を数えてください。また、LangGraphの最新バージョンについて検索して教えて。\"\n",
        "print_stream(new_graph, test_query)"
      ],
      "metadata": {
        "id": "TbgOflhTFzeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### まとめ\n",
        "\n",
        "本セクションでは LangGraph によるエージェント構築の基礎を実装しました。\n",
        "\n",
        "1.  **StateGraph:** 共有状態を持つグラフ構造の定義。\n",
        "2.  **Cyclic Execution:** `tools` から `agent` へのエッジによる、自律的なループ処理の実現。\n",
        "3.  **Conditional Logic:** `tools_condition` による動的な制御フローの実装。\n",
        "\n",
        "次回は、MemorySaver を用いた会話履歴の永続化 (Persistence) と、Reflection パターンの実装に進みます。"
      ],
      "metadata": {
        "id": "iX9kdrf3F3su"
      }
    }
  ]
}