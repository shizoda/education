{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy/fLdOZPjWePH9fvaSyk0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/agent/LangGraph(4)_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ (4) RAG ã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰ã¨ãƒ‡ãƒ¼ã‚¿æ¤œç´¢ã®å®Ÿè£…\n",
        "\n",
        "## 1. RAG (Retrieval-Augmented Generation) ã®æŠ€è¡“çš„èƒŒæ™¯\n",
        "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ« (LLM) ã¯ã€äº‹å‰å­¦ç¿’ã«å«ã¾ã‚Œãªã„ã€Œéå…¬é–‹ãƒ‡ãƒ¼ã‚¿ï¼ˆç¤¾å†…è¦å®šãªã©ï¼‰ã€ã‚„ã€Œæœ€æ–°æƒ…å ±ã€ã«é–¢ã™ã‚‹è³ªå•ã«ã¯æ­£ç¢ºã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã€‚ç„¡ç†ã«ç­”ãˆã•ã›ã‚‹ã¨ã€äº‹å®Ÿã«åŸºã¥ã‹ãªã„å›ç­”ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼‰ã‚’ç”Ÿæˆã™ã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "**RAG (æ¤œç´¢æ‹¡å¼µç”Ÿæˆ)** ã¯ã€ã“ã®èª²é¡Œã‚’è§£æ±ºã™ã‚‹ãŸã‚ã«ã€ä»¥ä¸‹ã®ãƒ—ãƒ­ã‚»ã‚¹ã‚’çµ±åˆã—ãŸã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã™ã€‚\n",
        "\n",
        "1.  **Retrieval (æ¤œç´¢)**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå• (Query) ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (Context) ã‚’æ„å‘³çš„é¡ä¼¼åº¦ã«åŸºã¥ã„ã¦æŠ½å‡ºã—ã¾ã™ã€‚\n",
        "2.  **Augmentation (æ‹¡å¼µ)**: æŠ½å‡ºã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã€Œæ­£è§£ã®æ ¹æ‹ ã€ã¨ã—ã¦ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã¿ã¾ã™ã€‚\n",
        "3.  **Generation (ç”Ÿæˆ)**: LLM ã¯ã€ä¸ãˆã‚‰ã‚ŒãŸæ ¹æ‹ ã®ã¿ã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
        "\n",
        "æœ¬ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€æ¶ç©ºã®å•†ç¤¾ **ã€Œæ ªå¼ä¼šç¤¾é™æµœå•†äº‹ã€** ã®ç¤¾å†…è¦å®šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã€LangGraph ã‚’ç”¨ã„ã¦æ¤œç´¢ã¨å›ç­”ç”Ÿæˆã®ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè£…ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "8X4RDuIxD3Ml"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfRIEpTMD2wD"
      },
      "outputs": [],
      "source": [
        "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "# langchain-chroma: ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ ChromaDB ã®ãƒ©ãƒƒãƒ‘ãƒ¼\n",
        "# sentence-transformers: ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«\n",
        "!pip install -qU langgraph langchain-openai langchain-community langchain-chroma sentence-transformers termcolor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. ç’°å¢ƒè¨­å®šã¨æ¨è«–ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©\n",
        "\n",
        "RAG ã®ã€Œç”Ÿæˆ (Generate)ã€ãƒ‘ãƒ¼ãƒˆã‚’æ‹…å½“ã™ã‚‹ LLM ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "ã“ã“ã§ã¯ã€OpenRouter çµŒç”±ã§ **`nvidia/nemotron-3-nano-30b-a3b`** ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¸ãˆã‚‰ã‚ŒãŸæ–‡ç« ï¼‰ã®ç†è§£åŠ›ãŒé«˜ãã€æŒ‡ç¤ºã«å¾“ã£ã¦å¿ å®Ÿã«å›ç­”ã™ã‚‹èƒ½åŠ›ã«å„ªã‚Œã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "ã¾ãŸã€API ã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿å‡¦ç†ã«ã¯ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’å®Ÿè£…ã—ã€è¨­å®šæ¼ã‚ŒãŒã‚ã‚‹å ´åˆã«è­¦å‘Šã‚’è¡¨ç¤ºã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "GUFQfG_9E4pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. ç’°å¢ƒè¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
        "import os\n",
        "import sys\n",
        "from google.colab import userdata\n",
        "from termcolor import colored\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# APIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿\n",
        "try:\n",
        "    os.environ[\"OPENROUTER_API_KEY\"] = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "    print(colored(\"OPENROUTER_API_KEY loaded.\", \"green\"))\n",
        "except Exception:\n",
        "    print(colored(\"Error: OPENROUTER_API_KEY not found in Secrets.\", \"red\"))\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«å®šç¾© (å®‰å®šæ€§ã®é«˜ã„ Nemotron ã‚’ä½¿ç”¨)\n",
        "MODEL_NAME = \"nvidia/nemotron-3-nano-30b-a3b\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=MODEL_NAME,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
        "    streaming=True,\n",
        "    model_kwargs={\n",
        "        \"extra_body\": {\n",
        "            \"provider\": {\n",
        "                \"order\": [\"deepinfra\"],\n",
        "                \"allow_fallbacks\": False\n",
        "            }\n",
        "        }\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "spvHx7YsD6EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã¨ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²\n",
        "\n",
        "### ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®šç¾©ã¨å‰å‡¦ç†\n",
        "RAG ã«ãŠã„ã¦ã€é•·ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãã®ã¾ã¾æ‰±ã†ã“ã¨ã¯ã€LLM ã®å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã‚„æ¤œç´¢ç²¾åº¦ã®è¦³ç‚¹ã‹ã‚‰æ¨å¥¨ã•ã‚Œã¾ã›ã‚“ã€‚ãã®ãŸã‚ã€å‰å‡¦ç†ã¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ãªã‚µã‚¤ã‚ºï¼ˆãƒãƒ£ãƒ³ã‚¯ï¼‰ã«åˆ†å‰²ã—ã¾ã™ã€‚\n",
        "\n",
        "ã“ã“ã§ã¯ã€ä»®æƒ³ä¼æ¥­ã€Œæ ªå¼ä¼šç¤¾é™æµœå•†äº‹ã€ã®ç¤¾å†…è¦å®šãƒ‡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã€ãã‚ŒãŒã©ã®ã‚ˆã†ã«åˆ†å‰²ã•ã‚Œã‚‹ã‹ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "PG3eE03bE_VR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from termcolor import colored\n",
        "\n",
        "# æ¤œç´¢å¯¾è±¡ã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®šç¾©\n",
        "rag_source_text = \"\"\"\n",
        "ã€æ ªå¼ä¼šç¤¾é™æµœå•†äº‹ (Shizuhama Trading Co., Ltd.) ç¤¾å†…è¦å®šãƒ»æ¦‚è¦ã€‘\n",
        "\n",
        "[1. ä¼æ¥­æ¦‚è¦]\n",
        "æœ¬ç¤¾ï¼šé™å²¡çœŒé™å²¡å¸‚è‘µåŒºå¾¡å¹¸ç”º 1-1\n",
        "ä»£è¡¨ï¼šå±±ç”° å¥å¤ªéƒ\n",
        "äº‹æ¥­å†…å®¹ï¼š\n",
        "- é™å²¡çœŒç”£èŒ¶è‘‰ã®è¼¸å‡ºã€ãŠã‚ˆã³ç·‘èŒ¶æˆåˆ†ã‚’ä½¿ç”¨ã—ãŸåŒ–ç²§å“é–‹ç™º\n",
        "- EVï¼ˆé›»æ°—è‡ªå‹•è»Šï¼‰å‘ã‘è»½é‡éƒ¨å“ã®èª¿é”ãƒ»å¸å£²\n",
        "- åœ°åŸŸå¯†ç€å‹å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼ï¼ˆå°æ°´åŠ›ç™ºé›»ï¼‰ã®ã‚³ãƒ³ã‚µãƒ«ãƒ†ã‚£ãƒ³ã‚°\n",
        "\n",
        "[2. å‹¤å‹™ä½“ç³»ãƒ»ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯è¦å®š]\n",
        "- åŸºæœ¬å°±æ¥­æ™‚é–“ï¼š9:00 - 18:00\n",
        "- ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹åˆ¶åº¦ï¼šã€Œå¯Œå£«å±±ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹ã€ã‚’å°å…¥ã€‚ã‚³ã‚¢ã‚¿ã‚¤ãƒ ã¯ 11:00 - 14:00 ã¨ã™ã‚‹ã€‚\n",
        "- ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ï¼šå…¨éƒ¨ç½²ã§æ¨å¥¨ã€‚é€±5æ—¥ã®ãƒ•ãƒ«ãƒªãƒ¢ãƒ¼ãƒˆã‚‚å¯ã¨ã™ã‚‹ãŒã€æœˆ1å›ã®ã€Œå…¨ä½“æˆ¦ç•¥ä¼šè­°ã€ã®ã¿å‡ºç¤¾å¿…é ˆã¨ã™ã‚‹ã€‚\n",
        "- ãƒ¯ãƒ¼ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼šä¼Šè±†åŠå³¶ãŠã‚ˆã³æµœåæ¹–ã‚¨ãƒªã‚¢ã®ææºæ–½è¨­ã§ã®å‹¤å‹™ã‚’èªã‚ã‚‹ã€‚\n",
        "\n",
        "[3. å‡ºå¼µãƒ»çµŒè²»è¦å®š]\n",
        "- æ–°å¹¹ç·šï¼šç‰‡é“100kmä»¥ä¸Šã§æŒ‡å®šå¸­åˆ©ç”¨å¯ã€‚å½¹å“¡ä»¥å¤–ã¯ã‚°ãƒªãƒ¼ãƒ³è»Šåˆ©ç”¨ä¸å¯ã€‚\n",
        "- å®¿æ³Šè²»ï¼šå›½å†…ä¸€å¾‹ 10,000å††/æ³Šã€æµ·å¤–ï¼ˆã‚¢ã‚¸ã‚¢ï¼‰15,000å††/æ³Šã€æµ·å¤–ï¼ˆæ¬§ç±³ï¼‰20,000å††/æ³Šã‚’ä¸Šé™ã¨ã™ã‚‹ã€‚\n",
        "- è‡ªå®¶ç”¨è»Šé€šå‹¤ï¼šé™å²¡æœ¬ç¤¾ã¯ä¸å¯ã€‚æµœæ¾æ”¯åº—ã€æ²¼æ´¥å–¶æ¥­æ‰€ã¯è¨±å¯åˆ¶ã¨ã™ã‚‹ã€‚\n",
        "\n",
        "[4. ç‹¬è‡ªã®ç¦åˆ©åšç”Ÿãƒ»ä¼‘æš‡]\n",
        "- èŒ¶æ‘˜ã¿ä¼‘æš‡ï¼šæ¯å¹´4æœˆä¸‹æ—¬ã€œ5æœˆã€å®Ÿå®¶ã¾ãŸã¯å¥‘ç´„è¾²åœ’ã§ã®èŒ¶æ‘˜ã¿ã‚’æ‰‹ä¼ã†ç¤¾å“¡ã«æœ€å¤§3æ—¥é–“ã®ç‰¹åˆ¥æœ‰çµ¦ã‚’ä»˜ä¸ã™ã‚‹ã€‚\n",
        "- ãƒ—ãƒ©ãƒ¢ãƒ‡ãƒ«è£½ä½œä¼‘æš‡ï¼šã‚‚ã®ã¥ãã‚Šæ–‡åŒ–ã®ç†è§£ä¿ƒé€²ã®ãŸã‚ã€å¹´1å›ã€æ¨¡å‹è£½ä½œã‚¤ãƒ™ãƒ³ãƒˆå‚åŠ æ—¥ã‚’å…¬ä¼‘æ‰±ã„ã¨ã™ã‚‹ã€‚\n",
        "- ã‚µã‚¦ãƒŠæ‰‹å½“ï¼šå¥åº·å¢—é€²ã®ãŸã‚ã€æœˆé¡3,000å††ã¾ã§ã‚µã‚¦ãƒŠåˆ©ç”¨æ–™ã‚’è£œåŠ©ã™ã‚‹ï¼ˆã€Œã—ãã˜ã€ç­‰ã®åˆ©ç”¨ã‚’æ¨å¥¨ï¼‰ã€‚\n",
        "\"\"\"\n",
        "\n",
        "print(colored(f\"åŸç¨¿ãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—æ•°: {len(rag_source_text)} æ–‡å­—\", \"cyan\"))\n",
        "\n",
        "# ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå¯è¦–åŒ–ï¼‰\n",
        "# å®Ÿéš›ã«ã¯ LangChain ã® Splitter ã‚’ä½¿ã„ã¾ã™ãŒã€ã“ã“ã§ã¯æ§‹é€ ç†è§£ã®ãŸã‚ã«ç°¡æ˜“è¡¨ç¤ºã—ã¾ã™\n",
        "sections = rag_source_text.strip().split('\\n\\n')\n",
        "print(colored(\"\\n--- ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚¤ãƒ¡ãƒ¼ã‚¸ (è«–ç†çš„ãªã¾ã¨ã¾ã‚Šã§ã®åˆ†å‰²ä¾‹) ---\", \"yellow\"))\n",
        "for i, section in enumerate(sections):\n",
        "    preview = textwrap.shorten(section.replace('\\n', ' '), width=60, placeholder=\"...\")\n",
        "    print(f\"Chunk {i+1}: {preview}\")"
      ],
      "metadata": {
        "id": "CclSbi8eD9IR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨æ¤œç´¢ç©ºé–“ã®æ§‹ç¯‰\n",
        "\n",
        "### ğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (Vector Store) ã®ä½œæˆ\n",
        "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã¯ãƒ†ã‚­ã‚¹ãƒˆã®æ„å‘³ã‚’ç›´æ¥ç†è§£ã§ãã¾ã›ã‚“ã€‚ãã“ã§ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•°ç™¾ã€œæ•°åƒæ¬¡å…ƒã®æ•°å€¤ã®åˆ—ï¼ˆãƒ™ã‚¯ãƒˆãƒ«ï¼‰ã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã‚Œã‚’ **Embedding (åŸ‹ã‚è¾¼ã¿)** ã¨å‘¼ã³ã¾ã™ã€‚\n",
        "\n",
        "RAG ã«ãŠã‘ã‚‹ã€Œæ¤œç´¢ã€ã¯ã€ä»¥ä¸‹ã®æ•°å­¦çš„ãªæ“ä½œã«åŸºã¥ãã¾ã™ã€‚\n",
        "\n",
        "1.  ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ $D$ ã‚’ãƒ™ã‚¯ãƒˆãƒ« $\\vec{d}$ ã«å¤‰æ›ã—ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ã™ã‚‹ã€‚\n",
        "2.  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå• $Q$ ã‚’åŒã˜ãƒ¢ãƒ‡ãƒ«ã§ãƒ™ã‚¯ãƒˆãƒ« $\\vec{q}$ ã«å¤‰æ›ã™ã‚‹ã€‚\n",
        "3.  ãƒ™ã‚¯ãƒˆãƒ«ç©ºé–“ä¸Šã§ã€$\\vec{q}$ ã¨æœ€ã‚‚è·é›¢ãŒè¿‘ã„ï¼ˆè§’åº¦ãŒä¼¼ã¦ã„ã‚‹ï¼‰$\\vec{d}$ ã‚’æŠ½å‡ºã™ã‚‹ã€‚\n",
        "\n",
        "é¡ä¼¼åº¦ã®è¨ˆç®—ã«ã¯ã€ä¸€èˆ¬çš„ã« **ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ (Cosine Similarity)** ãŒç”¨ã„ã‚‰ã‚Œã¾ã™ã€‚\n",
        "\n",
        "$$\\text{similarity} = \\cos(\\theta) = \\frac{\\vec{q} \\cdot \\vec{d}}{\\|\\vec{q}\\| \\|\\vec{d}\\|}$$\n",
        "\n",
        "ä»¥ä¸‹ã§ã¯ã€å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "d4DF9QmKFIbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# (1) ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰² (Chunking)\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,    # 1ã¤ã®ãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—æ•°\n",
        "    chunk_overlap=50   # æ–‡è„ˆã‚’ç¶­æŒã™ã‚‹ãŸã‚ã®é‡è¤‡å¹…\n",
        ")\n",
        "docs = splitter.split_documents([Document(page_content=rag_source_text)])\n",
        "\n",
        "print(colored(f\"åˆ†å‰²ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°: {len(docs)} ä»¶\", \"green\"))\n",
        "\n",
        "# (2) ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
        "print(\"Embedding ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
        "\n",
        "# (3) DBã¸ã®ä¿å­˜ (é‡è¤‡é˜²æ­¢å‡¦ç†ä»˜ã)\n",
        "# ä¸€åº¦DBã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã€ã‚‚ã—å¤ã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å‰Šé™¤ã—ã¦ã‹ã‚‰å†ç™»éŒ²ã—ã¾ã™\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"shizuhama_regulations\",\n",
        "    embedding_function=embeddings,\n",
        "    # æ°¸ç¶šåŒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®šã—ãªã„å ´åˆã¯ãƒ¡ãƒ¢ãƒªä¸Šã§å‹•ä½œã—ã¾ã™ãŒã€\n",
        "    # ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§ã®é‡è¤‡ã‚’é˜²ããŸã‚ã«æ˜ç¤ºçš„ãªåˆæœŸåŒ–ã‚’è¡Œã„ã¾ã™ã€‚\n",
        ")\n",
        "\n",
        "# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®å…¨å‰Šé™¤ï¼ˆãƒªã‚»ãƒƒãƒˆï¼‰\n",
        "try:\n",
        "    vector_store.delete_collection()\n",
        "    # å‰Šé™¤å¾Œã«å†å®šç¾©\n",
        "    vector_store = Chroma(\n",
        "        collection_name=\"shizuhama_regulations\",\n",
        "        embedding_function=embeddings,\n",
        "    )\n",
        "except:\n",
        "    pass # åˆå›å®Ÿè¡Œæ™‚ãªã©ã€å‰Šé™¤å¯¾è±¡ãŒãªã„å ´åˆã¯ã‚¹ãƒ«ãƒ¼\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ \n",
        "vector_store.add_documents(docs)\n",
        "\n",
        "print(colored(\"ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰å®Œäº†ï¼ˆãƒªã‚»ãƒƒãƒˆæ¸ˆã¿ï¼‰ã€‚\", \"green\"))"
      ],
      "metadata": {
        "id": "h5mxcxnXEIx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ” æ¤œç´¢ç²¾åº¦ã®æ¤œè¨¼ (Retrieval Check)\n",
        "\n",
        "RAG ã®å›ç­”ç²¾åº¦ã¯ã€Œæ¤œç´¢ç²¾åº¦ã€ã«ä¾å­˜ã—ã¾ã™ã€‚LLM ã«æ¸¡ã™å‰ã«ã€æ„å›³ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒæ­£ã—ãæ¤œç´¢ï¼ˆRetrieveï¼‰ã§ãã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã¯é‡è¦ã§ã™ã€‚\n",
        "\n",
        "ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’å®Ÿè¡Œã™ã‚‹ã¨å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚è³ªå•ã‚’å…¥åŠ›ã—ã€å®Ÿéš›ã«ã©ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒãƒ’ãƒƒãƒˆã—ã€ãã® **ã‚¹ã‚³ã‚¢ (è·é›¢)** ãŒã©ã‚Œãã‚‰ã„ã‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ã‚¹ã‚³ã‚¢ãŒä½ã„ï¼ˆè·é›¢ãŒé ã„ï¼‰å ´åˆã€LLM ã¯æ­£ã—ã„æ ¹æ‹ ã‚’å¾—ã‚‰ã‚Œã¾ã›ã‚“ã€‚\n",
        "\n",
        "* **æ¤œè¨¼ç”¨ã‚¯ã‚¨ãƒªä¾‹**:\n",
        "    * `ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹åˆ¶åº¦ã«ã¤ã„ã¦`\n",
        "    * `æ–°å¹¹ç·šã®åˆ©ç”¨è¦å®š`\n",
        "    * `æ±äº¬æ”¯ç¤¾ã®ä½æ‰€` ï¼ˆå­˜åœ¨ã—ãªã„æƒ…å ±ã®ç¢ºèªï¼‰"
      ],
      "metadata": {
        "id": "P3g_invXQ9xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title æ¤œç´¢å®Ÿé¨“ãƒ•ã‚©ãƒ¼ãƒ \n",
        "# @markdown æ¤œç´¢ã—ãŸã„è³ªå•ã‚’å…¥åŠ›ã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "query = \"æ±äº¬ã¸ã®å‡ºå¼µã®ã¨ãã¯ã€æ—…è²»ãŒæ”¯å‡ºã•ã‚Œã¾ã™ã‹ï¼Ÿ\" # @param {type:\"string\"}\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# é¡ä¼¼åº¦æ¤œç´¢ã®å®Ÿè¡Œ (ã‚¹ã‚³ã‚¢ä»˜ã)\n",
        "# k=3 ã¯ä¸Šä½3ä»¶ã‚’å–å¾—ã™ã‚‹ã¨ã„ã†æ„å‘³ã§ã™\n",
        "results_with_score = vector_store.similarity_search_with_score(query, k=3)\n",
        "\n",
        "print(colored(f\"æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}\", \"yellow\", attrs=[\"bold\"]))\n",
        "print(\"-\" * 60)\n",
        "\n",
        "scores = []\n",
        "contents = []\n",
        "\n",
        "for i, (doc, score) in enumerate(results_with_score):\n",
        "    # Chroma ã® score ã¯ L2 distance (è·é›¢) ãªã®ã§ã€å€¤ãŒå°ã•ã„ã»ã©é¡ä¼¼åº¦ãŒé«˜ã„\n",
        "    # (ä¸€èˆ¬çš„ãªã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã¨ã¯é€†ã®æŒ‡æ¨™ã§ã‚ã‚‹ã“ã¨ã«æ³¨æ„)\n",
        "    color = \"cyan\" if i == 0 else \"white\"\n",
        "    print(colored(f\"ã€Rank {i+1}ã€‘ Distance Score: {score:.4f}\", color, attrs=[\"bold\"]))\n",
        "    print(f\"Content: {doc.page_content.replace(chr(10), ' ')}\") # æ”¹è¡Œã‚’é™¤å»ã—ã¦è¡¨ç¤º\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    scores.append(score)\n",
        "    contents.append(f\"Rank {i+1}\")\n",
        "\n",
        "# è·é›¢ã‚¹ã‚³ã‚¢ã®å¯è¦–åŒ–\n",
        "if len(scores) > 0:\n",
        "    plt.figure(figsize=(8, 2))\n",
        "    plt.barh(contents[::-1], scores[::-1], color='skyblue')\n",
        "    plt.xlabel('L2 Distance (Lower is Better)')\n",
        "    # æ—¥æœ¬èªæ–‡å­—åŒ–ã‘å›é¿ã®ãŸã‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‹±èªå›ºå®šã«å¤‰æ›´\n",
        "    plt.title('Similarity Scores')\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bFomMg_hQ_EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. LangGraph ã«ã‚ˆã‚‹ RAG ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰\n",
        "\n",
        "### â›“ï¸ ãƒãƒ¼ãƒ‰ã¨ã‚°ãƒ©ãƒ•ã®å®šç¾©\n",
        "æ¤œç´¢ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼ˆContextï¼‰ã‚’ LLM ã«æ¸¡ã—ã€å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ãƒ­ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
        "å˜ç´”ãªé–¢æ•°å‘¼ã³å‡ºã—ã§ã¯ãªãã€LangGraph ã‚’ç”¨ã„ã¦ã€ŒçŠ¶æ…‹ (State)ã€ã¨ã€Œãƒãƒ¼ãƒ‰ (Node)ã€ã«ã‚ˆã‚‹ã‚°ãƒ©ãƒ•æ§‹é€ ã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚\n",
        "\n",
        "**ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼:**\n",
        "1.  **Start**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå• `question` ãŒå…¥åŠ›ã•ã‚Œã‚‹ã€‚\n",
        "2.  **Retrieve Node**:\n",
        "    * `question` ã‚’å…ƒã« Vector DB ã‚’æ¤œç´¢ã€‚\n",
        "    * çµæœã‚’æ–‡å­—åˆ—ã¨ã—ã¦çµåˆã—ã€`context` ã«ä¿å­˜ã€‚\n",
        "    * **ãƒã‚¤ãƒ³ãƒˆ**: ã“ã“ã§æ¤œç´¢ã•ã‚ŒãŸä¸­èº«ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚\n",
        "3.  **Generate Node**:\n",
        "    * `question` ã¨ `context` ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«åŸ‹ã‚è¾¼ã‚€ã€‚\n",
        "    * LLM ãŒ `answer` ã‚’ç”Ÿæˆã€‚\n",
        "4.  **End**: æœ€çµ‚çš„ãª `answer` ã‚’å‡ºåŠ›ã€‚"
      ],
      "metadata": {
        "id": "XpJYXxnNFMfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# --- 1. State (çŠ¶æ…‹) ã®å®šç¾© ---\n",
        "# å„ãƒãƒ¼ãƒ‰é–“ã§å—ã‘æ¸¡ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚­ãƒ¼ãƒ\n",
        "class RagState(TypedDict):\n",
        "    question: str   # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›\n",
        "    context: str    # æ¤œç´¢ã•ã‚ŒãŸæƒ…å ±ï¼ˆRetrieveãƒãƒ¼ãƒ‰ã§æ›´æ–°ï¼‰\n",
        "    answer: str     # LLMã®å›ç­”ï¼ˆGenerateãƒãƒ¼ãƒ‰ã§æ›´æ–°ï¼‰\n",
        "\n",
        "# --- 2. ãƒãƒ¼ãƒ‰é–¢æ•°ã®å®šç¾© ---\n",
        "\n",
        "def retrieve_node(state: RagState):\n",
        "    \"\"\"æ¤œç´¢ã‚’å®Ÿè¡Œã—ã€ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ãƒãƒ¼ãƒ‰\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    print(colored(f\"\\n[Process 1] æ–‡æ›¸æ¤œç´¢ã‚’å®Ÿè¡Œä¸­... Query: {question}\", \"grey\"))\n",
        "\n",
        "    # ãƒ™ã‚¯ãƒˆãƒ«DBã‚’Retrieverã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})\n",
        "    found_docs = retriever.invoke(question)\n",
        "\n",
        "    # è¤‡æ•°ã®æ¤œç´¢çµæœã‚’ä¸€ã¤ã®æ–‡å­—åˆ—ã«çµåˆ\n",
        "    context_text = \"\\n\\n\".join([d.page_content for d in found_docs])\n",
        "\n",
        "    # ã€é‡è¦ã€‘LLMã«æ¸¡ã•ã‚Œã‚‹ç”Ÿã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤ºï¼ˆé€”ä¸­çµŒéã®å¯è¦–åŒ–ï¼‰\n",
        "    print(colored(f\"[Result 1] æ¤œç´¢ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ:\\n{'-'*20}\\n{context_text}\\n{'-'*20}\", \"blue\"))\n",
        "\n",
        "    return {\"context\": context_text}\n",
        "\n",
        "def generate_node(state: RagState):\n",
        "    \"\"\"ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆã™ã‚‹ãƒãƒ¼ãƒ‰\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    print(colored(f\"[Process 2] LLMã«ã‚ˆã‚‹å›ç­”ç”Ÿæˆã‚’å®Ÿè¡Œä¸­...\", \"grey\"))\n",
        "\n",
        "    # RAGç‰¹æœ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼‰\n",
        "    # Context (äº‹å®Ÿ) ã¨ Question (è³ªå•) ã‚’æ˜ç¢ºã«åŒºåˆ¥ã—ã¦å…¥åŠ›ã—ã¾ã™\n",
        "    prompt = f\"\"\"\n",
        "    ã‚ãªãŸã¯æ ªå¼ä¼šç¤¾é™æµœå•†äº‹ã®ç¤¾å†…AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚\n",
        "    ä»¥ä¸‹ã®ã€ç¤¾å†…è¦å®šã€‘ã®ã¿ã«åŸºã¥ã„ã¦ã€ç¤¾å“¡ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "    è¦å®šã«è¨˜è¼‰ãŒãªã„å ´åˆã¯ã€æ­£ç›´ã«ã€Œè¦å®šã«è¨˜è¼‰ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚\n",
        "    è‡ªèº«ã®çŸ¥è­˜ã§è£œå®Œã—ãŸã‚Šã€æƒ…å ±ã‚’æé€ ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚\n",
        "\n",
        "    ã€ç¤¾å†…è¦å®šã€‘\n",
        "    {context}\n",
        "\n",
        "    ã€ç¤¾å“¡ã®è³ªå•ã€‘\n",
        "    {question}\n",
        "    \"\"\"\n",
        "\n",
        "    # ãƒ¢ãƒ‡ãƒ«å®šç¾©ã¯ç¬¬2ç« ã§ä½œæˆã—ãŸ `llm` ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½¿ç”¨\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    return {\"answer\": response.content}\n",
        "\n",
        "# --- 3. ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰ ---\n",
        "workflow = StateGraph(RagState)\n",
        "\n",
        "# ãƒãƒ¼ãƒ‰ã®ç™»éŒ²\n",
        "workflow.add_node(\"retrieve\", retrieve_node)\n",
        "workflow.add_node(\"generate\", generate_node)\n",
        "\n",
        "# ã‚¨ãƒƒã‚¸ï¼ˆæ¥ç¶šï¼‰ã®å®šç¾©\n",
        "workflow.add_edge(START, \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«\n",
        "app = workflow.compile()\n",
        "print(colored(\"RAG ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰å®Œäº†ã€‚\", \"green\"))\n",
        "\n",
        "# ã‚°ãƒ©ãƒ•æ§‹é€ ã®å¯è¦–åŒ– (Mermaidè¨˜æ³•)\n",
        "try:\n",
        "    from IPython.display import Image, display\n",
        "    display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    print(\"Graph visualization skipped (requires graphviz).\")"
      ],
      "metadata": {
        "id": "_yONDD4hFOCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. ã‚·ã‚¹ãƒ†ãƒ ã®ç·åˆå‹•ä½œç¢ºèª\n",
        "\n",
        "### âœ… ã‚·ãƒŠãƒªã‚ªåˆ¥ãƒ†ã‚¹ãƒˆ\n",
        "æ§‹ç¯‰ã—ãŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã‚’é€šã—ã¦è³ªå•ã‚’è¡Œã„ã¾ã™ã€‚\n",
        "RAG ãŒé©åˆ‡ã«æ©Ÿèƒ½ã—ã¦ã„ã‚‹ã‹ã€ä»¥ä¸‹ã®è¦³ç‚¹ã§ç¢ºèªã—ã¾ã™ã€‚\n",
        "\n",
        "1.  **Fact Retrieval**: è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹äº‹å®Ÿã‚’æ­£ã—ãå¼•ãå‡ºã›ã‚‹ã‹ã€‚\n",
        "2.  **Synthesis**: è¤‡æ•°ã®ãƒãƒ£ãƒ³ã‚¯ã«ã¾ãŸãŒã‚‹æƒ…å ±ã‚’çµ±åˆã§ãã‚‹ã‹ã€‚\n",
        "3.  **Negative Constraint**: è¨˜è¿°ã•ã‚Œã¦ã„ãªã„æƒ…å ±ã«å¯¾ã—ã¦ã€Œåˆ†ã‹ã‚‰ãªã„ã€ã¨ç­”ãˆã‚‰ã‚Œã‚‹ã‹ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã®æŠ‘åˆ¶ï¼‰ã€‚"
      ],
      "metadata": {
        "id": "W_hgQM_VFdlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_bot(question):\n",
        "    \"\"\"RAGã‚·ã‚¹ãƒ†ãƒ ã«è³ªå•ã‚’æŠ•ã’ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°\"\"\"\n",
        "    inputs = {\"question\": question, \"context\": \"\", \"answer\": \"\"}\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(colored(f\"Q. {question}\", \"yellow\", attrs=[\"bold\"]))\n",
        "\n",
        "    # ã‚°ãƒ©ãƒ•ã®å®Ÿè¡Œ\n",
        "    # stream=False ã§ä¸€æ‹¬å®Ÿè¡Œçµæœã‚’å–å¾—\n",
        "    result = app.invoke(inputs)\n",
        "\n",
        "    print(colored(\"\\n[Final Answer] AIã®å›ç­”:\", \"cyan\", attrs=[\"bold\"]))\n",
        "    print(result[\"answer\"])\n",
        "    print(\"=\" * 80 + \"\\n\")\n",
        "\n",
        "# --- æ¤œè¨¼ã‚·ãƒŠãƒªã‚ª ---\n",
        "\n",
        "# 1. å˜ç´”ãªäº‹å®Ÿç¢ºèª\n",
        "ask_bot(\"ãƒ•ãƒ¬ãƒƒã‚¯ã‚¹åˆ¶åº¦ã®ã‚³ã‚¢ã‚¿ã‚¤ãƒ ã‚’æ•™ãˆã¦\")\n",
        "\n",
        "# 2. è¤‡æ•°ã®æƒ…å ±ãŒå¿…è¦ãªè³ªå•ï¼ˆä¼‘æš‡åˆ¶åº¦ï¼‰\n",
        "ask_bot(\"ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªä¼‘æš‡åˆ¶åº¦ã«ã¯ã©ã®ã‚ˆã†ãªã‚‚ã®ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\")\n",
        "\n",
        "# 3. è¦å®šå¤–ã®è³ªå•ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æŠ‘åˆ¶ãƒ†ã‚¹ãƒˆï¼‰\n",
        "ask_bot(\"å¤§é˜ªæ”¯åº—ã®ä½æ‰€ã¯ã©ã“ã§ã™ã‹ï¼Ÿ\")"
      ],
      "metadata": {
        "id": "ctErjHsMFeyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. ğŸ“ ã€æ¼”ç¿’ã€‘PDFãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ãŸRAGã‚·ã‚¹ãƒ†ãƒ ã®æ§‹ç¯‰\n",
        "\n",
        "ã“ã“ã¾ã§ã®å­¦ç¿’å†…å®¹ã‚’å¿œç”¨ã—ã€å®Ÿéš›ã® PDF ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè«–æ–‡ã€ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€å¥‘ç´„æ›¸ãªã©ï¼‰ã‚’çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã¨ã™ã‚‹æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
        "å®Ÿå‹™ã«ãŠã„ã¦ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒç¶ºéº—ãªæ–‡å­—åˆ—ã§ç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã¯ç¨€ã§ã€PDF ã‚„ Word ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ãŒå¿…é ˆã¨ãªã‚Šã¾ã™ã€‚\n",
        "\n",
        "### ğŸ“¦ 1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æº–å‚™ã¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
        "PDF ã®èª­ã¿è¾¼ã¿ã«ã¯ `pypdf` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã€æ‰‹å…ƒã® PDF ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "â€» ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã€Webä¸Šã®å…¬é–‹PDFãªã©ã‚’é©å½“ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "WPq1mkJ7WDO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDFå‡¦ç†ç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
        "!pip install -qU pypdf\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "from termcolor import colored\n",
        "\n",
        "print(colored(\"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„...\", \"cyan\"))\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã®å‘¼ã³å‡ºã—\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾—\n",
        "if uploaded:\n",
        "    pdf_file_name = list(uploaded.keys())[0]\n",
        "    print(colored(f\"\\nãƒ•ã‚¡ã‚¤ãƒ« '{pdf_file_name}' ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\", \"green\"))\n",
        "else:\n",
        "    print(colored(\"\\nãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\", \"red\"))\n",
        "    pdf_file_name = None"
      ],
      "metadata": {
        "id": "0olJQICYWE1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ§  2. æ¼”ç¿’ï¼šãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ (ç©´åŸ‹ã‚)\n",
        "\n",
        "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸ PDF ã‚’æ¤œç´¢å¯èƒ½ãªãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã® `â– â– â– ` ã®éƒ¨åˆ†ã‚’åŸ‹ã‚ã¦ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’å®Œæˆã•ã›ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "#### ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ä½¿ç”¨ã™ã‚‹ä¸»è¦ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰\n",
        "\n",
        "1.  **`PyPDFLoader`**: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ PDF ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚`load()` ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã™ã€‚\n",
        "2.  **`RecursiveCharacterTextSplitter`**: é•·ã„æ–‡ç« ã‚’ã€æ–‡è„ˆã‚’è€ƒæ…®ã—ã¤ã¤é©åˆ‡ãªé•·ã•ã«åˆ†å‰²ã™ã‚‹ã‚¯ãƒ©ã‚¹ã§ã™ã€‚\n",
        "3.  **`Chroma.from_documents`**:\n",
        "    * **æ©Ÿèƒ½**: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆEmbeddingï¼‰ã‚’å—ã‘å–ã‚Šã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™ã€‚\n",
        "    * **å¼•æ•°**: `documents`ï¼ˆåˆ†å‰²ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆï¼‰, `embedding`ï¼ˆåŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ï¼‰\n",
        "    * **å½¹å‰²**: ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆã‚’ä¸€æ‹¬ã§è¡Œã†ä¾¿åˆ©ãªãƒ¡ã‚½ãƒƒãƒ‰ã§ã™ã€‚"
      ],
      "metadata": {
        "id": "ONvCYUFfWG8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "# ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ\n",
        "if pdf_file_name:\n",
        "    print(f\"å‡¦ç†å¯¾è±¡: {pdf_file_name}\")\n",
        "\n",
        "    # 1. PDFãƒ­ãƒ¼ãƒ€ãƒ¼ã®åˆæœŸåŒ–ã¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰\n",
        "    loader = PyPDFLoader(pdf_file_name)\n",
        "    raw_docs = loader.load()\n",
        "    print(f\"ãƒ­ãƒ¼ãƒ‰å®Œäº†: {len(raw_docs)} ãƒšãƒ¼ã‚¸\")\n",
        "\n",
        "\n",
        "    # 2. ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²å™¨ (Splitter) ã®å®šç¾© [æ¼”ç¿’]\n",
        "    # é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã™ã‚‹ã‚¯ãƒ©ã‚¹ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "    # ã‚¯ãƒ©ã‚¹åã¯ Recursive... ã§å§‹ã¾ã‚Šã¾ã™ã€‚\n",
        "    text_splitter = â– â– â– (\n",
        "        chunk_size=300,    # 1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã®æ–‡å­—æ•°\n",
        "        chunk_overlap=50   # é‡è¤‡ã•ã›ã‚‹æ–‡å­—æ•°\n",
        "    )\n",
        "\n",
        "    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åˆ†å‰²å®Ÿè¡Œ\n",
        "    pdf_docs = text_splitter.split_documents(raw_docs)\n",
        "    print(f\"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²å®Œäº†: {len(pdf_docs)} ä»¶\")\n",
        "\n",
        "\n",
        "    # 3. åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™\n",
        "    # (å‰ã®ç« ã¨åŒã˜ multilingual-e5-large ã‚’ä½¿ç”¨ã—ã¾ã™)\n",
        "    print(\"Embedding ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large\")\n",
        "\n",
        "\n",
        "    # 4. ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ§‹ç¯‰ [æ¼”ç¿’]\n",
        "    # åˆ†å‰²ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ(pdf_docs)ã¨åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«(embeddings)ã‚’ä½¿ã£ã¦DBã‚’ä½œæˆã—ã¾ã™ã€‚\n",
        "    # Chroma ã®ã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ from_... ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "    print(\"ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚’å®Ÿè¡Œä¸­...\")\n",
        "\n",
        "    pdf_vector_store = Chroma.â– â– â– (\n",
        "        documents=â– â– â– ,\n",
        "        embedding=â– â– â– \n",
        "    )\n",
        "\n",
        "    print(colored(\"PDFãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚\", \"green\"))\n",
        "\n",
        "else:\n",
        "    print(colored(\"ã‚¨ãƒ©ãƒ¼: PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å‰ã®ã‚»ãƒ«ã§ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚\", \"red\"))"
      ],
      "metadata": {
        "id": "8wriSlryWKMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ğŸ’¬ 3. æ¤œç´¢ãƒ†ã‚¹ãƒˆ\n",
        "\n",
        "æ§‹ç¯‰ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (`pdf_vector_store`) ã«å¯¾ã—ã¦æ¤œç´¢ã‚’è¡Œã„ã€PDF ã®å†…å®¹ãŒæ­£ã—ãå–å¾—ã§ãã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚\n",
        "ã“ã“ã§ã¯ RAG ã®å…¨ãƒ•ãƒ­ãƒ¼ï¼ˆç”Ÿæˆã¾ã§ï¼‰ã§ã¯ãªãã€æœ€ã‚‚é‡è¦ãªã€Œæ¤œç´¢ï¼ˆRetrievalï¼‰ã€éƒ¨åˆ†ã‚’æ¤œè¨¼ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "f358sCtsWLa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title æ¤œç´¢ãƒ†ã‚¹ãƒˆãƒ•ã‚©ãƒ¼ãƒ \n",
        "# @markdown PDFã®å†…å®¹ã«é–¢ã™ã‚‹è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "query_for_pdf = \"\\u3053\\u306EPDF\\u306E\\u8981\\u70B9\\u3092\\u6559\\u3048\\u3066\" # @param {type:\"string\"}\n",
        "\n",
        "if 'pdf_vector_store' in globals() and pdf_file_name:\n",
        "    print(colored(f\"Q. {query_for_pdf}\", \"yellow\", attrs=[\"bold\"]))\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # é¡ä¼¼åº¦æ¤œç´¢ã®å®Ÿè¡Œ\n",
        "    results = pdf_vector_store.similarity_search(query_for_pdf, k=3)\n",
        "\n",
        "    for i, doc in enumerate(results):\n",
        "        print(colored(f\"ã€Rank {i+1}ã€‘ (Page {doc.metadata.get('page', '?')})\", \"cyan\"))\n",
        "        print(doc.page_content.replace(\"\\n\", \" \")[:200] + \"...\") # é•·ã„ã®ã§å…ˆé ­200æ–‡å­—ã‚’è¡¨ç¤º\n",
        "        print(\"-\" * 60)\n",
        "else:\n",
        "    print(\"PDFãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒæ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\")"
      ],
      "metadata": {
        "id": "OY9q6qE2WL5p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}