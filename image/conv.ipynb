{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmHOMyU3iI9sgk7HQap58B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/image/conv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 画像処理"
      ],
      "metadata": {
        "id": "MN2ezyL_I-Qd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像の表現\n",
        "\n",
        "画像はコンピュータ上では，画像を格子状に区切った **画素** の配列として表現されます。一般的な2次元画像の場合、画素はピクセル (pixel) ともよばれます。\n",
        "\n",
        "この課題では2次元のカラー画像を扱います。色は通常、赤(R)、緑(G)、青(B) の3つの値で表され、それぞれが 0以上 255 以下の整数になります。つまり、1つの画素を表すのに3つの値が必要です。"
      ],
      "metadata": {
        "id": "dI2kooDsKdMk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 画像の読み込みとnumpy配列への変換の解説\n",
        "\n",
        "PythonのPIL（Pillow）ライブラリを使って画像を読み込み、numpy配列に変換します。\n",
        "\n",
        "サンプル画像をダウンロードして開いてみましょう。"
      ],
      "metadata": {
        "id": "kga3E7fkLBUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ファイルをダウンロードするライブラリ\n",
        "import urllib.request\n",
        "\n",
        "# サンプル画像（富士山の写真，パブリックドメイン）\n",
        "image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/MtFuji_FujiCity.jpg/320px-MtFuji_FujiCity.jpg'\n",
        "\n",
        "# 画像をダウンロードして保存するパス\n",
        "image_path = '/content/sample_image.jpg'\n",
        "\n",
        "# URLから画像をダウンロードして保存\n",
        "urllib.request.urlretrieve(image_url, image_path)"
      ],
      "metadata": {
        "id": "HyEHhsRkK9L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nrDcc85I7OI"
      },
      "outputs": [],
      "source": [
        "from PIL import Image              # PNG, JPG などのファイル形式を扱うライブラリ\n",
        "import matplotlib.pyplot as plt    # 画像やグラフなどの可視化を行うライブラリ\n",
        "import numpy as np                 # 多次元配列を扱うライブラリ\n",
        "\n",
        "# ダウンロードした画像を読み込む\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# numpy配列に変換\n",
        "img_array = np.array(img)\n",
        "\n",
        "# 画像の表示\n",
        "plt.figure(figsize=(img_array.shape[1] / 50, img_array.shape[0] / 50))\n",
        "plt.imshow(img_array)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像の次元とチャネル\n",
        "\n",
        "numpy配列となった画像の形状を確認します。\n",
        "\n",
        "カラー画像の場合、通常は (高さ, 幅, チャネル数) の形状を持ちます。\n",
        "この場合、RGBカラー画像ではチャネル数は3です。"
      ],
      "metadata": {
        "id": "sfa2p5MKOCUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Image shape:\", img_array.shape)  # 画像の形状を出力（例：(H, W, C)）\n",
        "print(\"Image dtype:\", img_array.dtype)  # データ型を出力（例：uint8など）"
      ],
      "metadata": {
        "id": "AySnoLWkKbpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グレースケールへの変換\n",
        "\n",
        "説明を単純にするため、グレースケールに変換してみます。"
      ],
      "metadata": {
        "id": "FiYquBRUPyNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gray_img = img.convert('L')\n",
        "gray_array = np.array(gray_img)\n",
        "\n",
        "# 画像の表示\n",
        "plt.figure(figsize=(gray_array.shape[1] / 50, gray_array.shape[0] / 50))\n",
        "plt.imshow(gray_array, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jXYw9Q7ZPxsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **課題１**\n",
        "\n",
        "- 元の画像は＿＿次元、グレースケールに変換した後は＿＿＿次元になりました。\n",
        "\n",
        "- 現在（グレースケール）、各画素は黒＿＿＿～白＿＿＿までの 256 段階の整数ひとつで表されています。"
      ],
      "metadata": {
        "id": "jpdCZp13mj3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像からの特徴抽出\n",
        "\n",
        "ここからは、画像内の重要なパターンや情報を抽出し、その情報を元に画像の理解や処理を行っていきます。\n",
        "\n",
        "特徴抽出とは、画像処理において重要な概念であり、画像から意味のある情報や特定のパターンを取り出すプロセスです。通常、画像はピクセル（画素）の集合として表現されますが、これだけでは画像に含まれる有用な情報を直接抽出するのは難しいです。特徴抽出は、画像内の局所的な領域やパターンを捉え、そのパターンが画像全体でどのように分布しているかを示す数値化された表現を生成します。\n",
        "\n",
        "具体的には、特徴抽出はフィルタやカーネルを用いた畳み込み演算などで行われます。畳み込みフィルタは、画像上でスライドさせながら局所的な領域とフィルタの積和を計算し、その結果を新しい画像（特徴マップ）として出力します。例えば、エッジ検出のためのフィルタでは、画像の境界や変化の大きな領域を強調し、その情報を抽出します。\n",
        "\n",
        "特徴抽出の目的は、画像の理解や処理を行うための基盤を提供することです。これにより、画像内の重要な情報を抽出し、後段の処理や解析に活用することが可能となります。"
      ],
      "metadata": {
        "id": "jd-H_7ntQI4a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 畳み込み\n",
        "\n",
        "畳み込み（Convolution）は、信号処理や画像処理の基本的な演算であり、最もよく使われる手法のひとつです。\n",
        "\n",
        "画像処理においては、畳み込み演算は画像上でフィルタ（カーネル）スライドさせて行います。この過程で、畳み込まれる画像領域とフィルタの対応する部分の要素積和が求められます。畳み込みはカーネルを変えることで、画像のフィルタリング、エッジ検出など、いろいろな使い方ができます。\n",
        "\n",
        "<a title=\"Michael Plotke, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:2D_Convolution_Animation.gif\"><img width=\"256\" alt=\"2D Convolution Animation\" src=\"https://upload.wikimedia.org/wikipedia/commons/1/19/2D_Convolution_Animation.gif?20130203224852\"></a>\n",
        "\n",
        "#### カーネル（微分によるエッジ強調，ぼかし等）\n",
        "\n",
        "カーネルは、畳み込み演算で使用される重要な要素です。**カーネル** は小さな行列（フィルタ）で、畳み込み処理の際に画像上でスライドされます。\n",
        "\n",
        "畳み込みの目的に応じて異なるカーネルが使われます．エッジ検出やぼかし、シャープネスの強調などを行うものが代表的です。\n",
        "\n",
        "- エッジ強調を行う場合、横方向や縦方向の微分を計算します。<br>\n",
        "[うさぎでもわかる画像処理 Part03 画像処理とフィルタ1](https://www.momoyama-usagi.com/entry/info-img03#2_1)（工業大学生ももやまのうさぎ塾）\n",
        " - 横方向\n",
        "\n",
        " <style>\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "  }\n",
        "  .table-container {\n",
        "    display: flex;\n",
        "    justify-content: space-between;\n",
        "    align-items: flex-start;\n",
        "  }\n",
        "  .table-item {\n",
        "    margin-right: 20px; /* 表と表の間に空白を追加 */\n",
        "  }\n",
        "</style>\n",
        "\n",
        "  <div class=\"table-container\">\n",
        "    <div class=\"table-item\">\n",
        "      <table>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>-1</td>\n",
        "          <td>1</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "        </tr>\n",
        "      </table>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        " - 縦方向\n",
        "\n",
        "  <div class=\"table-container\">\n",
        "    <div class=\"table-item\">\n",
        "      <table>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "          <td>0</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>-1</td>\n",
        "          <td>0</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>0</td>\n",
        "          <td>1</td>\n",
        "          <td>0</td>\n",
        "        </tr>\n",
        "      </table>\n",
        "    </div>\n",
        "  </div>\n",
        "\n",
        "- ぼかしを行う場合には、周囲のピクセルの値を平滑化します。<br>\n",
        "[平均化フィルタ - 画像をぼかす](https://www.mitani-visual.jp/mivlog/imageprocessing/avef12.php)（MiVLog）\n",
        "\n",
        " - ぼかし（一様重み）\n",
        "\n",
        " <style>\n",
        "  table, th, td {\n",
        "    border: 1px solid black;\n",
        "    border-collapse: collapse;\n",
        "    padding: 5px;\n",
        "    text-align: center;\n",
        "  }\n",
        "  .table-container {\n",
        "    display: flex;\n",
        "    justify-content: space-between;\n",
        "    align-items: flex-start;\n",
        "  }\n",
        "  .table-item {\n",
        "    margin-right: 20px; /* 表と表の間に空白を追加 */\n",
        "  }\n",
        "</style>\n",
        "\n",
        "  <div class=\"table-container\">\n",
        "    <div class=\"table-item\">\n",
        "      <table>\n",
        "        <tr>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "          <td>1/9</td>\n",
        "        </tr>\n",
        "      </table>\n",
        "  </div></div>\n",
        "\n",
        " - ぼかし（ガウシアン）\n",
        "\n",
        "  <div class=\"table-container\">\n",
        "    <div class=\"table-item\">\n",
        "      <table>\n",
        "        <tr>\n",
        "          <td>1/16</td>\n",
        "          <td>1/8</td>\n",
        "          <td>1/16</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>1/8</td>\n",
        "          <td>1/4</td>\n",
        "          <td>1/8</td>\n",
        "        </tr>\n",
        "        <tr>\n",
        "          <td>1/16</td>\n",
        "          <td>1/8</td>\n",
        "          <td>1/16</td>\n",
        "        </tr>\n",
        "      </table>\n",
        "  </div></div>\n"
      ],
      "metadata": {
        "id": "9linf1lxS7zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(image, kernel, stride=1):\n",
        "\n",
        "    \"\"\"\n",
        "    2次元の畳み込み演算を行う関数\n",
        "\n",
        "    Parameters:\n",
        "    image : numpy array\n",
        "        入力画像（2次元配列）\n",
        "    kernel : numpy array\n",
        "        畳み込みカーネル（2次元配列）\n",
        "    stride : int, optional\n",
        "        ストライドの値（デフォルトは1）\n",
        "\n",
        "    Returns:\n",
        "    numpy array\n",
        "        畳み込み演算後の出力画像（2次元配列）\n",
        "    \"\"\"\n",
        "\n",
        "    # 入力画像とカーネルのサイズを取得\n",
        "    image_height, image_width = image.shape\n",
        "    kernel_height, kernel_width = kernel.shape\n",
        "\n",
        "    # 畳み込み演算後の出力画像のサイズを計算\n",
        "    output_height = (image_height - kernel_height) // stride + 1\n",
        "    output_width = (image_width - kernel_width) // stride + 1\n",
        "\n",
        "    # 出力画像の初期化\n",
        "    output = np.zeros((output_height, output_width))\n",
        "\n",
        "    # 畳み込み演算\n",
        "    for h in range(output_height):\n",
        "        for w in range(output_width):\n",
        "            region = image[h * stride:h * stride + kernel_height,\n",
        "                           w * stride:w * stride + kernel_width]\n",
        "            output[h, w] = np.sum(region * kernel)\n",
        "\n",
        "    return output\n",
        "\n",
        "# 表示\n",
        "def display_convolution_result(conv_results, vmin=-30, vmax=30):\n",
        "    if isinstance(conv_results, (list, tuple)):\n",
        "        conv_results = [np.array(result) for result in conv_results]\n",
        "        num_results = len(conv_results)\n",
        "    else:\n",
        "        conv_results = [conv_results]\n",
        "        num_results = 1\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_results, figsize=(15, 5))\n",
        "\n",
        "    if num_results == 1:\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, result in enumerate(conv_results):\n",
        "        im = axes[i].imshow(result, cmap='gray', vmin=vmin, vmax=vmax)\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    fig.colorbar(im, ax=axes, orientation='vertical')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "MwRm5x8xQIGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 畳み込みカーネルの定義\n",
        "kernel = np.array(\n",
        "                  [[  0,  0,  0],\n",
        "                   [  0, -1,  1],\n",
        "                   [  0,  0,  0]]\n",
        "                  )\n",
        "\n",
        "# 畳み込み処理の実行\n",
        "conv_result = convolution(gray_array, kernel)\n",
        "\n",
        "display_convolution_result(conv_result)"
      ],
      "metadata": {
        "id": "3rFuzX2cWHt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **課題２**\n",
        "\n",
        "- 上記の畳み込みカーネルでは、輪郭線が白または黒に浮かび上がっています。\n",
        " - ＿＿＿ 方向のエッジを抽出（**強調** とは別物）するため、その方向への微分を行っています。\n",
        "- 次のコードセルにあるカーネルを変更して、もうひとつの方向のエッジを抽出するフィルタや、一様重みぼかしフィルタを実現してください．"
      ],
      "metadata": {
        "id": "AXj-pWJqpEQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ＿＿＿＿方向（上の例とは逆）のエッジを抽出\n",
        "kernel = np.array([\n",
        "                   [  0,  0,  0],\n",
        "                   [  0, -1,  1],\n",
        "                   [  0,  0,  0]\n",
        "                  ])\n",
        "result = convolution(gray_array, kernel)\n",
        "display_convolution_result(result)\n",
        "\n",
        "# 一様重みぼかし\n",
        "kernel = np.array([\n",
        "                   [  0,  0,  0],\n",
        "                   [  0, -1,  1],\n",
        "                   [  0,  0,  0]\n",
        "                  ])\n",
        "result = convolution(gray_array, kernel)\n",
        "display_convolution_result(result, vmin=0, vmax=255)"
      ],
      "metadata": {
        "id": "_PKJ7nquq8VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 畳み込みにより画像が小さく**なる**\n",
        "\n",
        "畳み込み演算では、畳み込みカーネルを画像の上にスライドさせながら演算を行います。このとき、画像の端（辺縁部分）においては畳み込みカーネルが完全に適用されないことがあります。具体的には、畳み込みカーネルが画像の範囲を超えてしまうため、その部分においては畳み込み演算が行えません。\n",
        "\n",
        "**上：出力**\n",
        "\n",
        "<a title=\"Vincent Dumoulin, Francesco Visin, MIT &lt;http://opensource.org/licenses/mit-license.php&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Full_padding_no_strides_transposed.gif\"><img width=\"256\" alt=\"Convolution arithmetic - Full padding no strides transposed\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/85/Convolution_arithmetic_-_Full_padding_no_strides_transposed.gif?20190413174624\"></a>\n",
        "\n",
        "**下：入力**\n",
        "\n",
        "上の例では、元の画像が 180×320、畳み込みカーネルが 3×3 でした。畳み込み演算によって得られる出力画像のサイズは以下のように計算されます\n",
        "\n",
        "- 出力画像の高さ: $180−3+1=178$\n",
        "- 出力画像の幅:　 $320−3+1=318$\n",
        "\n",
        "この場合、元の画像の辺縁部分では、畳み込みカーネルが完全に適用されないため、出力画像の寸法が元の画像よりも小さくなります。畳み込み演算を行う際には、画像の端のピクセルでは畳み込みカーネルが画像からはみ出すため、その部分の演算は行えません。\n",
        "\n",
        "なお以下の図のように、辺縁での計算を工夫することでサイズを小さくしないこともあります。\n",
        "\n",
        "**上：出力**\n",
        "\n",
        "<a title=\"Vincent Dumoulin, Francesco Visin, MIT &lt;http://opensource.org/licenses/mit-license.php&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Same_padding_no_strides.gif\"><img width=\"256\" alt=\"Convolution arithmetic - Same padding no strides\" src=\"https://upload.wikimedia.org/wikipedia/commons/e/ee/Convolution_arithmetic_-_Same_padding_no_strides.gif?20190413174642\"></a>\n",
        "\n",
        "**下：入力**"
      ],
      "metadata": {
        "id": "geVA1MHpblEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ストライドでもっと画像を小さく**する**\n",
        "\n",
        "畳み込み演算ではストライド（stride）として、フィルタ（カーネル）を画像上でどれだけ移動させるかを設定します。通常、ストライドが1の場合、フィルタは1ピクセルずつ移動し、重なり合う部分で演算が行われます。一方、ストライドを大きくすると、フィルタが大きくジャンプし、出力される画像のサイズが小さくなります。\n",
        "\n",
        "**上：出力**\n",
        "\n",
        "<a title=\"Vincent Dumoulin, Francesco Visin, MIT &lt;http://opensource.org/licenses/mit-license.php&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_No_padding_strides.gif\"><img width=\"256\" alt=\"Convolution arithmetic - No padding strides\" src=\"https://upload.wikimedia.org/wikipedia/commons/b/b9/Convolution_arithmetic_-_No_padding_strides.gif?20190413174627\"></a>\n",
        "\n",
        "**下：入力**\n",
        "\n",
        "<!-- <a title=\"Vincent Dumoulin, Francesco Visin, MIT &lt;http://opensource.org/licenses/mit-license.php&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Convolution_arithmetic_-_Padding_strides_odd.gif\"><img width=\"256\" alt=\"Convolution arithmetic - Padding strides odd\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/2d/Convolution_arithmetic_-_Padding_strides_odd.gif?20190413174630\"></a> -->\n",
        "\n",
        "入力画像のサイズを $ W \\times H $、フィルタのサイズを $ F \\times F $、ストライドを $ S $ とすると、畳み込み演算後の出力画像のサイズ $ W' \\times H' $ は次のように計算されます：\n",
        "\n",
        "$$\n",
        "W' = \\frac{W - F}{S} + 1 \\\\\n",
        "H' = \\frac{H - F}{S} + 1\n",
        "$$\n",
        "\n",
        "ここで、 $W′$ と $ H′$ は出力画像の幅と高さです。\n",
        "\n",
        "ストライドを 1 より大きくすると、入力画像よりも小さな出力を得ることができます。"
      ],
      "metadata": {
        "id": "AykycR9IYnCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 縦横のエッジを抽出するカーネル\n",
        "kernel = np.array([[0,  1,  0],\n",
        "                   [0, -2,  1],\n",
        "                   [0,  0,  0]])\n",
        "\n",
        "# 畳み込み処理の実行（ストライド2）\n",
        "output_image = convolution(gray_array, kernel, stride=2)\n",
        "\n",
        "display_convolution_result(output_image)\n",
        "print(\"入力のサイズ\", gray_array.shape)\n",
        "print(\"結果のサイズ\", output_image.shape)"
      ],
      "metadata": {
        "id": "t4Pk0pgCa-Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **課題３**\n",
        "- 次のコードセルで、富士山であることが分かる程度に小さな画像を、ストライドの調整により作ってください。<br>\n",
        "※表示すると小さくなる代わりに画素が大きくなるため、画像としては荒くなります。"
      ],
      "metadata": {
        "id": "qyXwBlXJ3pym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 例：縦横のエッジを抽出するカーネル\n",
        "kernel = np.array([\n",
        "                   [  0,  0,  0],\n",
        "                   [  0, -1,  0],\n",
        "                   [  0,  1,  0]\n",
        "                  ])\n",
        "\n",
        "# 畳み込み処理の実行（ストライド2）\n",
        "output_image = convolution(gray_array, kernel, stride=1)\n",
        "\n",
        "display_convolution_result(output_image)\n",
        "print(\"入力のサイズ\", gray_array.shape)\n",
        "print(\"結果のサイズ\", output_image.shape)"
      ],
      "metadata": {
        "id": "sLkffoL95UrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **課題４**\n",
        "２回の畳み込みそれぞれのストライドを調整して、やはり富士山であることが分かる程度に画像を小さくしてください。\n",
        "1. 一様重みぼかし\n",
        "2. 縦のエッジの抽出\n",
        "\n",
        "たとえばこんな感じになります。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/shizoda/education/main/image/fujishape.png\" width=\"400\">\n"
      ],
      "metadata": {
        "id": "sdvmCbF-6Wvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 一様重みぼかし\n",
        "kernel = np.array([\n",
        "                   [  1/9,  1/9,  1/9 ],\n",
        "                   [  1/9,  1/9,  1/9 ],\n",
        "                   [  1/9,  1/9,  1/9 ]\n",
        "                  ])\n",
        "result = convolution(gray_array, kernel, stride=1)\n",
        "display_convolution_result(result, vmin=0, vmax=255)\n",
        "\n",
        "# 縦のエッジを抽出\n",
        "kernel = np.array([\n",
        "                   [  0,  0,  0],\n",
        "                   [  0, -1,  0],\n",
        "                   [  0,  1,  0]\n",
        "                  ])\n",
        "result = convolution(result, kernel, stride=1)\n",
        "display_convolution_result(result)\n",
        "print(\"入力のサイズ\", gray_array.shape)\n",
        "print(\"結果のサイズ\", result.shape)"
      ],
      "metadata": {
        "id": "YPxKdIuv6R_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 画像から特徴量へ\n",
        "\n",
        "iris のデータセットの演習では，4 次元の **特徴量** からアヤメを分類しました。それは、それらの値がすでに花の分類に有用な状態で提供されていたからこそ可能でした。\n",
        "\n",
        "しかし画像はそうなっていません。画像は通常、数万や数億といった膨大な画素で構成されています。ここで畳み込みを用いることで、エッジのような重要な特徴を画像から引き出せます。ストライドを調節すれば、そのような重要な特徴を含む、画像より小さな配列を得ることもできます。\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Typical_cnn.png\"><img width=\"512\" alt=\"Typical cnn\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/512px-Typical_cnn.png?20151217030420\"></a>\n",
        "\n",
        "深層学習の手法として有名な **畳み込みニューラルネットワーク** (Convolutional Neural Network; **CNN**) は、画像を入力として、畳み込みを用いて画像から特徴量を抽出してから、分類や回帰などの目的に利用します。今回の演習では、カーネルはみずから定義しましたが、CNN ではカーネル自体も学習されます。解こうとしている問題にあわせてカーネルの値を調節するのが、CNN の学習であるともいえます。\n",
        "\n",
        "それでは，[CNN を用いた画像分類の演習に進みましょう。](https://github.com/shizoda/education/blob/main/machine_learning/cnn/cifar10_pytorch.ipynb)"
      ],
      "metadata": {
        "id": "NFSSND6okOG5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eyp5uV7FmFur"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}