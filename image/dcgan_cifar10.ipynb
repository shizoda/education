{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOnpGztmGUBJwJi/imCnIF0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/image/dcgan_cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEjmJ3nAK2h2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ハイパーパラメータ\n",
        "params = {\n",
        "    \"n_epochs\": 300,      # エポック数 (CIFAR-10はFashionMNISTより複雑なので多めに設定)\n",
        "    \"batch_size\": 128,    # バッチサイズ\n",
        "    \"lr\": 0.0002,         # 学習率\n",
        "    \"beta1\": 0.5,         # Adamオプティマイザのパラメータ\n",
        "    \"nz\": 100,            # 潜在変数の次元数 (ノイズのサイズ)\n",
        "    \"ngf\": 128,            # Generatorの特徴マップのサイズ\n",
        "    \"ndf\": 64,            # Discriminatorの特徴マップのサイズ\n",
        "    \"image_size\": 32,     # CIFAR-10の画像サイズは32x32\n",
        "    \"nc\": 3,              # 画像のチャンネル数 (CIFAR-10はカラーなので3)\n",
        "    \"target_class_name\": \"automobile\" # 学習したいクラス名\n",
        "}\n",
        "\n",
        "# GPUが利用可能か確認し、デバイスを設定\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像の前処理\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(params[\"image_size\"]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # [-1, 1]に正規化\n",
        "])\n",
        "\n",
        "# データセットのダウンロード\n",
        "full_dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "\n",
        "# CIFAR-10のクラス名\n",
        "class_names = full_dataset.classes\n",
        "print(f\"CIFAR-10 class names: {class_names}\")\n",
        "\n",
        "# 学習対象のクラスのインデックスを取得\n",
        "try:\n",
        "    target_class_idx = class_names.index(params[\"target_class_name\"])\n",
        "    print(f\"Targeting class: '{params['target_class_name']}' (index: {target_class_idx})\")\n",
        "except ValueError:\n",
        "    print(f\"Error: '{params['target_class_name']}' is not a valid CIFAR-10 class name. Please choose from {class_names}\")\n",
        "    exit()\n",
        "\n",
        "# 特定のクラスのデータのみを抽出\n",
        "indices = [i for i, label in enumerate(full_dataset.targets) if label == target_class_idx]\n",
        "dataset = Subset(full_dataset, indices)\n",
        "dataloader = DataLoader(dataset, batch_size=params[\"batch_size\"], shuffle=True)\n",
        "\n",
        "if len(dataset) == 0:\n",
        "    print(f\"Error: No images found for class '{params['target_class_name']}'. Please check the class name or dataset.\")\n",
        "    exit()\n",
        "else:\n",
        "    print(f\"Number of images for '{params['target_class_name']}': {len(dataset)}\")\n",
        "\n",
        "# データの可視化 (確認用)\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Training Images ({params['target_class_name']})\")\n",
        "plt.imshow(np.transpose(make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(), (1, 2, 0)))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-UtyGdj8K5aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 重みの初期化関数\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "# Generator\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz, ngf, nc):\n",
        "        super(Generator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # 入力は潜在変数Z\n",
        "            nn.ConvTranspose2d(nz, ngf * 4, 4, 1, 0, bias=False), # CIFAR-10は画像サイズが小さいのでConvTransposeの層を調整\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*4) x 4 x 4\n",
        "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf*2) x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. (ngf) x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh() # 出力は-1から1の範囲\n",
        "            # state size. (nc) x 32 x 32\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "-GH2P1fxK6tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf, nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # input is (nc) x 32 x 32\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. (ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid() # 確率を出力\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "metadata": {
        "id": "E8kGAUWkK89Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのインスタンス化\n",
        "netG = Generator(params[\"nz\"], params[\"ngf\"], params[\"nc\"]).to(device)\n",
        "netD = Discriminator(params[\"ndf\"], params[\"nc\"]).to(device)\n",
        "\n",
        "# 重みの初期化を適用\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# 損失関数とオプティマイザ\n",
        "criterion = nn.BCELoss() # バイナリクロスエントロピー損失\n",
        "\n",
        "# 学習の進捗可視化用に、固定のノイズを生成\n",
        "fixed_noise = torch.randn(64, params[\"nz\"], 1, 1, device=device)\n",
        "\n",
        "# 本物と偽物のラベル\n",
        "real_label = 0.9\n",
        "fake_label = 0.1\n",
        "\n",
        "# オプティマイザの設定\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=params[\"lr\"], betas=(params[\"beta1\"], 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=params[\"lr\"], betas=(params[\"beta1\"], 0.999))\n",
        "\n",
        "# 学習ループ\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "img_list = []\n",
        "iters = 0\n",
        "\n",
        "print(f\"Starting Training Loop for class: {params['target_class_name']}...\")\n",
        "for epoch in range(params[\"n_epochs\"]):\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # ---------------------\n",
        "        # (1) Discriminatorの学習\n",
        "        # ---------------------\n",
        "        netD.zero_grad()\n",
        "        # 本物の画像で学習\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        errD_real = criterion(output, label)\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        # 偽物の画像で学習\n",
        "        noise = torch.randn(b_size, params[\"nz\"], 1, 1, device=device)\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        errD_fake = criterion(output, label)\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        # 損失を合計し、オプティマイザで更新\n",
        "        errD = errD_real + errD_fake\n",
        "        optimizerD.step()\n",
        "\n",
        "        # ---------------------\n",
        "        # (2) Generatorの学習\n",
        "        # ---------------------\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label) # Generatorにとっては偽物が本物\n",
        "        output = netD(fake).view(-1)\n",
        "        errG = criterion(output, label)\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        optimizerG.step()\n",
        "\n",
        "        # 損失を記録\n",
        "        if i % 50 == 0: # 50イテレーションごとにログを出力\n",
        "            print(f'[{epoch+1}/{params[\"n_epochs\"]}][{i}/{len(dataloader)}] '\n",
        "                  f'Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f} '\n",
        "                  f'D(x): {D_x:.4f} D(G(z)): {D_G_z1:.4f} / {D_G_z2:.4f}')\n",
        "\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "    # 各エポックの終わりに、固定ノイズから生成した画像を確認\n",
        "    with torch.no_grad():\n",
        "        fake = netG(fixed_noise).detach().cpu()\n",
        "    img_list.append(make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "print(\"Training Finished.\")"
      ],
      "metadata": {
        "id": "I0wdFRrlK92O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gEN3M1YvK_OE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 最後の_エポックで生成された画像を表示\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"Generated Images for {params['target_class_name']}\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()\n",
        "\n",
        "# リアルな画像と生成画像を比較\n",
        "# dataloaderが空の場合を考慮\n",
        "if len(dataloader) > 0:\n",
        "    real_batch = next(iter(dataloader))\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Real Images ({params['target_class_name']})\")\n",
        "    plt.imshow(np.transpose(make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Fake Images ({params['target_class_name']})\")\n",
        "    plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Cannot display real images as the dataloader for {params['target_class_name']} is empty.\")"
      ],
      "metadata": {
        "id": "FtotqV_7LAAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}