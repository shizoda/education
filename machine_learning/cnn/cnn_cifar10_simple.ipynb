{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOERcmvaE7a1b/x4+p+taZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/cnn/cnn_cifar10_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📷 画像分類：CNNによる特徴抽出と確率出力\n",
        "\n",
        "前回のノートブックでは、4つの数値（特徴量）を入力として扱いました。今回は、 **画像（ピクセルデータの集合）** を入力とする「畳み込みニューラルネットワーク (CNN)」を扱います。\n",
        "\n",
        "重要なポイントは以下の2点です。\n",
        "\n",
        "1.  **入力** : 人間が計測した数値ではなく、画像データそのものを入力する。\n",
        "2.  **出力** : 各クラスに属する「確率」が出力される。\n",
        "\n",
        "---\n",
        "### ⚙️ GPU ランタイムの確認\n",
        "このプログラムは計算負荷が高いため、 **Google Colab を前提とし、GPU（グラフィックボード）を使用します。** メニューの「ランタイム」→「ランタイムのタイプを変更」から「T4 GPU」を選択してください。\n",
        "\n",
        "設定できていない場合、以下のセルを実行するとエラーが発生して停止します。"
      ],
      "metadata": {
        "id": "ZkLQkrgDsMO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "\n",
        "# GPUが使用可能か確認する\n",
        "if not torch.cuda.is_available():\n",
        "    # GPUが使えない場合は、意図的にエラーを発生させて停止させる\n",
        "    raise RuntimeError(\n",
        "        \"❌ GPUが検出されませんでした。\\n\"\n",
        "        \"メニューバーの「ランタイム」>「ランタイムのタイプを変更」から\\n\"\n",
        "        \"「T4 GPU」などを選択して保存し、再実行してください。\"\n",
        "    )\n",
        "\n",
        "print(f\"✅ GPUが正常に検出されました: {torch.cuda.get_device_name(0)}\")\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "# 必要なライブラリのインポート\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "1j0FEcFSuAC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🖼️ 1. データセットの確認\n",
        "\n",
        "モデルを構築する前に、今回使用するデータセット **CIFAR-10** の中身を確認します。\n",
        "これは以下の10クラスの画像が含まれています。\n",
        "\n",
        "* `plane` (飛行機), `car` (自動車), `bird` (鳥), `cat` (猫), `deer` (鹿)\n",
        "* `dog` (犬), `frog` (カエル), `horse` (馬), `ship` (船), `truck` (トラック)\n",
        "\n",
        "画像は $32 \\times 32$ ピクセルのカラー画像です。"
      ],
      "metadata": {
        "id": "XYOlSKJVuXOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title データのダウンロードと各クラスの表示\n",
        "# 前処理の定義（テンソル化と正規化）\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 学習用データのダウンロードとロード\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "# テスト用データのダウンロードとロード\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "# クラス名の定義\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# 画像表示用の関数\n",
        "def imshow(img, ax):\n",
        "    img = img / 2 + 0.5     # 正規化を戻す\n",
        "    npimg = img.numpy()\n",
        "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    ax.axis('off')\n",
        "\n",
        "# 各クラスの画像を1枚ずつ取得して表示\n",
        "class_images = {}\n",
        "dataiter = iter(trainset)\n",
        "\n",
        "# 10クラス揃うまで画像を探索\n",
        "while len(class_images) < 10:\n",
        "    image, label = next(dataiter)\n",
        "    label_name = classes[label]\n",
        "    if label_name not in class_images:\n",
        "        class_images[label_name] = image\n",
        "\n",
        "# 表示\n",
        "print(f\"--- CIFAR-10 データセットのサンプル ({len(trainset)}枚から抜粋) ---\")\n",
        "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    imshow(class_images[class_name], axes[i])\n",
        "    axes[i].set_title(class_name, fontsize=12, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# データローダーの準備（学習用）\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "wMKLU8esuWkt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 課題：前回 (Iris) と今回 (CIFAR-10) の比較\n",
        "\n",
        "前回の講義で扱った「アヤメ (Iris) の分類」と、今回の「画像 (CIFAR-10) の分類」について、入力と出力の違いを整理しましょう。以下の表の空欄を埋めながら、違いを確認してください。\n",
        "\n",
        "| 項目 | 前回: Iris (アヤメ) | 今回: CIFAR-10 (画像) |\n",
        "| :--- | :--- | :--- |\n",
        "| **1. 入力データ** | 人間が計測した **【　　　量】** <br> (例：がくの長さ、幅など **4** つの数値) | カメラが撮影した **【　　　値】** <br> (例：$32 \\times 32$ ピクセル $\\times$ RGB 3色 ＝ **3072** 個の数値) |\n",
        "| **入力データの意味** | 数値そのものに意味がある <br> (大きい＝長い、など) | **個々の画素値に特定の意味はない** <br> (隣り合う画素との関係性が重要) |\n",
        "| **2. 出力データ** | **3** つのクラスごとの確率 | **【　　　　】** つのクラスごとの確率 |"
      ],
      "metadata": {
        "id": "iG5Ur3pvxcSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ⚙️ 2. モデルの構築と学習\n",
        "\n",
        "画像分類を行う **CNN (Convolutional Neural Network)** モデルを定義し、学習を行います。\n",
        "\n",
        "### モデルの役割\n",
        "このモデルは、入力された画像データ $x$ に対し、一連の計算処理を行い、最終的に10個の数値（確率の元となるスコア）を出力します。\n",
        "\n",
        "1.  **特徴抽出 (Convolution)** : 画像からエッジや模様などの特徴を自動的に検出します。\n",
        "2.  **分類 (Linear)** : 検出された特徴に基づき、どのクラスに属するかを計算します。\n",
        "\n",
        "※以下のセルを実行すると学習が始まります（数分かかります）。"
      ],
      "metadata": {
        "id": "HQKHIq_junrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title モデル定義と学習実行\n",
        "# シンプルなCNNモデルの定義\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # 特徴抽出層 (畳み込み層 + プーリング層)\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        # 分類層 (全結合層)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, 512), nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# モデルをGPUに転送\n",
        "net = SimpleCNN().to(device)\n",
        "\n",
        "# 損失関数と最適化手法の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "# 学習ループ\n",
        "epochs = 5\n",
        "print(f\"🚀 学習を開始します (全 {epochs} エポック)...\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    net.train() # 学習モード\n",
        "    running_loss = 0.0\n",
        "    # tqdmで進捗バーを表示\n",
        "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
        "        for data in tepoch:\n",
        "            tepoch.set_description(f\"Epoch {epoch+1}\")\n",
        "\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()       # 勾配の初期化\n",
        "            outputs = net(inputs)       # 推論\n",
        "            loss = criterion(outputs, labels) # 損失の計算\n",
        "            loss.backward()             # 逆伝播\n",
        "            optimizer.step()            # パラメータ更新\n",
        "\n",
        "            tepoch.set_postfix(loss=loss.item())\n",
        "\n",
        "print(\"✅ 学習が完了しました。\")"
      ],
      "metadata": {
        "collapsed": true,
        "cellView": "form",
        "id": "FQO3SCP9upWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🧪 3. 推論結果の可視化\n",
        "\n",
        "学習済みモデルを用いて、テストデータ（学習には使用していない画像）の分類を行います。\n",
        "\n",
        "以下のフォームで画像IDを指定すると、モデルに入力画像を与え、その出力結果（確率分布）を表示します。\n",
        "モデルが **「どのクラスだと判断したか」** **「その判断にどれくらいの確信度（確率）を持っているか」** を確認してください。"
      ],
      "metadata": {
        "id": "KkqjcYQEvEvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🔍 テスト画像の判定\n",
        "#@markdown 画像IDを選択してください\n",
        "\n",
        "image_id = 1148 # @param {\"type\":\"slider\",\"min\":0,\"max\":9999,\"step\":1}\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # 正規化を戻す\n",
        "    npimg = img.cpu().numpy() # GPUにある場合はCPUに戻す\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.axis('off')\n",
        "\n",
        "# 指定されたIDの画像を取得\n",
        "test_data_iter = iter(testloader)\n",
        "# image_idの数だけスキップ（簡易実装）\n",
        "for _ in range(image_id):\n",
        "    try:\n",
        "        next(test_data_iter)\n",
        "    except StopIteration:\n",
        "        print(\"画像IDが範囲外です。最初に戻ります。\")\n",
        "        test_data_iter = iter(testloader)\n",
        "        break\n",
        "\n",
        "images, labels = next(test_data_iter)\n",
        "\n",
        "# モデルによる推論\n",
        "net.eval() # 評価モード\n",
        "with torch.no_grad():\n",
        "    images_gpu = images.to(device)\n",
        "    outputs = net(images_gpu)\n",
        "    # ソフトマックス関数で確率に変換\n",
        "    probs = F.softmax(outputs, dim=1)\n",
        "    # CPUに戻してNumPy配列化\n",
        "    probs_np = probs.cpu().numpy()[0] * 100\n",
        "\n",
        "# 結果の取得\n",
        "prediction_idx = torch.argmax(probs, dim=1).item()\n",
        "true_label_idx = labels.item()\n",
        "prediction_name = classes[prediction_idx]\n",
        "true_label_name = classes[true_label_idx]\n",
        "\n",
        "# --- 可視化 ---\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# 1. 入力画像の表示\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(images[0])  # ここで修正した関数を使用\n",
        "title_text = f\"Input: {true_label_name}\"\n",
        "title_color = \"black\"\n",
        "if prediction_idx != true_label_idx:\n",
        "    title_text += f\" (Model Predicted: {prediction_name})\"\n",
        "    title_color = \"red\"\n",
        "plt.title(title_text, fontsize=14, color=title_color, fontweight='bold')\n",
        "\n",
        "# 2. 確率分布の表示\n",
        "plt.subplot(1, 2, 2)\n",
        "colors = ['skyblue'] * 10\n",
        "# 正解のバーを緑、間違った予測のバーを赤にする\n",
        "colors[true_label_idx] = 'lightgreen'\n",
        "if prediction_idx != true_label_idx:\n",
        "    colors[prediction_idx] = 'salmon'\n",
        "\n",
        "bars = plt.bar(classes, probs_np, color=colors, edgecolor='black')\n",
        "plt.ylabel('Probability (%)')\n",
        "plt.title(f'Prediction Confidence\\n(Max: {probs_np[prediction_idx]:.1f}%)', fontsize=12)\n",
        "plt.ylim(0, 100)\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# 確率値の表示\n",
        "for bar, p in zip(bars, probs_np):\n",
        "    if p > 1.0: # 1%以上のみ表示\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, p + 2, f\"{p:.0f}%\", ha='center', fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# テキスト出力\n",
        "print(f\"正解クラス: {true_label_name}\")\n",
        "if prediction_idx == true_label_idx:\n",
        "    print(f\"モデル判定: 正解 ({probs_np[prediction_idx]:.1f}% の確率で {prediction_name} と予測)\")\n",
        "else:\n",
        "    print(f\"モデル判定: 不正解 ({probs_np[prediction_idx]:.1f}% の確率で {prediction_name} と予測)\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gdcfZc3XvGGK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 課題：モデルの出力特性を分析する\n",
        "\n",
        "上の実験コードで `image_id` を変更し、以下のケースに該当する画像の番号（ID）を探してください。\n",
        "\n",
        "#### 1. 高い確信度での正解\n",
        "モデルが90%以上の確率を出して正解した画像のIDを1つ挙げてください。\n",
        "* **画像ID** : [      ]\n",
        "* **クラス** : [      ]\n",
        "* **考察** : なぜモデルはこの画像の分類が容易だったと考えられますか？（例：背景、形状の特徴など）\n",
        "    * [ 記述欄 ]\n",
        "\n",
        "#### 2. 低い確信度、または誤分類\n",
        "確率が低い、複数のクラスで確率が分散している、あるいは誤分類した画像のIDを1つ挙げてください。\n",
        "* **画像ID** : [      ]\n",
        "* **モデルの予測** : [      ]  （正解は：[      ]）\n",
        "* **考察** : なぜモデルは分類に失敗した、あるいは確信を持てなかったと考えられますか？\n",
        "    * [ 記述欄 ]"
      ],
      "metadata": {
        "id": "whgPYUmTvhyP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📝 復習課題：間違いだらけのレポート修正\n",
        "\n",
        "ある学生が、今回の実験（画像分類AI）についてレポートを書きましたが、**入力と出力に関して大きな勘違い**をしているようです。\n",
        "以下の文章には **3つの間違い** があります。どこが間違っているか指摘し、正しい説明に直してください。\n",
        "\n",
        "---\n",
        "\n",
        "### ❌ 間違いだらけのレポート\n",
        "\n",
        "「今回扱った画像認識AI（CNN）は、人間と同じように画像を見るすごいモデルです。\n",
        "\n",
        "まず入力として、私たちは画像の中に写っている **『耳が尖っている』や『尻尾が長い』といった特徴を言葉や数値にして** AIに教えました（①）。\n",
        "\n",
        "AIの内部で計算が行われた後、出力層からは **『猫』という正解のクラス名（文字）** が出力されました（②）。\n",
        "\n",
        "この出力を見ることで、AIがどれくらい自信を持っているかが分かります。なぜなら、出力された数値の合計は **特に決まっていない（100%にならない）** からです（③）。」\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ あなたの修正案\n",
        "\n",
        "**① 入力について**\n",
        "* **誤**: 『耳が尖っている』などの特徴を入力した\n",
        "* **正**: AIに入力したのは、カメラで撮ったままの **【　　　　】** です。（ヒント：3072個の数値）\n",
        "\n",
        "**② 出力について**\n",
        "* **誤**: 『猫』というクラス名だけが出力された\n",
        "* **正**: 実際には、10個のクラスそれぞれの **【　　　　】** が出力されました。私たちはその中から最大のものを選んでいます。\n",
        "\n",
        "**③ 確率のルール**\n",
        "* **誤**: 合計は決まっていない\n",
        "* **正**: 全てのクラスの確率を足すと必ず **【　　　　】** になるようになっています。"
      ],
      "metadata": {
        "id": "eVr6_EyL0jmJ"
      }
    }
  ]
}