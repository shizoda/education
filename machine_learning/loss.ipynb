{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtOLWtm55g1//QChEhmTJv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 損失関数（Loss Function）\n",
        "\n",
        "損失関数は、**モデルの予測と正解の差を定量化するもの**です。この「差」を最小化することこそが、ニューラルネットワークの学習です。\n",
        "\n",
        "### 役割\n",
        "\n",
        "1. **学習の指標**:\n",
        "   - モデルの出力が正解にどれだけ近いかを評価。\n",
        "2. **最適化**:\n",
        "   - 勾配を計算し、小さくなる方向へネットワークの重みを更新。\n",
        "\n",
        "\n",
        "\n",
        "### 代表的な損失関数\n",
        "\n",
        "1. **MSE Loss（Mean Squared Error）**:\n",
        "   - 出力とターゲットの「数値的な差」を平方して最小化する。\n",
        "   - 回帰問題では有効だけど、分類問題では確率分布を正しく扱えないことがある。\n",
        "   \n",
        "   \n",
        "$$\n",
        "  \\text{MSE Loss} = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^C \\left( y_{ij} - \\hat{y}_{ij} \\right)^2\n",
        "$$\n",
        "- $ N$ : サンプル数\n",
        "- $ C $: クラス数\n",
        "- $ y_{ij} $: 正解ラベル（one-hot形式）\n",
        "- $ \\hat{y}_{ij} $: モデルの出力（Softmax適用済み確率）\n",
        "\n",
        "2. **Cross Entropy Loss**:\n",
        "   - 確率分布の「誤差」を直接計算する。\n",
        "   - 出力が正解クラスに近づくほどロスが小さくなり、効率的に学習が進む。\n",
        "\n",
        "   $$\n",
        "   \\text{Cross Entropy Loss} = - \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^C y_{ij} \\log \\hat{y}_{ij}\n",
        "   $$\n"
      ],
      "metadata": {
        "id": "jQkuq5Z7tXlr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### 分類タスクでの損失関数\n",
        "分類タスクでは、出力を **確率分布** として扱うのが一般的です。確率分布とは、**ある事象が起こる確率を示す分布**のことです。分類タスクでは、モデルの出力（**ロジット**）をSoftmax関数に通すことで、各クラスの確率を計算します。\n",
        "\n",
        "この確率分布を用いて、正解クラスが予測される確率を最大化する方向に学習を進めます。\n",
        "\n",
        "### Softmax関数\n",
        "\n",
        "Softmaxはロジット（未正規化スコア）を確率に変換する関数で、次のように定義されます：\n",
        "$$\n",
        "\\hat{y}_j = \\frac{\\exp(z_j)}{\\sum_{k=1}^C \\exp(z_k)}\n",
        "$$\n",
        "- $ z_j $: クラス$ j $ のロジット（モデルの出力）\n",
        "- $ C $: クラス数\n",
        "- $ \\hat{y}_j $: クラス $ j $ が正解である確率\n",
        "\n",
        "この計算により、Softmaxの出力は次の特性を持ちます：\n",
        "1. 各クラスの確率は $0 $〜$ 1 $ の範囲。\n",
        "2. 全クラスの確率の合計は $ 1 $ になる。\n",
        "\n",
        "### 確率分布として扱うことのメリット\n",
        "\n",
        "分類タスクで確率分布を扱うことで、以下のような利点があります：\n",
        "\n",
        "1. **出力の解釈が明確**：\n",
        "   - モデルの出力を確率として解釈できるため、「このクラスが正解である可能性は何％か」という具体的な理解が可能です。\n",
        "\n",
        "2. **正解クラスを最大化する設計が可能**：\n",
        "   - 損失関数（例：Cross Entropy Loss）は、確率分布を直接扱うことで、正解クラスの確率を1に近づける方向に学習を進めます。\n",
        "\n",
        "3. **間違いの程度を考慮可能**：\n",
        "   - 予測が完全に間違っている場合（例：正解クラスの確率が極端に低い）ほど、損失が大きくなるため、モデルは間違いをより強く修正しようとします。\n",
        "\n",
        "4. **クラス間の重要度を調整可能**：\n",
        "   - Softmax出力にクラス重みを導入することで、クラス間の不均衡にも対応できます。\n",
        "\n",
        "### 具体例をもとに両者を比較\n",
        "モデルの出力（ロジット）：$ z = [2.0, 1.0, 0.1] $\n",
        "\n",
        "Softmax後の確率分布：$ \\hat{y} = [0.7, 0.2, 0.1] $\n",
        "\n",
        "この出力は次のように解釈できます：\n",
        "- クラス0が正解である確率は **70%**。\n",
        "- クラス1が正解である確率は **20%**。\n",
        "- クラス2が正解である確率は **10%**。\n",
        "\n",
        "正解がクラス0である場合、**Cross Entropy Loss**はクラス0の確率 $ \\hat{y}_0 = 0.7 $ をさらに高めるように学習を進めます。これは、正解クラスの確率を最大化するという**明確な目標**を持つため、分類タスクにおいて非常に効率的です。\n",
        "\n",
        "一方で、**MSE Loss**もSoftmax後の確率分布を扱うことで、「正解クラスの確率を1に近づける」という学習を行えます。ただし、以下の点で学習効率が劣る場合があります：\n",
        "\n",
        "1. **全クラスの誤差を等しく考慮**：  \n",
        "   MSE Lossはすべてのクラスについて誤差を計算するため、正解クラス以外の確率（例：$ \\hat{y}_1, \\hat{y}_2 $）の寄与が学習を鈍らせることがあります。\n",
        "\n",
        "2. **勾配が線形的に減少**：  \n",
        "   MSE Lossでは、確率の差が小さくなると勾配も小さくなるため、正解クラスの確率が高い場合に学習速度が遅くなります。\n",
        "\n",
        "このように MSE LossはSoftmax出力を使って分類タスクにも適用できますが、**Cross Entropy Lossのように確率分布を最大化する設計がないため、学習が遅くなることが多い**です。このため、分類タスクではCross Entropy Lossが一般的に選ばれます。\n"
      ],
      "metadata": {
        "id": "Az-_ET_aw0rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 課題１\n",
        "\n",
        "- ロジットに対してソフトマックスを適用し、値を表示してください。\n",
        "- クロスエントロピーロスを実装し、値を表示してください。"
      ],
      "metadata": {
        "id": "qZdkZOGOtzkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RsRm8bNtXLL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ロジット（Softmax適用前の出力）の例\n",
        "logits = torch.tensor([[3.2, 1.6, 0.2], [0.3, 2.6, 0.2]])\n",
        "\n",
        "# softmax を実装する\n",
        "softmax_predictions = F.softmax(logits, dim=1)\n",
        "print(f\"Softmax Predictions: {softmax_predictions}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解ラベル（one-hot形式）\n",
        "targets_one_hot = torch.tensor([[1, 0, 0], [0, 0, 1]])  # 正解ラベル（one-hot形式）\n",
        "\n",
        "# 正解ラベル（インデックス形式）も定義\n",
        "targets_index = torch.tensor([0, 2])  # クラス0, クラス2が正解\n",
        "\n",
        "# MSE Loss\n",
        "mse_loss = F.mse_loss(softmax_predictions, targets_one_hot)\n",
        "print(f\"MSE Loss: {mse_loss.item()}\")\n",
        "\n",
        "# Cross Entropy Loss\n",
        "# 自分で実装する。自分で書いてもいいし、PyTorch を使用しても可"
      ],
      "metadata": {
        "id": "AQ4MwxxFxfbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 課題２\n",
        "\n",
        "iris の分類において、Cross Entropy Loss を使えるように実装してください。\n",
        "また、その様子を観察してください。"
      ],
      "metadata": {
        "id": "coSxUplc0pyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Iris データセットの読み込み\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target  # 3クラス: 0, 1, 2\n",
        "\n",
        "# 特徴量を2次元に限定（Sepal Length, Sepal Width）\n",
        "X = X[:, :2]\n",
        "\n",
        "# データの標準化\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# サンプル点の可視化\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c=\"red\", marker=\"o\", label=\"Train - Setosa\")\n",
        "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c=\"blue\", marker=\"o\", label=\"Train - Versicolor\")\n",
        "plt.scatter(X_train[y_train == 2, 0], X_train[y_train == 2, 1], c=\"green\", marker=\"o\", label=\"Train - Virginica\")\n",
        "plt.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], c=\"red\", marker=\"x\", label=\"Test - Setosa\")\n",
        "plt.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], c=\"blue\", marker=\"x\", label=\"Test - Versicolor\")\n",
        "plt.scatter(X_test[y_test == 2, 0], X_test[y_test == 2, 1], c=\"green\", marker=\"x\", label=\"Test - Virginica\")\n",
        "plt.title(\"Train/Test Split Visualization (Iris Dataset)\")\n",
        "plt.xlabel(\"Feature 1 (Standardized)\")\n",
        "plt.ylabel(\"Feature 2 (Standardized)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EdOLzMA20o4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データをTensorに変換\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)  # マルチクラス分類用\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# シンプルなMLPモデル\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 3),  # 特徴量数: 2, 出力: 3（3クラス分類）\n",
        "    nn.Softmax(dim=1)  # 出力を確率分布に変換\n",
        ")\n",
        "\n",
        "# 損失関数のリスト\n",
        "loss_functions = {\n",
        "    # \"CrossEntropyLoss\":   # マルチクラス交差エントロピー\n",
        "    \"MSELoss\": nn.MSELoss()                     # 平均二乗誤差（Softmax後）\n",
        "}\n",
        "\n",
        "# オプティマイザのリスト\n",
        "optimizers = {\n",
        "    \"SGD\": lambda: optim.SGD(model.parameters(), lr=0.1),\n",
        "}\n",
        "\n",
        "# トレーニング関数\n",
        "def train(criterion_name, optimizer_name):\n",
        "    criterion = loss_functions[criterion_name]  # 損失関数を選択\n",
        "    optimizer = optimizers[optimizer_name]()    # オプティマイザを選択\n",
        "    scheduler = StepLR(optimizer, step_size=50, gamma=0.9)  # 学習率スケジューラ\n",
        "    losses = []  # ロスを記録するリスト\n",
        "\n",
        "    for epoch in range(300):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train_tensor)\n",
        "\n",
        "        # MSEの場合はone-hotエンコーディングが必要\n",
        "        if criterion_name == \"MSELoss\":\n",
        "            y_train_one_hot = torch.nn.functional.one_hot(y_train_tensor, num_classes=3).float()\n",
        "            loss = criterion(y_pred, y_train_one_hot)\n",
        "        else:\n",
        "            loss = criterion(y_pred, y_train_tensor)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # 学習率を更新\n",
        "\n",
        "        # 各エポックでのロスを記録\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    return losses  # ロスのリストを返す\n",
        "\n",
        "# トレーニングと可視化\n",
        "for criterion_name in loss_functions.keys():\n",
        "    for optimizer_name in optimizers.keys():\n",
        "        model.apply(lambda m: m.reset_parameters() if hasattr(m, \"reset_parameters\") else None)  # 重み初期化\n",
        "        losses = train(criterion_name, optimizer_name)  # トレーニング\n",
        "\n",
        "        # 横並びのグラフ作成\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "        # 学習曲線を左側にプロット\n",
        "        ax1 = axes[0]\n",
        "        ax1.plot(losses, label=\"Loss\", color=\"blue\")\n",
        "        ax1.set_xlabel(\"Epoch\")\n",
        "        ax1.set_ylabel(\"Loss\", color=\"blue\")\n",
        "        ax1.set_title(f\"Loss Curve ({criterion_name}, {optimizer_name})\")\n",
        "\n",
        "        # 決定境界を右側にプロット（ヒートマップ＆等高線）\n",
        "        ax2 = axes[1]\n",
        "        xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "        grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
        "        preds = model(grid).detach().numpy()  # 各クラスの確率分布\n",
        "        for class_idx in range(3):\n",
        "            class_scores = preds[:, class_idx].reshape(xx.shape)  # クラスごとのスコア\n",
        "            ax2.contourf(xx, yy, class_scores, levels=50, cmap=\"RdBu\", alpha=0.2)\n",
        "            ax2.contour(xx, yy, class_scores, levels=10, colors=\"black\", linewidths=0.5)\n",
        "        ax2.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c=\"red\", marker=\"o\", label=\"Setosa\")\n",
        "        ax2.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c=\"blue\", marker=\"s\", label=\"Versicolor\")\n",
        "        ax2.scatter(X_train[y_train == 2, 0], X_train[y_train == 2, 1], c=\"green\", marker=\"x\", label=\"Virginica\")\n",
        "        ax2.set_title(f\"Decision Boundary ({criterion_name}, {optimizer_name})\")\n",
        "        ax2.legend()\n",
        "\n",
        "        # レイアウト調整して表示\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "wcIZIBWq0vju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クラス間の不均衡への対応\n",
        "\n",
        "分類タスクでは、データの分布がクラス間で不均衡な場合があります。このような場合、標準的なCross Entropy Lossでは、サンプル数の多いクラス（多数派）が優先され、少数派クラスの正確な学習が難しくなります。\n",
        "\n",
        "### Weighted Cross Entropy\n",
        "\n",
        "クラス間の不均衡を補正するために、クラスごとに異なる重みを与える **Weighted Cross Entropy** が有効です。重み付きCross Entropyの式は以下の通りです：\n",
        "\n",
        "$$\n",
        "\\text{Weighted Cross Entropy Loss} = -\\frac{1}{N} \\sum_{i=1}^N w_{y_i} \\log(p_{i, y_i})\n",
        "$$\n",
        "\n",
        "- $N$: サンプル数\n",
        "- $y_i$: サンプル$i$の正解クラス\n",
        "- $p_{i, y_i}$: サンプル$i$の正解クラス$y_i$に対する予測確率\n",
        "- $w_{y_i}$: クラス$y_i$の重み\n",
        "\n",
        "クラスの重み$w_{y}$は、通常以下のように設定されます：\n",
        "$$\n",
        "w_{y} = \\frac{1}{n_y}\n",
        "$$\n",
        "ここで、$n_y$はクラス$y$に属するサンプル数です。これにより、少数派クラスの影響が増強され、学習が進むようになります。\n",
        "\n"
      ],
      "metadata": {
        "id": "mc3XHpTg292M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# デバイス設定\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "assert device.type == \"cuda\", \"CUDA が利用できません！GPU 環境で実行してください。\"\n",
        "\n",
        "# データセットの準備\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# クラスごとの使用率を定義\n",
        "ratios = [0.3, 0.2, 0.1, 0.1, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]\n",
        "print(sum(ratios))\n",
        "\n",
        "# クラスごとのインデックスを抽出\n",
        "indices_per_class = [[] for _ in range(10)]\n",
        "for idx, (_, label) in enumerate(train_dataset):\n",
        "    indices_per_class[label].append(idx)\n",
        "\n",
        "# 使用率に基づいてインデックスをサンプリング\n",
        "imbalanced_indices = []\n",
        "for class_idx, ratio in enumerate(ratios):\n",
        "    n_samples = int(len(indices_per_class[class_idx]) * ratio)\n",
        "    imbalanced_indices.extend(indices_per_class[class_idx][:n_samples])\n",
        "\n",
        "\n",
        "# インバランスなデータセットを作成\n",
        "imbalanced_train_dataset = Subset(train_dataset, imbalanced_indices)\n",
        "\n",
        "# train と validation に分割（validation は 10%）\n",
        "train_size = int(0.9 * len(imbalanced_train_dataset))\n",
        "val_size = len(imbalanced_train_dataset) - train_size\n",
        "imbalanced_train_dataset, val_dataset = random_split(imbalanced_train_dataset, [train_size, val_size])\n",
        "\n",
        "# DataLoader を作成\n",
        "trainloader = DataLoader(imbalanced_train_dataset, batch_size=64, shuffle=True)\n",
        "valloader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# 分割の結果を確認\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "IAoCGDo53SOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# バランス確認用のサンプル画像を表示\n",
        "def show_samples(dataset, num_samples=100):\n",
        "    loader = DataLoader(dataset, batch_size=num_samples, shuffle=True)\n",
        "    images, labels = next(iter(loader))\n",
        "    images = images[:num_samples]\n",
        "    labels = labels[:num_samples]\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i in range(num_samples):\n",
        "        plt.subplot(10, 10, i + 1)\n",
        "        plt.imshow(images[i].permute(1, 2, 0) * 0.5 + 0.5)  # デノーマライズ\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(labels[i].item(), fontsize=8)\n",
        "    plt.suptitle(\"Sample Images with Class Labels\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# サンプル画像を表示して確認\n",
        "print(\"教師データのサンプルを表示（クラスバランス確認）:\")\n",
        "\n",
        "show_samples(imbalanced_train_dataset)"
      ],
      "metadata": {
        "id": "zJQprRCfEI37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ネットワークは、CIFAR-10 での通常の画像分類のものとほぼ同じですが、バッチ正規化を導入しています。"
      ],
      "metadata": {
        "id": "bLYsBp7tgg0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(3, 6, 5), nn.BatchNorm2d(6), nn.ReLU())\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Sequential(nn.Conv2d(6, 16, 5), nn.BatchNorm2d(16), nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(nn.Linear(16 * 5 * 5, 120), nn.BatchNorm1d(120), nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(nn.Linear(120, 84), nn.BatchNorm1d(84), nn.ReLU())\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.conv1(x))\n",
        "        x = self.pool(self.conv2(x))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        return self.fc3(x)\n"
      ],
      "metadata": {
        "id": "QKJBZyT13ZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 課題３\n",
        "\n",
        "まず最後まで実行し、様子を確認します。\n",
        "\n",
        "その上でクロスエントロピー損失関数に、クラスのバランスを考慮するように変更してみましょう。"
      ],
      "metadata": {
        "id": "NcTnTElyM6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルのインスタンス化\n",
        "net = Net().to(device)\n",
        "print(net)\n",
        "\n",
        "# inverse_ratios =         # ratios から 1/ratios に変換\n",
        "# inverse_ratios = torch.tensor(inverse_ratios).to(device)\n",
        "\n",
        "# クロスエントロピー損失関数\n",
        "criterion = nn.CrossEntropyLoss(weight=None)\n",
        "\n",
        " # Adam オプティマイザ\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "TtIk7ek-Zyc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_epoch = 100     # 最大エポック数\n",
        "patience = 5       # 改善が見られないエポック数の許容回数\n",
        "trigger_times = 0  # 改善が見られないエポック数のカウンター\n",
        "\n",
        "best_val_loss = float(\"inf\")  # 初期値として無限大を設定\n",
        "train_losses = []  # 学習データセットの損失を保存するリスト\n",
        "val_losses = []  # 検証データセットの損失を保存するリスト\n",
        "\n",
        "# エポック数のループ\n",
        "for epoch in range(max_epoch):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # 学習データセットからミニバッチを得るたびに…\n",
        "    for i, data in enumerate(trainloader , 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)  # 入力データをGPUに送る\n",
        "        labels = labels.to(device)  # ラベルをGPUに送る\n",
        "\n",
        "        optimizer.zero_grad()  # 勾配の初期化\n",
        "\n",
        "        outputs = net(inputs)  # ネットワークに入力データを渡して出力を取得\n",
        "        loss = criterion(outputs, labels)  # 損失を計算\n",
        "        loss.backward()  # 逆伝播を行い、勾配を計算\n",
        "        optimizer.step()  # パラメータを更新\n",
        "\n",
        "        running_loss += loss.item()  # ミニバッチの損失を累積\n",
        "\n",
        "    # エポックごとの訓練データセットに対する平均損失を計算\n",
        "    train_loss = running_loss / len(trainloader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    # 検証データセットに対する損失を計算\n",
        "    val_loss = 0.0\n",
        "    net.eval()  # モデルを評価モードに切り替える\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # 検証データセットからミニバッチを得るたびに…\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)  # 入力データをGPUに送る\n",
        "            labels = labels.to(device)  # ラベルをGPUに送る\n",
        "\n",
        "            outputs = net(images)  # ネットワークに入力データを渡して出力を取得\n",
        "            loss = criterion(outputs, labels)  # 損失を計算\n",
        "            val_loss += loss.item()  # 損失を累積\n",
        "\n",
        "    # エポックごとの検証データセットに対する平均損失を計算\n",
        "    val_loss = val_loss / len(valloader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # 損失の値をグラフで表示\n",
        "    plt.clf()  # 前のグラフをクリア\n",
        "    plt.plot(train_losses, label='Training loss')  # 訓練データセットの損失\n",
        "    plt.plot(val_losses, label='Validation loss')  # 検証データセットの損失をプロット\n",
        "    plt.xlabel('Epoch')  # x軸のラベルを設定\n",
        "    plt.ylabel('Loss')  # y軸のラベルを設定\n",
        "    plt.xlim(left=0)  # x軸の表示範囲を設定\n",
        "    plt.ylim(bottom=0)  # y軸の表示範囲を設定\n",
        "    plt.legend()  # 凡例を表示\n",
        "    plt.show()  # グラフを表示\n",
        "\n",
        "    # エポックごとの損失を出力\n",
        "    print(\"Epoch:\", epoch + 1)\n",
        "    print(\"Train loss     : \", train_loss)\n",
        "    print(\"Validation loss: \", val_loss)\n",
        "\n",
        "    # 検証データセットに対する損失が改善しない場合の処理\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss  # 最良の検証データセット損失を更新\n",
        "        trigger_times = 0  # 改善が見られないエポック数をリセット\n",
        "    else:\n",
        "        trigger_times += 1  # 改善が見られないエポック数をカウントアップ\n",
        "        if trigger_times >= patience:  # 許容回数を超えた場合の処理\n",
        "            print(f\"{epoch + 1} エポックで早期終了\")  # 早期終了のメッセージを出力\n",
        "            break  # 学習を終了\n",
        "\n",
        "print('学習終了')"
      ],
      "metadata": {
        "id": "ix6eyIpS3bF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0  # 正解数のカウンターを初期化\n",
        "total = 0  # 全体の画像数のカウンターを初期化\n",
        "\n",
        "# 訓練モードでの計算を停止（推論モードに切り替える）\n",
        "with torch.no_grad():\n",
        "    # テストデータセットに対してループ\n",
        "    for data in testloader:\n",
        "        images, labels = data  # ミニバッチごとの画像とラベルを取得\n",
        "        images = images.to(device)  # GPUに画像を送る\n",
        "        labels = labels.to(device)  # GPUにラベルを送る\n",
        "\n",
        "        outputs = net(images)  # ネットワークに画像を入力し、出力を取得\n",
        "        _, predicted = torch.max(outputs.data, 1)  # 出力の中で最大の値を持つクラスを予測として取得\n",
        "        total += labels.size(0)  # ミニバッチ内の画像数を全体の画像数に加算\n",
        "        correct += (predicted == labels).sum().item()  # 予測が正しい場合、正解数をカウントアップ\n",
        "\n",
        "# 精度を計算して表示\n",
        "print('テスト画像における精度 %d %%' % (100 * correct / total))"
      ],
      "metadata": {
        "id": "1jitGSVJL-xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像を表示するための関数\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # 非正規化\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# テストデータの画像を表示し、正解と推定値を表示する関数\n",
        "def visualize_test_predictions(start_idx, end_idx):\n",
        "    # テストデータローダーを作成\n",
        "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=1,\n",
        "                                             shuffle=False, num_workers=2)\n",
        "\n",
        "    # 指定したインデックス範囲の画像とラベルを取得\n",
        "    images, labels = zip(*[(data[0], data[1]) for i, data in enumerate(testloader) if start_idx <= i < end_idx])\n",
        "\n",
        "    # モデルの予測結果を格納するリストを初期化\n",
        "    predicted_labels = []\n",
        "\n",
        "    # 推論モードで計算を停止\n",
        "    with torch.no_grad():\n",
        "        # 画像ごとに予測を行う\n",
        "        for image in images:\n",
        "            image = image.to(device)  # GPUに画像を送る\n",
        "            outputs = net(image)  # ネットワークに画像を入力し、出力を得る\n",
        "            _, predicted = torch.max(outputs, 1)  # 出力の中で最大の値を持つクラスを予測として取得\n",
        "            predicted_labels.append(predicted.item())  # 予測結果をリストに追加\n",
        "\n",
        "    # 画像とラベルを表示\n",
        "    for i in range(len(images)):\n",
        "        print(f\"画像 {start_idx + i}\")\n",
        "        imshow(torchvision.utils.make_grid(images[i]))  # 画像をグリッド形式で表示\n",
        "        print(f\"正解： {classes[labels[i]]}\")  # 正解ラベルを表示\n",
        "        print(f\"推定： {classes[predicted_labels[i]]}\\n\")  # 予測ラベルを表示\n",
        "\n",
        "# 例: インデックス範囲 0 から 5 の画像を表示\n",
        "visualize_test_predictions(0, 5)"
      ],
      "metadata": {
        "id": "ToI9iEhSL_Si"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}