{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxqwECxSXE5JjEz9zEewgJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/text/Using_LLM_via_OpenRouter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📚 OpenRouter API 呼び出し演習\n",
        "\n",
        "このノートブックは、OpenRouter を使ってさまざまな LLM (大規模言語モデル) の API を呼び出す練習をするための教材です。\n",
        "\n",
        "解説を読み、Markdown セルに記載されている **サンプルコード（解答例）** を参考にしながら、 **Python コードセル（練習問題）** の `...` の部分を埋めて、コードを実行してください。"
      ],
      "metadata": {
        "id": "-nYg2QaD4Q8D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🌎 1. OpenRouter とは？\n",
        "\n",
        "OpenRouter は、**「LLM のルーター（仲介・振り分け役）」** のようなサービスです。\n",
        "\n",
        "通常、OpenAI のモデル (GPT) を使いたい場合は OpenAI の API キーが、Anthropic のモデル (Opus, Sonnet など) を使いたい場合は Anthropic の API キーが... というように、モデル提供会社ごとに契約とAPIキーが必要で、呼び出し方も少しずつ違います。\n",
        "\n",
        "OpenRouter を使うと、以下の利点があります。\n",
        "\n",
        "1.  **単一の API キー:** OpenRouter の API キーが 1 つあれば、OpenRouter が提携している数十種類以上のモデル（OpenAI, Google, Anthropic, Meta, Mistral, Qwen, DeepSeek など）をすべて呼び出せます。\n",
        "2.  **共通の API 形式:** すべてのモデルを、OpenAI の API と**まったく同じ形式**で呼び出せます。\n",
        "3.  **コスト管理:** 利用料金は OpenRouter にまとめて支払う（クレジットカード登録）だけで済み、モデルごとのコストもダッシュボードで一目でわかります。\n",
        "4.  **安価・オープンなモデルへのアクセス:** GPT-4 のような高性能モデルだけでなく、`Llama ` や `Qwen`、`DeepSeek` といった、非常に安価（または無料枠がある）で高性能なオープンソースモデルにも簡単にアクセスできます。\n",
        "\n",
        "この演習では、この「OpenRouter を OpenAI 互換 API として利用する」方法を学びます。"
      ],
      "metadata": {
        "id": "1piiaAkP4SU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🔑 2. 準備: API キーとライブラリのインストール\n",
        "\n",
        "API を呼び出すための準備をします。\n",
        "\n",
        "### ステップ 2-1: OpenRouter の API キーを Colab に設定する\n",
        "\n",
        "まず、OpenRouter の API キーを取得し、Colab のシークレット機能に保存します。\n",
        "\n",
        "1.  [OpenRouter のサイト](https://openrouter.ai/keys) にアクセスし、アカウント登録・ログインします。\n",
        "2.  （初回利用時）クレジットカード情報を登録し、利用上限額（例: $10）を設定します。\n",
        "3.  「Keys」ページで「+ Create Key」を押し、キーを発行します。（`sk-or-...` で始まる文字列です）\n",
        "4.  Colab の画面左側にある「🔑」（鍵マーク）アイコンをクリックします。\n",
        "5.  「新しいシークレットを追加」を押します。\n",
        "    * **名前 (name):** `OPENROUTER_API_KEY`\n",
        "    * **値 (value):** 先ほどコピーした `sk-or-...` のキー\n",
        "6.  「ノートブックへのアクセス」を **オン (有効)** にします。\n",
        "\n",
        "\n",
        "\n",
        "### ステップ 2-2: 必要なライブラリのインストール\n",
        "\n",
        "OpenRouter は OpenAI API と互換性があるため、**`openai` ライブラリ**をそのまま使います。"
      ],
      "metadata": {
        "id": "JDec5ZTR4gmK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8xUqQZ74KqN"
      },
      "outputs": [],
      "source": [
        "# 練習 2-2: openai ライブラリをインストールします\n",
        "# (ヒント: !pip install ...)\n",
        "\n",
        "...\n",
        "\n",
        "print(\"openai ライブラリのインストールが完了しました。\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🔌 3. クライアントの初期化\n",
        "\n",
        "API を呼び出すための「クライアント」を設定します。\n",
        "\n",
        "シークレットから API キーを読み込み、OpenAI ライブラリのクライアントを作成します。\n",
        "このとき、`base_url` (APIの接続先) を OpenAI 公式ではなく、OpenRouter の URL (`https://openrouter.ai/api/v1`) に指定するのが**最重要ポイント**です。\n",
        "\n",
        "### 📑 サンプルコード (クライアント初期化)\n",
        "\n",
        "```python\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# 1. Colab シークレットからキーを取得\n",
        "my_openrouter_key = userdata.get(\"OPENROUTER_API_KEY\")\n",
        "\n",
        "# 2. クライアントを初期化\n",
        "client = OpenAI(\n",
        "  # 接続先を OpenRouter に指定 (重要)\n",
        "  base_url=\"https://openrouter.ai/api/v1,\n",
        "  # 取得した API キーを指定\n",
        "  api_key=my_openrouter_key,\n",
        ")\n",
        "\n",
        "print(\"OpenRouter クライアントの初期化に成功しました。\")"
      ],
      "metadata": {
        "id": "WcgZNUNk4sSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "# 練習 3-1: Colab シークレットから \"OPENROUTER_API_KEY\" という名前のキーを取得\n",
        "my_openrouter_key = userdata.get(\"...\") # 👈 ここにシークレット名を入力\n",
        "\n",
        "# 練習 3-2: OpenAI クライアントを初期化\n",
        "client = OpenAI(\n",
        "  # 接続先 (base_url) を OpenRouter のエンドポイントに指定\n",
        "  base_url= \"...\" , # 👈 ここに OpenRouter の URL を入力\n",
        "\n",
        "  # API キー (api_key) に上で取得した変数を指定\n",
        "  api_key= ...  , # 👈 ここに my_openrouter_key 変数を入力\n",
        ")"
      ],
      "metadata": {
        "id": "lUdwC58F4uO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 📜 4. モデルタイプ1: Text Completion (単純なテキスト補完)\n",
        "\n",
        "これは、LLM の API としては古い形式 (`/v1/completions`) ですが、「与えられた文章の**続き**をそのまま書く」というモデルの基本的な動作を理解するのに役立ちます。\n",
        "\n",
        "* **API:** `client.completions.create()` を使います。\n",
        "* **特徴:** 対話形式ではなく、単一の「プロンプト (prompt)」を与えます。\n",
        "* **用途:** 指示に従わせる (Reasoning) というよりは、文章の続きを予測させる (Non-Reasoning) タスクに向いています。\n",
        "* **モデル例:** `nousresearch/nous-hermes-llama-2-7b` (Free Tier), `openai/gpt-3.5-turbo-instruct`\n",
        "\n",
        "### 📑 サンプルコード (Text Completion)\n",
        "\n",
        "```python\n",
        "# 1. Text Completion をサポートするモデル名を指定\n",
        "# (Free Tier のモデルを使ってみます)\n",
        "model_name = \"nousresearch/nous-hermes-llama-2-7b\"\n",
        "\n",
        "# 2. 続きを書いてほしいプロンプト\n",
        "prompt_text = \"昔々あるところに、\"\n",
        "\n",
        "# 3. API を呼び出す\n",
        "response = client.completions.create(\n",
        "    model=model_name,\n",
        "    prompt=prompt_text,\n",
        "    max_tokens=50 # 生成する最大の長さ\n",
        ")\n",
        "\n",
        "# 4. 結果（続きの文章）を表示\n",
        "print(f\"--- {model_name} が生成した続き ---\")\n",
        "print(prompt_text + response.choices[0].text)"
      ],
      "metadata": {
        "id": "zuM5Uscd52Jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 練習 4-1: モデル名を指定 (例: \"deepseek/deepseek-chat-v3-0324\")\n",
        "model_name = \"...\" # 👈 ここにモデル名を入力\n",
        "\n",
        "# 練習 4-2: 続きを書いてほしいプロンプト\n",
        "# (例: \"昔々あるところに\")\n",
        "prompt_text = \"...\" # 👈 ここにプロンプトを入力\n",
        "\n",
        "# 練習 4-3: client.completions.create() を呼び出す\n",
        "# (ヒント: model, prompt, max_tokens が必要です)\n",
        "\n",
        "# client.completions.create メソッド（メソッドとは関数みたいなもの）を実行し，\n",
        "# 戻り値を response として受け取ってください\n",
        "... = ... (\n",
        "    model=model_name,\n",
        "    prompt=prompt_text,\n",
        "    max_tokens=30\n",
        ")\n",
        "\n",
        "# 練習 4-4: 結果（プロンプト + 続き）を表示\n",
        "# (ヒント: 続きは response.choices[0].text に入っています)\n",
        "generated_text = ... # 👈 ここに続きのテキストを取り出すコードを入力\n",
        "\n",
        "print(f\"--- {model_name} による補完結果 ---\")\n",
        "print(prompt_text + generated_text)"
      ],
      "metadata": {
        "id": "zg90mnDI58Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🧠 5. モデルタイプ2: Chat Completion (対話・指示実行)\n",
        "\n",
        "現在、API 利用の主流となっている形式 (`/v1/chat/completions`) です。\n",
        "単純な続きを書くだけでなく、役割を与えたり、複雑な指示 (Reasoning) に従わせたりすることができます。\n",
        "\n",
        "* **API:** `client.chat.completions.create()` を使います。\n",
        "* **特徴:** `messages` リストを使って、役割 (`role`) ごとに発言を渡します。\n",
        "    * `system`: AI の役割や前提条件を指示します (例: 「あなたはPythonの専門家です」)。\n",
        "    * `user`: ユーザーからの質問や指示です。\n",
        "    * `assistant`: (オプション) AI の過去の応答例です。\n",
        "* **モデル例:**\n",
        "    * `qwen/qwen3-coder-flash` (コーディング向き・安価)\n",
        "    * `meta-llama/llama-3.1-8b-instruct` (高性能・安価)\n",
        "\n",
        "### 📑 サンプルコード (Chat Completion)\n",
        "\n",
        "```python\n",
        "# 1. Chat Completion モデル名を指定 (コーディングに強いモデル)\n",
        "model_name = \"deepseek/deepseek-coder-v2-lite\"\n",
        "\n",
        "# 2. 送信するメッセージのリストを作成\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"あなたはPythonコーディングの専門家です。\"},\n",
        "    {\"role\": \"user\", \"content\": \"Pythonで、リストの偶数だけを返す関数を書いてください。\"}\n",
        "]\n",
        "\n",
        "# 3. API を呼び出す\n",
        "response = client.chat.completions.create(\n",
        "    model=model_name,\n",
        "    messages=messages\n",
        ")\n",
        "\n",
        "# 4. 結果（回答）を表示\n",
        "print(f\"--- {model_name} からの回答 ---\")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "plC5fbQi8V4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 練習 5-1: モデル名を指定 (例: \"qwen/qwen-2-7b-instruct\")\n",
        "model_name = \"...\" # 👈 ここにチャットモデル名を入力\n",
        "\n",
        "# 練習 5-2: メッセージリストを作成 (system と user)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"あなたは日本語で回答する、親切なAIアシスタントです。\"},\n",
        "    {\"role\": \"user\", \"content\": \"OpenRouterの利点を2つ教えてください。\"}\n",
        "]\n",
        "\n",
        "# 練習 5-3: client.chat.completions.create() を呼び出す\n",
        "# (ヒント: model と messages が必要です)\n",
        "... = ... (\n",
        "    model= ... , # 👈 ここに model_name 変数を入力\n",
        "    messages= ...  # 👈 ここに messages 変数を入力\n",
        ")\n",
        "\n",
        "# 練習 5-4: 結果（回答）を表示\n",
        "# (ヒント: 回答は response.choices[0].message.content に入っています)\n",
        "answer = ... # 👈 ここに回答を取り出すコードを入力\n",
        "\n",
        "print(f\"--- {model_name} からの回答 ---\")\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "bIPz1uFh8QQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 🎉 6. まとめ\n",
        "\n",
        "お疲れ様でした！この演習では、OpenRouter を通じて2つの異なるタイプの LLM を呼び出す方法を学びました。\n",
        "\n",
        "1.  **Text Completion (<code>completions.create</code>):**\n",
        "    * プロンプトの「続き」を生成する。\n",
        "2.  **Chat Completion (<code>chat.completions.create</code>):**\n",
        "    * 現在の主流。`messages` リストで対話や指示 (Reasoning) を行う。"
      ],
      "metadata": {
        "id": "hQGM7Yo89P3T"
      }
    }
  ]
}
