{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvYNLoZmQTRm1IHgrJ7+u/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/basics/neural.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ©Ÿæ¢°å­¦ç¿’ä½“é¨“ãƒ—ãƒ­ã‚°ãƒ©ãƒ \n",
        "\n",
        "åŸºæœ¬çš„ãªåˆ†é¡å•é¡Œã‚’ç”¨ã„ã¦æ©Ÿæ¢°å­¦ç¿’ã‚’ä½“é¨“ã—ã¤ã¤ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®ä»•çµ„ã¿ã‚„ä½¿ã„æ–¹ã‚’ç†è§£ã—ã¾ã—ã‚‡ã†ã€‚\n",
        "\n",
        "<a title=\"Dake, Mysid, CC BY 1.0 &lt;https://creativecommons.org/licenses/by/1.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Neural_network.svg\"><img width=\"512\" alt=\"Neural network\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Neural_network.svg/512px-Neural_network.svg.png?20210102213114\"></a>\n",
        "\n",
        "## å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "\n",
        "ä»¥ä¸‹ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ï¼š\n",
        "- `numpy`: æ•°å€¤è¨ˆç®—ã‚’åŠ¹ç‡çš„ã«è¡Œã†ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
        "- `scikit-learn`: æ©Ÿæ¢°å­¦ç¿’ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚åˆ†é¡ã€å›å¸°ã€ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ãªã©æ§˜ã€…ãªæ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã‚’æä¾›ã—ã¾ã™ã€‚\n",
        "- `matplotlib`: ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚ã‚°ãƒ©ãƒ•ã‚„å›³ã‚’ç°¡å˜ã«æç”»ã§ãã¾ã™ã€‚\n",
        "- `pandas`: ãƒ‡ãƒ¼ã‚¿æ“ä½œã¨åˆ†æã®ãŸã‚ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã€‚"
      ],
      "metadata": {
        "id": "GBGv21QTKGZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXEFK3EIKFwY"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.utils import shuffle\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "random_state = 42  # ä¹±æ•°ã®ã‚·ãƒ¼ãƒ‰\n",
        "\n",
        "import warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "\n",
        "# ConvergenceWarningã‚’ç„¡è¦–ã™ã‚‹ã‚ˆã†ã«è¨­å®š\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®é¸æŠ\n",
        "\n",
        "ã„ãã¤ã‹ã®æœ‰åãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‹ã‚‰é¸æŠã§ãã¾ã™ã€‚å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ¦‚è¦ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š\n",
        "\n",
        "| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå | ç›®çš„ | ç‰¹å¾´é‡æ•° | å„ç‰¹å¾´é‡ |\n",
        "| --- | --- | --- | --- |\n",
        "| Iris | 3ç¨®é¡ã®ã‚¢ãƒ¤ãƒ¡ã®å“ç¨®ã‚’åˆ†é¡ | 4 | ã‚¬ã‚¯ã®é•·ã•ãƒ»å¹…ã€èŠ±å¼ã®é•·ã•ãƒ»å¹… |\n",
        "| Wine | 3ç¨®é¡ã®ãƒ¯ã‚¤ãƒ³ã®ã‚¿ã‚¤ãƒ—ã‚’åˆ†é¡ | 13 | ã‚¢ãƒ«ã‚³ãƒ¼ãƒ«åº¦æ•°ã€ãƒã‚°ãƒã‚·ã‚¦ãƒ å«æœ‰é‡ãªã© |\n",
        "| Breast Cancer | è‰¯æ€§ãƒ»æ‚ªæ€§ã®è…«ç˜ã‚’åˆ†é¡ | 30 | åŠå¾„ã€ãƒ†ã‚¯ã‚¹ãƒãƒ£ã€å‘¨å›²é•·ã€é¢ç©ãªã© |\n",
        "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€ä½¿ç”¨ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "GqvTZYiVKWl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"Iris\" # @param [\"Iris\",\"Wine\",\"Breast Cancer\"]\n",
        "\n",
        "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import sys\n",
        "from IPython.display import display\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹é–¢æ•°\n",
        "def load_dataset(dataset_name):\n",
        "    if dataset_name == \"Iris\":\n",
        "        dataset = load_iris()\n",
        "        feature_names = dataset.feature_names\n",
        "        # feature_names = [\"ã‚¬ã‚¯ã®é•·ã•\", \"ã‚¬ã‚¯ã®å¹…\", \"èŠ±å¼ã®é•·ã•\", \"èŠ±å¼ã®å¹…\"]\n",
        "        target_names = dataset.target_names\n",
        "    elif dataset_name == \"Wine\":\n",
        "        dataset = load_wine()\n",
        "        feature_names = dataset.feature_names\n",
        "        target_names = dataset.target_names\n",
        "    elif dataset_name == \"Breast Cancer\":\n",
        "        dataset = load_breast_cancer()\n",
        "        feature_names = dataset.feature_names\n",
        "        # target_names = dataset.target_names\n",
        "        target_names = [\"Malignant (bad)\", \"Benign (good)\"]\n",
        "    else:\n",
        "        print(\"èª¤ã£ãŸç•ªå·ã§ã™\")\n",
        "        return None, None, None, None, None, None\n",
        "\n",
        "    X = dataset.data\n",
        "    y = dataset.target\n",
        "    return dataset.data, dataset.target, pd.DataFrame(X, columns=feature_names), pd.Series(y, name=\"CLASS\"), dataset_name, target_names, feature_names\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ­ãƒ¼ãƒ‰\n",
        "X, y, feature_df, y_df, dataset_name, target_names, feature_names = load_dataset(dataset_name)\n",
        "\n",
        "if X is not None:\n",
        "    # ã‚¯ãƒ©ã‚¹åã‚’è¿½åŠ \n",
        "    y_class_names = y_df.map(lambda x: target_names[x]).rename(\"CLASS_NAME\")\n",
        "\n",
        "    # ç‰¹å¾´é‡ã¨ã‚¯ãƒ©ã‚¹ã€ã‚¯ãƒ©ã‚¹åã‚’çµåˆã—ãŸDataFrameã‚’ä½œæˆ\n",
        "    df_combined = pd.concat([y_df, y_class_names, feature_df], axis=1)\n",
        "\n",
        "    # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«\n",
        "    df_shuffled = shuffle(df_combined, random_state=42).reset_index(drop=True)\n",
        "\n",
        "    # è¡¨ç¤º\n",
        "    display(df_shuffled.head())"
      ],
      "metadata": {
        "id": "iZ1TW4sRKTEf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œ 1**\n",
        "- ã²ã¨ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆèŠ±ï¼Œãƒ¯ã‚¤ãƒ³ï¼Œæ‚£è€…ï¼‰ã¯è¡Œã§ã™ã‹ï¼Œåˆ—ã§ã™ã‹ï¼Ÿ\n",
        "- ã“ã®è¡¨ã§ã¯ï¼Œå„ã‚µãƒ³ãƒ—ãƒ«ã®\n",
        " - ã‚¯ãƒ©ã‚¹ã¯ã©ã“ã§ã™ã‹ï¼Ÿ\n",
        " - ï¼‘ã¤ã®ã‚µãƒ³ãƒ—ãƒ«ã”ã¨ã«ä½•æ¬¡å…ƒã®ç‰¹å¾´é‡ãŒã‚ã‚Šã¾ã™ã‹ï¼Ÿ\n",
        "- ä»Šå›ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å„ã‚µãƒ³ãƒ—ãƒ«ãŒã‚‚ã¤ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã«åŸºã¥ã„ã¦ã€ãã®ãƒ‡ãƒ¼ã‚¿ãŒå„ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ ï¼¿ï¼¿ï¼¿ï¼¿ ã‚’ãã‚Œãã‚Œè¨ˆç®—ã—ã€ãã®å€¤ãŒæœ€å¤§ã¨ãªã‚‹ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "PeZkpNFxapUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å¯è¦–åŒ–\n",
        "\n",
        "### ãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç†è§£ã™ã‚‹ãŸã‚ã®å¯è¦–åŒ–\n",
        "\n",
        "æ©Ÿæ¢°å­¦ç¿’ã®ç¬¬ä¸€æ­©ã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚’ç†è§£ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ã€‚\n",
        "\n",
        "ã¾ãšã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç‰¹å¾´é‡ã®ã†ã¡2ã¤ã‚’é¸ã‚“ã§æ•£å¸ƒå›³ã‚’æãã€ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã¨ã‚¯ãƒ©ã‚¹ã”ã¨ã®é–¢ä¿‚ã‚’è¦–è¦šåŒ–ã—ã¾ã™ã€‚\n"
      ],
      "metadata": {
        "id": "tKnOnqahKpGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ä»»æ„ã®ã‚¯ãƒ©ã‚¹æ•°ã«å¯¾å¿œã™ã‚‹ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°\n",
        "def generate_color_palette(n_colors):\n",
        "    return plt.cm.get_cmap('tab10', n_colors)\n",
        "\n",
        "# ç‰¹å¾´é‡ã®ã†ã¡ã€2ã¤ã‚’é¸ã‚“ã§æ•£å¸ƒå›³ã‚’æãé–¢æ•°\n",
        "def plot_2d_projection(X, y, feature_indices, feature_names, target_names, title=\"\"):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    palette = generate_color_palette(len(np.unique(y)))\n",
        "    for target in np.unique(y):\n",
        "        subset = X[y == target]\n",
        "        plt.scatter(subset[:, feature_indices[0]], subset[:, feature_indices[1]], label=f\"Class {target}: {target_names[target]}\", color=palette(target))\n",
        "    plt.xlabel(f\"Feature {feature_indices[0]}: {feature_names[0]}\")\n",
        "    plt.ylabel(f\"Feature {feature_indices[1]}: {feature_names[1]}\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›ã‚’é¸ã‚“ã§ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "if X is not None:\n",
        "    plot_2d_projection(X, y, feature_indices=[0, 1], feature_names=feature_names, target_names=target_names, title=f\"{dataset_name} Data - Features 0 and 1\")"
      ],
      "metadata": {
        "id": "SgJ_PnnmKrzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²\n",
        "\n",
        "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’1ã¤ã®å¡Šã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã®ã§ã¯ãªãã€ä»¥ä¸‹ã®3ã¤ã®éƒ¨åˆ†ã«åˆ†å‰²ã—ã¾ã™ï¼š\n",
        "\n",
        "1. **æ•™å¸«ãƒ‡ãƒ¼ã‚¿ (training data)**:\n",
        "   ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã¯ç‰¹å¾´é‡ã¨ç›®æ¨™å¤‰æ•°ï¼ˆãƒ©ãƒ™ãƒ«ï¼‰ã®é–¢ä¿‚ã‚’å­¦ã³ã¾ã™ã€‚\n",
        "\n",
        "2. **æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ (validation data)**:\n",
        "   ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã—ã€ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ã«ä½¿ç”¨ã—ã¾ã™ã€‚æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œãªã„ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã†ã“ã¨ã§ã€ãƒ¢ãƒ‡ãƒ«ã®æ±åŒ–æ€§èƒ½ã‚’ç¢ºèªã—ã¾ã™ã€‚\n",
        "\n",
        "3. **ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ (test data)**:\n",
        "   æœ€çµ‚çš„ãªãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã—ã¾ã™ã€‚ã“ã®ãƒ‡ãƒ¼ã‚¿ã‚‚æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã«ã¯å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ€§èƒ½ãŒé«˜ã‘ã‚Œã°ã€ãƒ¢ãƒ‡ãƒ«ã¯æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚è‰¯å¥½ã«å‹•ä½œã™ã‚‹ã“ã¨ãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚\n"
      ],
      "metadata": {
        "id": "_oBLnuEcK2CD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hotã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°\n",
        "encoder = OneHotEncoder()\n",
        "y_onehot = encoder.fit_transform(y.reshape(-1, 1)).toarray()\n",
        "\n",
        "# ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰² (70% training, 15% validation, 15% test)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y_onehot, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# åˆ†å‰²çµæœã®ç¢ºèª\n",
        "\n",
        "# DataFrameã®ä½œæˆ\n",
        "def create_df(X, y, feature_names, target_names):\n",
        "    y_classes = [target_names[i] for i in y.argmax(axis=1)]\n",
        "    y_class_series = pd.Series(y_classes, name=\"CLASS_NAME\")\n",
        "    return pd.concat([pd.DataFrame(X, columns=feature_names), y_class_series], axis=1)\n",
        "\n",
        "df_train = create_df(X_train, y_train, feature_names, target_names)\n",
        "df_val = create_df(X_val, y_val, feature_names, target_names)\n",
        "df_test = create_df(X_test, y_test, feature_names, target_names)\n",
        "\n",
        "# è¡¨ç¤º\n",
        "print(\"\\n[æ•™å¸«ãƒ‡ãƒ¼ã‚¿]\")\n",
        "print(\"ã‚µã‚¤ã‚º:\", X_train.shape)\n",
        "display(df_train.head())\n",
        "\n",
        "print(\"\\n[æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿]\")\n",
        "print(\"ã‚µã‚¤ã‚º:\", X_val.shape)\n",
        "display(df_val.head())\n",
        "\n",
        "print(\"\\n[ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿]\")\n",
        "print(\"ã‚µã‚¤ã‚º:\", X_test.shape)\n",
        "display(df_test.head())"
      ],
      "metadata": {
        "id": "rhaAbZgLK1Gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼’**\n",
        "ã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚’ï¼“å€‹ã«åˆ†å‰²ã—ã¾ã—ãŸï¼ãã‚Œãã‚Œä½•ã«ä½¿ã‚ã‚Œã¾ã™ã‹ï¼Ÿ\n",
        "\n",
        "- æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã€€ï¼š\n",
        "- æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã€€ï¼š\n",
        "- ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼š\n"
      ],
      "metadata": {
        "id": "pRcMbvK1tifq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
        "\n",
        "æ¬¡ã«ã€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚ã“ã“ã§ã¯ã€scikit-learnã®`MLPClassifier`ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
        "\n",
        "### ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ¦‚è¦\n",
        "\n",
        "ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªä¸»è¦ãªè¦ç´ ã§æ§‹æˆã•ã‚Œã¾ã™ï¼š\n",
        "\n",
        "1. **å…¥åŠ›å±¤ (Input Layer)**:\n",
        "   ç‰¹å¾´é‡ã‚’å…¥åŠ›ã™ã‚‹å±¤ã§ã™ã€‚ç‰¹å¾´é‡ã®æ•°ã ã‘ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "\n",
        "2. **éš ã‚Œå±¤ (Hidden Layer)**:\n",
        "   å…¥åŠ›å±¤ã¨å‡ºåŠ›å±¤ã®é–“ã«ã‚ã‚‹å±¤ã§ã™ã€‚ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å­¦ç¿’èƒ½åŠ›ã‚’é«˜ã‚ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚éš ã‚Œå±¤ã®æ•°ã‚„å„å±¤ã®ãƒãƒ¼ãƒ‰æ•°ã¯ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã™ã€‚\n",
        "\n",
        "3. **å‡ºåŠ›å±¤ (Output Layer)**:\n",
        "   ã‚¯ãƒ©ã‚¹ã®æ•°ã ã‘ãƒãƒ¼ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚ã“ã“ã§ã¯ã€å„ãƒãƒ¼ãƒ‰ãŒç‰¹å®šã®ã‚¯ãƒ©ã‚¹ã«å¯¾å¿œã—ã¾ã™ã€‚\n",
        "\n",
        "### ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°ã®é¸æŠ\n",
        "\n",
        "ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã¨ã€plot_2d_projectionã§é¸ã‚“ã 2æ¬¡å…ƒã®ã¿ã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã®ã„ãšã‚Œã‹ã§å­¦ç¿’ã‚’è¡Œã„ã¾ã™ã€‚\n",
        "\n",
        "æœ€åˆã¯è¦–è¦šçš„ãªç†è§£ã®ãŸã‚ã«ã€2å€‹ã®ç‰¹å¾´é‡ã®ã¿ã‚’ç”¨ã„ã¾ã™ã€‚<br>\n",
        "ç²¾åº¦ã‚’ä¸Šã’ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã™ã«ã¯3å€‹ä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’ä½¿ã†ã¹ãã§ã™ã®ã§ã€`use_two_features = False` ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚ãã®å ´åˆã¯ç‰¹å¾´ç©ºé–“ã‚„æ±ºå®šå¢ƒç•Œã‚’å¯è¦–åŒ–ã§ããªããªã‚‹ã®ã§ã”æ³¨æ„ãã ã•ã„ã€‚"
      ],
      "metadata": {
        "id": "Oh3lkD5jK951"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2æ¬¡å…ƒã®ç‰¹å¾´é‡ã‚’é¸æŠã™ã‚‹é–¢æ•°\n",
        "def select_two_features(X, feature_indices):\n",
        "    return X[:, feature_indices]\n",
        "\n",
        "# ç‰¹å¾´é‡ã®æ¬¡å…ƒæ•°ã‚’é¸æŠã™ã‚‹ã‹ã©ã†ã‹\n",
        "use_two_features = True\n",
        "feature_indices = [0, 1]\n",
        "\n",
        "if use_two_features:\n",
        "    X_train_transformed = select_two_features(X_train, feature_indices)\n",
        "    X_val_transformed = select_two_features(X_val, feature_indices)\n",
        "    X_test_transformed = select_two_features(X_test, feature_indices)\n",
        "    clms = feature_df.columns[0:2]\n",
        "else:\n",
        "    X_train_transformed = X_train\n",
        "    X_val_transformed = X_val\n",
        "    X_test_transformed = X_test\n",
        "    clms = feature_df.columns"
      ],
      "metadata": {
        "id": "TbJcHsV-LPDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ## æå¤±é–¢æ•°ï¼ˆLoss Functionï¼‰ã®è§£èª¬\n",
        "\n",
        "æå¤±é–¢æ•°ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒã©ã‚Œã ã‘ã€Œ**é–“é•ã£ã¦ã„ã‚‹ã‹**ã€ã‚’æ¸¬ã‚‹ãŸã‚ã®**ãƒšãƒŠãƒ«ãƒ†ã‚£ç‚¹æ•°**ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã§ã™ã€‚å­¦ç¿’ã®ç›®æ¨™ã¯ã€ã“ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ç‚¹æ•°ã‚’ã©ã‚“ã©ã‚“å°ã•ãã—ã¦ã„ãã“ã¨ã§ã™ã€‚\n",
        "\n",
        "ã“ã“ã§ã¯ã€ä»£è¡¨çš„ãª3ã¤ã®æå¤±é–¢æ•°ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚\n",
        "\n",
        "#### **1. ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢ (Manhattan Distance / L1æå¤±)** ğŸ™ï¸\n",
        "\n",
        "* **è€ƒãˆæ–¹**: äºˆæ¸¬ã¨æ­£è§£ã®ã€Œå·®ã®çµ¶å¯¾å€¤ã€ã‚’åˆè¨ˆã—ã¾ã™ã€‚å„ã‚¯ãƒ©ã‚¹ã®ã‚ºãƒ¬ã‚’ãã®ã¾ã¾è¶³ã—åˆã‚ã›ã‚‹ã€ã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ„Ÿçš„ãªæ–¹æ³•ã§ã™ã€‚\n",
        "* **ç‰¹å¾´**: å¤–ã‚Œå€¤ï¼ˆæ¥µç«¯ã«å¤§ãã„é–“é•ã„ï¼‰ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„ã¨ã„ã†åˆ©ç‚¹ãŒã‚ã‚Šã¾ã™ã€‚\n",
        "* **è¨ˆç®—ä¾‹**:\n",
        "    * **ç†æƒ³ã®å‡ºåŠ›**: `[0, 1, 0]`\n",
        "    * **ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›**: `[0.1, 0.7, 0.2]`\n",
        "    * **æå¤±**: `|0 - 0.1| + |1 - 0.7| + |0 - 0.2| = 0.1 + 0.3 + 0.2 = 0.6`\n",
        "\n",
        "#### **2. ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ (Euclidean Distance / L2æå¤±)** ğŸ“\n",
        "\n",
        "* **è€ƒãˆæ–¹**: äºˆæ¸¬ã¨æ­£è§£ã®ã€Œå·®ã®2ä¹—ã€ã‚’åˆè¨ˆã—ã¾ã™ã€‚å¹¾ä½•å­¦çš„ãª\"ç›´ç·šè·é›¢\"ã®2ä¹—ã‚’è¨ˆç®—ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸ã§ã™ã€‚\n",
        "* **ç‰¹å¾´**: å·®ã‚’2ä¹—ã™ã‚‹ãŸã‚ã€**å¤§ããªé–“é•ã„ã«å¯¾ã—ã¦ã‚ˆã‚Šå³ã—ã„ãƒšãƒŠãƒ«ãƒ†ã‚£**ã‚’ä¸ãˆã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯å¤§ããå¤–ã™ã“ã¨ã‚’é¿ã‘ã‚‹ã‚ˆã†ã«å­¦ç¿’ãŒé€²ã¿ã¾ã™ã€‚\n",
        "* **è¨ˆç®—ä¾‹**:\n",
        "    * **ç†æƒ³ã®å‡ºåŠ›**: `[0, 1, 0]`\n",
        "    * **ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›**: `[0.1, 0.7, 0.2]`\n",
        "    * **æå¤±**: `(0 - 0.1)Â² + (1 - 0.7)Â² + (0 - 0.2)Â² = 0.01 + 0.09 + 0.04 = 0.14`\n",
        "\n",
        "#### **3. ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ (Cross-Entropy / Log Loss)** ğŸ”¥\n",
        "\n",
        "* **è€ƒãˆæ–¹**: 2ã¤ã®ã€Œç¢ºç‡åˆ†å¸ƒã€ãŒã©ã‚Œã ã‘ä¼¼ã¦ã„ãªã„ã‹ã‚’æ¸¬ã‚‹æŒ‡æ¨™ã§ã™ã€‚åˆ†é¡å•é¡Œã®å‡ºåŠ›ã¯ç¢ºç‡ãªã®ã§ã€æœ€ã‚‚ç†ã«ã‹ãªã£ãŸæ–¹æ³•ã§ã™ã€‚\n",
        "* **ç‰¹å¾´**: **ã€Œè‡ªä¿¡æº€ã€…ã«ã€å¤§é–“é•ã„ã—ãŸã¨ãã€ã«çˆ†ç™ºçš„ã«å¤§ããªãƒšãƒŠãƒ«ãƒ†ã‚£**ã‚’ä¸ãˆã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯è‡´å‘½çš„ãªé–“é•ã„ã‹ã‚‰å„ªå…ˆçš„ã«å­¦ç¿’ã™ã‚‹ãŸã‚ã€åŠ¹ç‡çš„ã«å­¦ç¿’ãŒé€²ã¿ã¾ã™ã€‚åˆ†é¡å•é¡Œã§ã¯æœ€ã‚‚æ¨™æº–çš„ã«ä½¿ã‚ã‚Œã¾ã™ã€‚\n",
        "* **è¨ˆç®—ä¾‹**: æ­£è§£ã‚¯ãƒ©ã‚¹ã«å¯¾ã™ã‚‹ç¢ºç‡ãŒä½ã„ã»ã©ã€æå¤±ã¯æ€¥æ¿€ã«å¤§ãããªã‚Šã¾ã™ (`-log(ç¢ºç‡)`)ã€‚\n"
      ],
      "metadata": {
        "id": "VmR3oxz7pBDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#@title æå¤±é–¢æ•°ã‚’é¸æŠã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ { run: \"auto\" }\n",
        "loss_function_name = \"ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼\" #@param [\"ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢\", \"ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\", \"ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼\"]\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 1. å„æå¤±é–¢æ•°ã®å®šç¾© (ä¿®æ­£ç‰ˆ)\n",
        "# --------------------------------------------------\n",
        "\n",
        "def manhattan_loss(y_true_one_hot, y_pred_proba):\n",
        "    \"\"\"\n",
        "    ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢ (L1æå¤±) ã‚’è¨ˆç®—ã€‚\n",
        "    y_true_one_hot ã¯æ—¢ã«one-hotè¡¨ç¾ã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®šã€‚\n",
        "    \"\"\"\n",
        "    # y_true_one_hot ã¯æ—¢ã«æ­£ã—ã„å½¢ãªã®ã§ã€ãã®ã¾ã¾è¨ˆç®—ã«ä½¿ã†\n",
        "    loss = np.sum(np.abs(y_pred_proba - y_true_one_hot)) / len(y_true_one_hot)\n",
        "    return loss\n",
        "\n",
        "def euclidean_loss(y_true_one_hot, y_pred_proba):\n",
        "    \"\"\"\n",
        "    ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã®2ä¹— (MSE) ã‚’è¨ˆç®—ã€‚\n",
        "    y_true_one_hot ã¯æ—¢ã«one-hotè¡¨ç¾ã§ã‚ã‚‹ã“ã¨ã‚’æƒ³å®šã€‚\n",
        "    \"\"\"\n",
        "    # y_true_one_hot ã¯æ—¢ã«æ­£ã—ã„å½¢ãªã®ã§ã€ãã®ã¾ã¾è¨ˆç®—ã«ä½¿ã†\n",
        "    loss = np.sum((y_pred_proba - y_true_one_hot)**2) / len(y_true_one_hot)\n",
        "    return loss\n",
        "\n",
        "def cross_entropy_loss(y_true_one_hot, y_pred_proba):\n",
        "    \"\"\"\n",
        "    ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤± (log_loss) ã‚’è¨ˆç®—ã€‚\n",
        "    scikit-learnã®log_lossã¯ã‚¯ãƒ©ã‚¹ç•ªå·ã‚’è¦æ±‚ã™ã‚‹ãŸã‚ã€one-hotã‚’å…ƒã«æˆ»ã™ã€‚\n",
        "    \"\"\"\n",
        "    # one-hotè¡¨ç¾ (ä¾‹: [0, 1, 0]) ã‹ã‚‰ã‚¯ãƒ©ã‚¹ç•ªå· (ä¾‹: 1) ã«å¤‰æ›\n",
        "    y_true_labels = np.argmax(y_true_one_hot, axis=1)\n",
        "    return log_loss(y_true_labels, y_pred_proba)\n",
        "\n",
        "# --------------------------------------------------\n",
        "# 2. ã€Œé–¢æ•°ãƒã‚¤ãƒ³ã‚¿ã€ã®å½¹å‰²ã‚’æœãŸã™è¾æ›¸ã‚’ä½œæˆ\n",
        "# --------------------------------------------------\n",
        "loss_functions = {\n",
        "    \"ãƒãƒ³ãƒãƒƒã‚¿ãƒ³è·é›¢\": manhattan_loss,\n",
        "    \"ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢\": euclidean_loss,\n",
        "    \"ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼\": cross_entropy_loss,\n",
        "}\n",
        "\n",
        "# ãƒ—ãƒ«ãƒ€ã‚¦ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã§é¸æŠã•ã‚ŒãŸåå‰ã‹ã‚‰ã€ä½¿ç”¨ã™ã‚‹é–¢æ•°ã‚’å–å¾—\n",
        "selected_loss_func = loss_functions[loss_function_name]"
      ],
      "metadata": {
        "id": "g113PQV-oKnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
        "\n",
        "ã¾ãšãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
        "\n",
        "éš ã‚Œå±¤ï¼ˆä¸­é–“å±¤ï¼‰ã®æ•°ã‚„ãƒãƒ¼ãƒ‰æ•°ã‚’èª¿ç¯€ã—ã¦ãã ã•ã„ã€‚<br>\n",
        "è¤‡é›‘ã«ã™ã‚Œã°ã™ã‚‹ã»ã©é›£ã—ã„å•é¡ŒãŒè§£ã‘ã‚‹ã‚ˆã†ã«ãªã‚‹åé¢ã€æ•™å¸«ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„å ´åˆã«éå­¦ç¿’ãŒèµ·ãã‚„ã™ããªã£ãŸã‚Šã€è¨ˆç®—æ™‚é–“ãŒå¢—ãˆãŸã‚Šã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "MKuaKXf1LOdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_layer_sizes = [5, ]  # éš ã‚Œå±¤ã®ãƒãƒ¼ãƒ‰æ•°ã€‚è¤‡æ•°ã®å±¤ã«ã—ãŸã„å ´åˆã¯ [3,4] ã‚„ [3,5,4] ãªã©\n",
        "batch_size = 32            # ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒŸãƒ‹ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰ã€‚ï¼‘å›ã®å­¦ç¿’ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®æ•°\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "\n",
        "def draw_mlp_network(input_nodes, hidden_layers, output_nodes):\n",
        "    \"\"\"\n",
        "    MLPã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æç”»ã™ã‚‹é–¢æ•°\n",
        "\n",
        "    Parameters:\n",
        "    - input_nodes: å…¥åŠ›å±¤ã®ãƒãƒ¼ãƒ‰æ•°\n",
        "    - hidden_layers: éš ã‚Œå±¤ã®ãƒãƒ¼ãƒ‰æ•°ã®ãƒªã‚¹ãƒˆ\n",
        "    - output_nodes: å‡ºåŠ›å±¤ã®ãƒãƒ¼ãƒ‰æ•°\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "\n",
        "    # ãƒãƒ¼ãƒ‰ã®è¿½åŠ \n",
        "    layers = [input_nodes] + hidden_layers + [output_nodes]\n",
        "    layer_pos = []\n",
        "    max_nodes = max(layers)\n",
        "\n",
        "    for i, layer in enumerate(layers):\n",
        "        # ä¸­å¤®æƒãˆã«ã™ã‚‹ãŸã‚ã®ã‚ªãƒ•ã‚»ãƒƒãƒˆè¨ˆç®—\n",
        "        offset = (max_nodes - layer) / 2\n",
        "        current_layer = []\n",
        "        for j in range(layer):\n",
        "            if i == 0:\n",
        "                node_id = f'in_{j}'\n",
        "            elif i == len(layers) - 1:\n",
        "                node_id = f'out_{j}'\n",
        "            else:\n",
        "                node_id = f'hidden{i-1}_{j}'\n",
        "            G.add_node(node_id, pos=(i, max_nodes - (j + offset)))\n",
        "            current_layer.append(node_id)\n",
        "        layer_pos.append(current_layer)\n",
        "\n",
        "    # ã‚¨ãƒƒã‚¸ã®è¿½åŠ \n",
        "    for i in range(len(layers) - 1):\n",
        "        for node_start in layer_pos[i]:\n",
        "            for node_end in layer_pos[i + 1]:\n",
        "                G.add_edge(node_start, node_end)\n",
        "\n",
        "    # ãƒãƒ¼ãƒ‰ã®ä½ç½®ã‚’å–å¾—\n",
        "    pos = nx.get_node_attributes(G, 'pos')\n",
        "\n",
        "    # ã‚°ãƒ©ãƒ•ã®æç”»\n",
        "    plt.figure(figsize=(8, 6))  # æ¨ªå¹…ã‚’800pxã«è¨­å®šã™ã‚‹ãŸã‚ã®èª¿æ•´\n",
        "    nx.draw(G, pos, with_labels=True, node_size=1500, node_color=\"lightblue\", font_size=8)\n",
        "    plt.title('MLP Network Structure')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰\n",
        "mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, max_iter=1, warm_start=True, random_state=random_state, batch_size=batch_size)\n",
        "\n",
        "# æ§‹é€ ã®æç”»\n",
        "draw_mlp_network(input_nodes=X_train_transformed.shape[1], hidden_layers=hidden_layer_sizes, output_nodes=len(target_names))"
      ],
      "metadata": {
        "id": "ZjqbyRKfwDsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©ã§ããŸã‚‰å­¦ç¿’ã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚\n",
        "æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã‚’èª¿ç¯€ã—ã¦ãã ã•ã„ã€‚\n",
        "\n",
        "**ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã‚’æ›¸ãæ›ãˆãŸå ´åˆã€ä¸Šã®ã‚»ãƒ«ã‚’å¿…ãšå®Ÿè¡Œã—ã¦ã€åæ˜ ã•ã›ã¦ã‹ã‚‰å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚**"
      ],
      "metadata": {
        "id": "NSZ7Q5HvxnbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_epochs = 1000           # æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°\n",
        "\n",
        "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# tqdmã‚’ä½¿ã£ã¦é€²è¡ŒçŠ¶æ³ãƒãƒ¼ã‚’è¡¨ç¤º\n",
        "with tqdm(total=max_epochs, leave=False) as pbar:\n",
        "    for epoch in range(max_epochs):\n",
        "        mlp.fit(X_train_transformed, y_train)\n",
        "\n",
        "        # æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã¨è©•ä¾¡\n",
        "        y_train_pred = mlp.predict(X_train_transformed)\n",
        "        y_train_pred_proba = mlp.predict_proba(X_train_transformed)\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        train_loss = selected_loss_func(y_train, y_train_pred_proba)\n",
        "\n",
        "        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬ã¨è©•ä¾¡\n",
        "        y_val_pred = mlp.predict(X_val_transformed)\n",
        "        y_val_pred_proba = mlp.predict_proba(X_val_transformed)\n",
        "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "        val_loss = selected_loss_func(y_val, y_val_pred_proba)\n",
        "\n",
        "        # è¨˜éŒ²\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        # tqdmã®èª¬æ˜æ–‡ã‚’æ›´æ–°\n",
        "        pbar.set_description(f\"Epoch {epoch + 1}/{max_epochs} - Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}, Train acc: {train_accuracy:.4f}, Val acc: {val_accuracy:.4f}\")\n",
        "        pbar.update(1)\n",
        "\n",
        "# æœ€å¾Œã®ã‚¨ãƒãƒƒã‚¯ã®çµæœã‚’è¡¨ç¤º\n",
        "print(f\"Epoch {max_epochs}/{max_epochs} - Train accuracy: {train_accuracy:.4f}, Train loss: {train_loss:.4f}, Val accuracy: {val_accuracy:.4f}, Val loss: {val_loss:.4f}\")\n",
        "\n",
        "# ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®é–“å¼•ã\n",
        "def reduce_points(data, num_points):\n",
        "    if len(data) > num_points:\n",
        "        indices = np.linspace(0, len(data) - 1, num_points, dtype=int)\n",
        "        return [data[i] for i in indices]\n",
        "    return data\n",
        "\n",
        "# ã‚°ãƒ©ãƒ•ã§å­¦ç¿’ã®æ§˜å­ã‚’è¡¨ç¤º\n",
        "\n",
        "num_points = 100\n",
        "epochs = range(1, max_epochs + 1)\n",
        "epochs_reduced = reduce_points(list(epochs), num_points)\n",
        "train_accuracies_reduced = reduce_points(train_accuracies, num_points)\n",
        "val_accuracies_reduced = reduce_points(val_accuracies, num_points)\n",
        "train_losses_reduced = reduce_points(train_losses, num_points)\n",
        "val_losses_reduced = reduce_points(val_losses, num_points)\n",
        "\n",
        "# ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_reduced, train_accuracies_reduced, label='Train Accuracy')\n",
        "plt.plot(epochs_reduced, val_accuracies_reduced, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.legend()\n",
        "plt.title('Accuracy per Epoch')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_reduced, train_losses_reduced, label='Train Loss')\n",
        "plt.plot(epochs_reduced, val_losses_reduced, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim(0, max(max(train_losses_reduced), max(val_losses_reduced)))\n",
        "plt.legend()\n",
        "plt.title('Loss per Epoch')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "siueLWKXLXsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼“**\n",
        "\n",
        "- å­¦ç¿’ã§ã¯ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã®å€¤ã‚’å°ã•ãã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ï¼\n",
        " - ã‚ã‚‹å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸä»®ã®å‡ºåŠ›ï¼ˆå„ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ï¼¿ï¼¿ï¼¿ï¼¿ï¼‰ã¨ï¼Œæ­£è§£ã® ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ è¡¨ç¾ã‚’æ¯”è¼ƒã—ã¦ï¼Œãã®å€¤ãŒå°‘ã—ã ã‘å°ã•ããªã‚‹ã‚ˆã†ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ›´æ–°ã—ã¾ã™ï¼ã“ã®æ¯”è¼ƒã«ç”¨ã„ã‚‹é–¢æ•°ã¯ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿é–¢æ•°ã¨ã‚ˆã°ã‚Œã¾ã™ï¼\n",
        "\n",
        "- å·¦ã®ã‚°ãƒ©ãƒ•ã¯ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼Œå³ã®ã‚°ãƒ©ãƒ•ã¯ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ã§ã™ï¼\n",
        " - å­¦ç¿’ã§å°ã•ãã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã®ã¯å³ã§ã™ã‹ï¼Œå·¦ã§ã™ã‹ï¼Ÿ\n",
        "\n",
        "- ä»Šå›ã¯æœ€å¤§ã‚¨ãƒãƒƒã‚¯æ•°ã‚’æŒ‡å®šã—ã¦å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã—ã¾ã—ãŸãŒã€ã‚¨ãƒãƒƒã‚¯æ•°ã‚ˆã‚Šã‚‚ãšã£ã¨å¤šãã®å›æ•°ã®å­¦ç¿’ãŒè¡Œã‚ã‚Œã¾ã™ã€‚\n",
        "\n",
        " - å­¦ç¿’ã‚’ç¹°ã‚Šè¿”ã™ã®ã¡ã€ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã‚’ã²ã¨ã¨ãŠã‚Šä½¿ã„åˆ‡ã‚‹ã“ã¨ã‚’ 1 ã‚¨ãƒãƒƒã‚¯ã¨æ•°ãˆã‚‹ã€‚\n",
        "\n",
        " - ãƒ‡ãƒ¼ã‚¿é‡ãŒå¤šã™ãã¦ä¸€åº¦ã«ä½¿ã„åˆ‡ã‚Œãªã„ã®ã§ã€å°‘æ•°ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–ã‚Šå‡ºã—ã¦ã¯å­¦ç¿’ã‚’è¡Œã†ã€‚å–ã‚Šå‡ºã™å˜ä½ã‚’ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã¨å‘¼ã¶ã€‚ã“ã‚Œã‚’ç•¥ã—ã¦ãƒãƒƒãƒã¨ã„ã„ã€ï¼‘å€‹ã«å«ã¾ã‚Œã‚‹å€‹æ•°ã‚’ãƒ—ãƒ­ã‚°ãƒ©ãƒ ä¸­ã§ã¯ `batch_size`ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰ã¨ã—ã¦ã„ã‚‹ã€‚ä»Šå›ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã§ã‚ã‚‹ã€‚\n",
        "\n",
        " - å­¦ç¿’ã®ãŸã³ã€ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿é–¢æ•°ã‚’ç”¨ã„ã¦ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã¨ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã‚’æ¯”è¼ƒã—ã€ãã®é–¢æ•°ãŒå°ã•ããªã‚‹ã‚ˆã†ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä¿®æ­£ã™ã‚‹ã€‚ãã®ä¿®æ­£ã®å‡¦ç†ã‚’ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã¨ã„ã†[ï¼ˆå‚è€ƒï¼‰](https://hogetech.info/ml/dl/backpropagation)ã€‚\n"
      ],
      "metadata": {
        "id": "SktsNjzTxogs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã‚„æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§è©¦ã™"
      ],
      "metadata": {
        "id": "lf1lMnjgWKaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬\n",
        "y_train_pred = mlp.predict(X_train_transformed)\n",
        "y_train_pred_proba = mlp.predict_proba(X_train_transformed)\n",
        "\n",
        "# æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "train_loss = selected_loss_func(y_train, y_train_pred_proba)\n",
        "\n",
        "print(f\"æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: {train_accuracy:.3f}\")\n",
        "print(f\"æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã®æå¤±: {train_loss:.3f}\")\n",
        "\n",
        "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬\n",
        "y_val_pred = mlp.predict(X_val_transformed)\n",
        "y_val_pred_proba = mlp.predict_proba(X_val_transformed)\n",
        "\n",
        "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "val_loss = selected_loss_func(y_val, y_val_pred_proba)\n",
        "\n",
        "print(f\"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: {val_accuracy:.3f}\")\n",
        "print(f\"æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®æå¤±: {val_loss:.3f}\")"
      ],
      "metadata": {
        "id": "j0wzWMm8OgwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’ï¼‘å€‹å…¥åŠ›ã—ã¦è©¦ã™\n",
        "\n",
        "ä½œæˆã•ã‚ŒãŸãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒã©ã®ã‚ˆã†ã«å‹•ä½œã™ã‚‹ã®ã‹ã€æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‚’ï¼‘å€‹ç”¨ã„ã¦ç¢ºèªã—ã¦ã¿ã¾ã™ã€‚\n",
        "\n",
        "- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¸ã®å…¥åŠ›ï¼ˆç‰¹å¾´é‡ï¼‰**\n",
        "\n",
        "    æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å®šã®ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸ã³ã€ãã®ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚ã“ã‚Œã¯ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆãƒ¢ãƒ‡ãƒ«ï¼‰ã«å…¥åŠ›ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã§ã€å„ç‰¹å¾´é‡ãŒæ•°å€¤ã¨ã—ã¦è¡¨ç¾ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
        "\n",
        "- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ï¼ˆç¢ºç‡ï¼‰**\n",
        "\n",
        "    é¸æŠã—ãŸå…¥åŠ›ã«å¯¾ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãŒå„ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ç¢ºç‡ã‚’è¨ˆç®—ã—ã¾ã™ã€‚ã“ã®ç¢ºç‡ã¯ã€å…¥åŠ›ãŒãã‚Œãã‚Œã®ã‚¯ãƒ©ã‚¹ã«åˆ†é¡ã•ã‚Œã‚‹å¯èƒ½æ€§ã‚’ç¤ºã—ã¦ãŠã‚Šã€å„ã‚¯ãƒ©ã‚¹ã«å¯¾ã—ã¦1ã¤ã®ç¢ºç‡å€¤ãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚\n",
        "\n",
        "- **æ¨å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ç•ªå·ã® one-hot è¡¨ç¾**\n",
        "\n",
        "    ãƒ¢ãƒ‡ãƒ«ãŒäºˆæ¸¬ã—ãŸã‚¯ãƒ©ã‚¹ã®one-hotè¡¨ç¾ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚one-hotè¡¨ç¾ã¨ã¯ã€æ­£è§£ã‚¯ãƒ©ã‚¹ã‚’1ã€ãã‚Œä»¥å¤–ã®ã‚¯ãƒ©ã‚¹ã‚’0ã¨ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«å½¢å¼ã®ã“ã¨ã§ã™ã€‚ä¾‹ãˆã°4ã‚¯ãƒ©ã‚¹ã®å ´åˆã€[0, 0, 1, 0]ã¯ã‚¯ãƒ©ã‚¹ 2 ã‚’ç¤ºã—ã¾ã™ï¼ˆæ³¨ï¼šã‚¯ãƒ©ã‚¹ç•ªå·ã¯ 0 ã‹ã‚‰å§‹ã¾ã‚Šã¾ã™ï¼‰ã€‚\n",
        "\n",
        "- **ã‚¯ãƒ©ã‚¹æ¨å®šã®è¡¨ç¤ºï¼ˆæ•´æ•°è¡¨ç¾ï¼‰**\n",
        "\n",
        "    one-hotè¡¨ç¾ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ•´æ•°ã«å¤‰æ›ã—ã€äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã‚’æ•°å€¤ã¨ã—ã¦ç¤ºã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "28kqsh6QWpxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã€å„ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡ã‚’å‡ºåŠ›\n",
        "sample_index = 1  # ä»»æ„ã®ã‚µãƒ³ãƒ—ãƒ«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n",
        "sample_input = X_val_transformed[sample_index].reshape(1, -1)  # 1ã‚µãƒ³ãƒ—ãƒ«ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿\n",
        "print(\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã¸ã®å…¥åŠ›ï¼ˆç‰¹å¾´é‡ï¼‰ã€€ã€€ ï¼š\", sample_input)\n",
        "\n",
        "# ç¢ºç‡ã®å‡ºåŠ›\n",
        "class_probabilities = mlp.predict_proba(sample_input)\n",
        "print(\"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å‡ºåŠ›ï¼ˆç¢ºç‡ï¼‰ã€€ã€€ ã€€ã€€ï¼š\", class_probabilities)\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹æ¨å®š\n",
        "predicted_class = mlp.predict(sample_input)\n",
        "print(\"æ¨å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ç•ªå·ã® one-hot è¡¨ç¾ï¼š\", predicted_class)\n",
        "print(\"æ¨å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ç•ªå·ã€€ã€€ã€€ã€€ã€€ã€€ã€€ ï¼š\", np.argmax(predicted_class))\n",
        "\n",
        "# ã‚¯ãƒ©ã‚¹æ¨å®š\n",
        "predicted_class = mlp.predict(sample_input)\n",
        "print(\"æ­£è§£ã® one-hot è¡¨ç¾ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ï¼š\", y_train[sample_index])\n",
        "print(\"æ­£è§£ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ã€€ ï¼š\", np.argmax(y_train[sample_index]))"
      ],
      "metadata": {
        "id": "wo3wEk2AWeSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼”**\n",
        "\n",
        "- å‡ºåŠ›ã‚’èª­ã¿å–ã‚ŠãªãŒã‚‰åŸ‹ã‚ã¦ãã ã•ã„ï¼š\n",
        "\n",
        "  ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã® ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã«å…¥åŠ›ã—ãŸã¨ã“ã‚ï¼Œï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ãŒå‡ºåŠ›ã•ã‚ŒãŸï¼\n",
        "\n",
        "  å‡ºåŠ›ã¯ï¼Œãã®ã‚µãƒ³ãƒ—ãƒ«ãŒå„ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ç¢ºç‡ã‚’è¡¨ã™ã‚‚ã®ã§ã‚ã‚‹ï¼ãã®ä¸­ã§ã¯ ï¼¿ï¼¿ï¼¿ï¼¿ ç•ªç›®ã®ã‚¯ãƒ©ã‚¹ãŒæœ€å¤§ã¨ãªã£ãŸã“ã¨ã‹ã‚‰ï¼Œæ¨å®šã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ã¯ ï¼¿ï¼¿ï¼¿ï¼¿ ã¨ãªã£ãŸï¼"
      ],
      "metadata": {
        "id": "Vj9yir4s0OzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡\n",
        "\n",
        "ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦è©•ä¾¡ã¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚<br>\n",
        "å­¦ç¿’ä¸­ã«ç²¾åº¦ã‚’ç¢ºèªã™ã‚‹ã®ã«ç”¨ã„ãŸæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ã¯ç•°ãªã‚Šã€å­¦ç¿’ä¸­ã«ã¯ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ã¾ã£ãŸãä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
      ],
      "metadata": {
        "id": "TTAZIzrKLeAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çµæœã‚’è¡¨ç¤º\n",
        "all_test_samples = []\n",
        "\n",
        "for i in range(len(X_test_transformed)):\n",
        "    test_sample = X_test_transformed[i].reshape(1, -1)\n",
        "    probabilities = mlp.predict_proba(test_sample)[0]\n",
        "    predicted_class_index = np.argmax(probabilities)\n",
        "    predicted_class_name = target_names[predicted_class_index]\n",
        "    true_class_index = np.argmax(y_test[i])\n",
        "    true_class_name = target_names[true_class_index]\n",
        "\n",
        "    test_sample_df = pd.DataFrame(test_sample, columns=clms)\n",
        "    test_sample_df[\"æ­£è§£\"] = f\"ã‚¯ãƒ©ã‚¹{true_class_index}-{true_class_name}\"\n",
        "    test_sample_df[\"æ¨è«–\"] = f\"ã‚¯ãƒ©ã‚¹{predicted_class_index}-{predicted_class_name}\"\n",
        "\n",
        "    # å„ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡ã‚’è¿½åŠ \n",
        "    for class_index, prob in enumerate(probabilities):\n",
        "        test_sample_df[f\"ã‚¯ãƒ©ã‚¹{class_index}ã®ç¢ºç‡\"] = round(prob, 3)\n",
        "\n",
        "    # ã‚«ãƒ©ãƒ ã®é †ç•ªã‚’èª¿æ•´\n",
        "    probability_columns = [f\"ã‚¯ãƒ©ã‚¹{class_index}ã®ç¢ºç‡\" for class_index in range(len(probabilities))]\n",
        "    test_sample_df = test_sample_df[\n",
        "        [\"æ­£è§£\", \"æ¨è«–\"] + probability_columns + clms.tolist()\n",
        "    ]\n",
        "\n",
        "    all_test_samples.append(test_sample_df)\n",
        "\n",
        "all_test_samples_df = pd.concat(all_test_samples, ignore_index=True)\n",
        "\n",
        "print(\"å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çµæœ:\")\n",
        "display(all_test_samples_df)\n"
      ],
      "metadata": {
        "id": "K0QedxwAc94z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ã•ã‚‰ã«ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ç²¾åº¦ï¼ˆæ­£è§£ç‡ï¼‰ãŠã‚ˆã³æå¤±ã‚’è¨ˆç®—ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
      ],
      "metadata": {
        "id": "sXANa8uudS9d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬\n",
        "y_test_pred = mlp.predict(X_test_transformed)\n",
        "y_test_pred_proba = mlp.predict_proba(X_test_transformed)\n",
        "\n",
        "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "test_loss = selected_loss_func(y_test, y_test_pred_proba)\n",
        "\n",
        "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦: {test_accuracy:.4f}\")\n",
        "print(f\"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æå¤±: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "DNlCHrSHLdjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼•**\n",
        "- ã€Œå…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çµæœã€ã®è¡¨ã‚’èª­ã¿å–ã£ã¦ãã ã•ã„\n",
        " - ãŸã¨ãˆã°æœ€åˆã®è¡Œã®ã‚µãƒ³ãƒ—ãƒ«ã¯ã€ï¼ˆå„ã‚¯ãƒ©ã‚¹ã®ç¢ºç‡ã‚’å†™ã—ã¦ãã ã•ã„ï¼‰ã¨å‡ºåŠ›ã•ã‚ŒãŸã€‚æœ€å¤§ã®ç¢ºç‡ã‚’ã‚‚ã¤ã‚¯ãƒ©ã‚¹ãŒ ï¼¿ï¼¿ï¼¿ ã§ã‚ã£ãŸãŸã‚ã€ã€Œæ¨è«–ã€ã®çµæœã‚‚ ï¼¿ï¼¿ï¼¿ ã¨ãªã‚Šã€ï¼ˆæ­£è§£ã«ä¸€è‡´ã—ã¦ã„ãŸï¼æ­£è§£ã¨ç•°ãªã£ã¦ã„ãŸï¼‰ã€‚"
      ],
      "metadata": {
        "id": "dgW3fwgUQXF-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2æ¬¡å…ƒãƒ—ãƒ­ãƒƒãƒˆã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã®å¯è¦–åŒ–\n",
        "\n",
        "2å€‹ï¼ˆ2æ¬¡å…ƒï¼‰ã®ç‰¹å¾´é‡ã®ã¿ã§å­¦ç¿’ã‚’è¡Œã£ãŸå ´åˆã€å¾—ã‚‰ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®åˆ†é¡é ˜åŸŸã‚’2æ¬¡å…ƒã§è¦–è¦šåŒ–ã§ãã¾ã™ã€‚<br>\n",
        "ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã€ãã®ç‚¹ã«å¯¾ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚"
      ],
      "metadata": {
        "id": "BGvykzFKLlO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒã«ã‚ˆã‚‹é ˜åŸŸãƒ—ãƒ­ãƒƒãƒˆ\n",
        "def plot_decision_boundary(clf, X, y, feature_indices, feature_names, title=\"\"):\n",
        "    # ã‚°ãƒªãƒƒãƒ‰ã‚’ç”Ÿæˆ\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
        "                         np.arange(y_min, y_max, 0.02))\n",
        "\n",
        "    # ã‚°ãƒªãƒƒãƒ‰å…¨ä½“ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = np.argmax(Z, axis=1)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # ãƒ—ãƒ­ãƒƒãƒˆã®æç”»\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "    palette = plt.cm.get_cmap('tab10', len(np.unique(np.argmax(y, axis=1))))\n",
        "    for target in np.unique(np.argmax(y, axis=1)):\n",
        "        subset = X[np.argmax(y, axis=1) == target]\n",
        "        plt.scatter(subset[:, feature_indices[0]], subset[:, feature_indices[1]], label=f\"Class {target}: {target_names[target]}\", color=palette(target))\n",
        "    plt.xlabel(f\"Feature {feature_indices[0]}: {feature_names[0]}\")\n",
        "    plt.ylabel(f\"Feature {feature_indices[1]}: {feature_names[1]}\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ç‰¹å¾´é‡ã®çµ„ã¿åˆã‚ã›ã‚’é¸ã‚“ã§ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "if use_two_features == True:\n",
        "  plot_decision_boundary(mlp, X_test_transformed, y_test, feature_indices, feature_names, title=f\"Decision Boundary for {dataset_name} Dataset\")\n",
        "else:\n",
        "  print(\"3æ¬¡å…ƒä»¥ä¸Šã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“\")"
      ],
      "metadata": {
        "id": "y-aXjWVILkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼–**\n",
        "\n",
        "- ã‚¯ãƒ©ã‚¹ã‚’åˆ†ã‘ã‚‹å¢ƒç•Œã®ã“ã¨ã‚’ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã¨ã„ã†ï¼\n",
        " - ã“ã‚Œã‚’é©åˆ‡ãªä½ç½®ã«æ±ºã‚ã‚‹ã“ã¨ãŒå­¦ç¿’ã§ã‚ã‚‹ã¨ã‚‚ã„ãˆã‚‹ï¼\n",
        " - å„ã‚¯ãƒ©ã‚¹ãŒæ¦‚ã­è‰¯å¥½ã«åˆ†é›¢ã§ãã¦ã„ã‚Œã°å­¦ç¿’ã¯æˆåŠŸ\n",
        " - ã‚ã¾ã‚Šã«ã‚‚ç´°ã‹ãã‚¯ãƒã‚¯ãƒã¨åˆ†é›¢ã—ã¦ã„ã‚‹çŠ¶æ³ã¯ ï¼¿ï¼¿ï¼¿ï¼¿ï¼¿ ã¨ã•ã‚Œã‚‹ï¼æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã§ã¯é«˜ã„ç²¾åº¦ã‚’å¾—ã‚‰ã‚Œã‚‹ãŒï¼Œãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯ã‚€ã—ã‚ç²¾åº¦ãŒä¸‹ãŒã£ã¦ã—ã¾ã†ï¼å­¦ç¿’ã®ã—ã™ãã‚’é˜²ããŸã‚ã«ï¼Œï¼¿ï¼¿ï¼¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿ç¯€ã—ãŸã‚Šï¼Œã¡ã‚‡ã†ã©ã‚ˆã„ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§ã§å­¦ç¿’ã‚’åœæ­¢ã—ãŸã‚Šã™ã‚‹å·¥å¤«ãŒè¡Œã‚ã‚Œã‚‹ï¼"
      ],
      "metadata": {
        "id": "u0JmbxqH2LzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **èª²é¡Œï¼—**\n",
        "\n",
        "å­¦ã‚“ã ã“ã¨ã‚’ã‚‚ã¨ã«ï¼Œã”è‡ªèº«ã®è¨€è‘‰ã§ã¾ã¨ã‚ã¦ãã ã•ã„ï¼\n",
        "\n",
        "- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å…¥åŠ›ã¨å‡ºåŠ›\n",
        "- åˆ†é¡å•é¡Œã«ãŠã‘ã‚‹å­¦ç¿’ã¨ã¯ã€ä½•ã‚’ç”¨ã„ã¦ä½•ã‚’ã™ã‚‹ã‚‚ã®ï¼Ÿ\n",
        " - ã‚¯ãƒ©ã‚¹ãƒ»ã‚µãƒ³ãƒ—ãƒ«ãƒ»ç‰¹å¾´é‡ãƒ»æ±ºå®šå¢ƒç•Œãƒ»æå¤±ãƒ»one-hot ã¨ã„ã£ãŸè¨€è‘‰ã‚’ç”¨ã„ã¦ãã ã•ã„\n",
        "- å­¦ç¿’ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ã©ã†ã‚„ã£ã¦ä½¿ã†ã¨ï¼Œæ–°ãŸãªã‚µãƒ³ãƒ—ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚’æ¨å®šã§ãã‚‹ï¼Ÿ\n"
      ],
      "metadata": {
        "id": "pc6diR8k3rz4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## ç™ºå±•\n",
        "\n",
        "ä»Šå›ï¼Œï¼‘ã‚µãƒ³ãƒ—ãƒ«ã®ç‰¹å¾´é‡ã¯ï¼Œå¤šãã¦ã‚‚ 30 æ¬¡å…ƒã§ã—ãŸï¼\n",
        "\n",
        "ã—ã‹ã—ï¼ŒãŸã¨ãˆã°ç”»åƒã‚’åˆ¤åˆ¥ã™ã‚‹ãªã‚‰ï¼Œã¨ã¦ã‚‚å°ã•ãªç”»åƒã§ã‚‚ ç¸¦ 32 Ã— æ¨ª 32 Ã— RGB 3ãƒãƒ£ãƒ³ãƒãƒ« ï¼ 3072 æ¬¡å…ƒãã‚‰ã„ã¯ã‚ã‚Šã¾ã™ï¼ã“ã®å ´åˆï¼Œç”»åƒã‚’ç‰¹å¾´é‡ã«å¤‰æ›ï¼ˆ**ç‰¹å¾´æŠ½å‡º**ï¼‰ã—ãŸä¸Šã§ï¼Œåˆ¤åˆ¥ã«ä½¿ã†ã“ã¨ã«ãªã‚Šã¾ã™ï¼\n",
        "\n",
        "ã“ã®ç‰¹å¾´æŠ½å‡ºã‚’ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å†…éƒ¨ã§è¡Œã£ã¦ãã‚Œã‚‹ã‚‚ã®ã¨ã—ã¦æœ‰åãªã®ãŒ **ç•³ã¿è¾¼ã¿å±¤**ï¼ˆConvolutional Layerï¼‰ã§ã™ï¼ã¾ãŸï¼Œãã‚Œã‚’å«ã‚€ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãŒç•³ã¿è¾¼ã¿ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆConvolutional Neural Network; **CNN**ï¼‰ã§ã™ï¼\n",
        "\n",
        "- å¤šæ¬¡å…ƒé…åˆ—ã®æ‰±ã„ã«ã¤ã„ã¦ã¯ [NumPy ã®æ¼”ç¿’](https://github.com/shizoda/education/blob/main/machine_learning/numpy.ipynb)\n",
        "\n",
        "- ãƒ‡ã‚¸ã‚¿ãƒ«ç”»åƒã®è¡¨ç¾ã«ã¤ã„ã¦ã¯ [ç”»åƒè¡¨ç¾ã®æ¼”ç¿’](https://github.com/shizoda/education/blob/main/image/colors.ipynb)\n",
        "\n",
        "- ç•³ã¿è¾¼ã¿ã‚„ãƒ•ã‚£ãƒ«ã‚¿å‡¦ç†ã«ã¤ã„ã¦ã¯ [ç•³ã¿è¾¼ã¿ã®æ¼”ç¿’](https://github.com/shizoda/education/blob/main/image/conv.ipynb)\n",
        "\n",
        "ã“ã‚Œã‚‰ã‚’ã”å­˜çŸ¥ã®æ–¹ã¯ã“ã®ã¾ã¾\n",
        "\n",
        "- [CNN ã‚’ç”¨ã„ãŸç”»åƒåˆ†é¡ã®æ¼”ç¿’](https://github.com/shizoda/education/blob/main/machine_learning/cnn/cifar10_pytorch.ipynb)\n",
        "\n",
        "ã«é€²ã‚“ã§ãã ã•ã„ï¼"
      ],
      "metadata": {
        "id": "u9SgYRGm-yZ5"
      }
    }
  ]
}