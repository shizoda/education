{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVqugcsfGnCHZcpxxNCuf7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 最適化器（オプティマイザ）\n",
        "\n",
        "**最適化器（オプティマイザ）** とは、学習率を調節したり、どのような方向にネットワーク内の重みを修正するかを自動的に調節するアルゴリズムのことです。モデルの性能を最大限に引き出すためには、適切なオプティマイザを選択し、その動作をうまく調整することが重要です。\n",
        "\n",
        "機械学習において **初期学習率 (learning rate)** を適切に設定することは、学習プロセスの効率を決める重要な要素です。学習率が大きすぎると、損失関数の最小値に到達する前に値が発散したり、過学習を引き起こすことがあります。一方で、学習率が小さすぎると、モデルが収束するのに長い時間がかかります。\n",
        "\n",
        "また、学習が進むにつれて、学習率を動的に調節する必要があります。学習の初期段階では、モデルがまだ正しい方向性を見つけられていないため、大きな学習率を設定して、大まかな方向を素早く探ります。しかし、学習が進んで損失関数が安定してくる段階では、学習率を小さくして慎重に調整することが重要です。このようにすることで、最適解に近づく際に余計な振動や遠ざかりを防ぐことができます。このような調節をスケジューリングといい、最初は大きめの値として、後半では徐々に小さくすることが多いです。\n"
      ],
      "metadata": {
        "id": "7C3n7lHYPzbI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### そもそも最小化とは\n",
        "\n",
        "機械学習の目的は、モデルが誤差（損失関数）を最小限に抑えることです。損失関数とは、モデルがどれだけ正しい予測をしているかを数値で示したものです。例えば、予測と実際の値が大きく離れているほど損失関数の値は大きくなり、逆に一致しているほど小さくなります。\n",
        "\n",
        "この損失関数を最小化するためには、数学的には関数の最小値を求める「最適化問題」を解く必要があります。ここで着目すべきなのが **勾配（関数の傾き）**です。\n",
        "\n",
        "### 最小化の手順\n",
        "\n",
        "基本的な **勾配降下法 (Gradient Descent)** という方法で、関数が最小となるパラメータを探してみましょう。\n",
        "\n",
        "- 勾配の計算\n",
        "\n",
        "損失関数を入力パラメータについて微分して、**現時点からどの方向に進めば関数の値が減るか** を調べます。\n",
        "\n",
        "- パラメータの更新\n",
        "\n",
        "勾配が示す方向とは逆の方向に少しだけ進むことで、損失を少しずつ減らします。この際、更新の幅を決めるのが **学習率（learning rate） ** です。\n",
        "\n",
        "- 繰り返し\n",
        "\n",
        "この操作を何度も繰り返して、損失が最小になるパラメータを探します。今回はステップごと  ``decay_rate`` 0.9 倍で学習率を減らしていくことにします。"
      ],
      "metadata": {
        "id": "BZ2DfRNnQ2Bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import trange\n",
        "\n",
        "# 初期値と学習率\n",
        "x = 0  # 初期点\n",
        "initial_learning_rate = 0.01\n",
        "decay_rate = 0.9  # 減衰率\n",
        "\n",
        "# 最大ステップ数\n",
        "steps = 20\n",
        "\n",
        "# 損失関数とその勾配を定義\n",
        "def loss_function(x):\n",
        "    return x**4 - 3*x**3 - 7*x**2 + 5*x  # 損失関数\n",
        "\n",
        "def gradient(x):\n",
        "    return 4*x**3 - 9*x**2 - 8*x + 5  # 損失関数の微分\n",
        "\n",
        "# 記録用リスト\n",
        "path = [x]\n",
        "learning_rates = []  # 学習率の変化を記録\n",
        "\n",
        "# 最適化\n",
        "for step in trange(steps):\n",
        "    current_learning_rate = initial_learning_rate * (decay_rate ** step)  # 学習率の減少\n",
        "    learning_rates.append(current_learning_rate)\n",
        "    grad = gradient(x)  # 勾配の計算\n",
        "    x -= current_learning_rate * grad  # パラメータの更新\n",
        "    path.append(x)\n",
        "\n",
        "# 可視化\n",
        "x_vals = np.linspace(-3, 5, 500)\n",
        "y_vals = loss_function(x_vals)\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# 損失関数と最適化経路\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(x_vals, y_vals, label=\"Loss Function\", color=\"blue\")\n",
        "plt.scatter(path, [loss_function(x) for x in path], color=\"red\", label=\"SGD Steps\")\n",
        "plt.title(\"Gradient Descent with Learning Rate Decay\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.axhline(0, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
        "plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=0.5)\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "\n",
        "# 学習率の変化\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(steps), learning_rates, label=\"Learning Rate\", marker=\"o\", color=\"red\")\n",
        "plt.title(\"Learning Rate Decay\")\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BaNME8idQIM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 演習１\n",
        "\n",
        "初期値や学習率を調節して、大域解に到達するようにしてください。\n",
        "\n",
        "また、なるべく高速に（少ない回数で）到達できるようにしてください。初期値が適切でも、あまりにも学習率を上げすぎるとうまくいかないことも確認してください。\n",
        "\n",
        "----"
      ],
      "metadata": {
        "id": "PkxQ-UjtbKJk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **確率的勾配降下法（SGD）**\n",
        "\n",
        "上記の勾配降下法 (GD) には以下の課題があります：\n",
        "- データ全体（全データセット）を使って勾配を計算するため、計算コストが高い。\n",
        "- 学習率の調整が難しく、適切な収束が保証されない場合がある。\n",
        "\n",
        "これらの問題を解決するために登場したのが **確率的勾配降下法（SGD）** です。SGDは勾配降下法を改良した手法で、以下の特徴があります：\n",
        "\n",
        "1. **ミニバッチの使用**:  \n",
        "   全データセットの代わりに、ランダムに選ばれたデータの小さな部分集合（ミニバッチ）を使って勾配を計算します。\n",
        "2. **計算コストの削減**:  \n",
        "   一部のデータだけを使うため、1回の更新の計算が効率的です。\n",
        "3. **不確実性（ノイズ）の活用**:  \n",
        "   各更新にランダム性が含まれるため、**局所解（local minimum）**から脱出しやすいです。\n",
        "\n",
        "| 手法                | 使用するデータ              | 更新回数            | 特徴                              |\n",
        "|---------------------|---------------------------|---------------------|-----------------------------------|\n",
        "| 勾配降下法（GD）    | 全データ                  | 1エポック1回更新    | 安定だが計算コストが高い           |\n",
        "| 確率的勾配降下法（SGD） | ミニバッチ                | データ数 ÷ バッチサイズ回 | ノイズを含むが計算が効率的         |\n",
        "| SGD + 学習率減衰     | ミニバッチ                | 同上                | 初期は探索、後半は安定した収束     |\n",
        "| SGD + Momentum       | ミニバッチ                | 同上                | 更新がスムーズで振動が抑えられる   |\n",
        "\n",
        "\n",
        "\n",
        "### **SGDの更新式**\n",
        "GDの更新式は次のように表されます：\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\nabla L(\\theta_t)\n",
        "$$\n",
        "\n",
        "一方、SGDでは、損失関数 $L(\\theta_t)$ を全データではなくミニバッチ $B$ で近似するため、次のように更新します：\n",
        "\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t - \\eta \\nabla L_B(\\theta_t)\n",
        "$$\n",
        "\n",
        "ここで：\n",
        "- $B$: ミニバッチのデータ\n",
        "- $L_B(\\theta_t)$: ミニバッチで計算された損失関数\n",
        "\n",
        "\n",
        "### **学習率減衰（Learning Rate Decay）**\n",
        "学習率減衰は、SGDにも適用可能であり、以下の理由で重要です：\n",
        "\n",
        "1. **学習初期の探索性**: 初期段階では大きなステップサイズで広範囲を探索します。\n",
        "2. **収束時の安定性**: 最適化が進むにつれてステップサイズを小さくすることで、最終的な解への収束を安定させます。\n",
        "\n",
        "学習率減衰は、たとえば指数関数的減衰（Exponential Decay）で以下のように書けます：\n",
        "$$\n",
        "\\eta_t = \\eta_0 r^t\n",
        "$$\n",
        "\n",
        "ここで：\n",
        "- $\\eta_t$: ステップ $t$ における学習率\n",
        "- $\\eta_0$: 初期学習率\n",
        "- $r$: 減衰率（例えば 0.9）\n",
        "\n",
        "### **SGDとMomentumの組み合わせ**\n",
        "SGD単独では、不安定な振動が起こる場合があります。これを改善するために、**Momentum** を加えることが一般的です。Momentumは、過去の更新方向の情報を利用して、更新をスムーズにする手法です。\n",
        "\n",
        "#### **Momentumの更新式**\n",
        "$$\n",
        "v_t = \\beta v_{t-1} - \\eta \\nabla L_B(\\theta_t)\n",
        "$$\n",
        "$$\n",
        "\\theta_{t+1} = \\theta_t + v_t\n",
        "$$\n",
        "\n",
        "ここで：\n",
        "- $v_t$: 過去の更新量の累積\n",
        "- $\\beta$: Momentum係数（通常は 0.9 など）\n",
        "- $\\eta$: 学習率\n",
        "- $\\nabla L_B(\\theta_t)$: ミニバッチ $B$ における損失関数の勾配\n",
        "\n"
      ],
      "metadata": {
        "id": "oRCMtSKEGJeG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 演習２\n",
        "\n",
        "SGD を用いて iris の分類問題を実行し、どのようなスピードで学習率が低下していくのか確認してみましょう。"
      ],
      "metadata": {
        "id": "-1R_EWvEXTKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from logging import critical\n",
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "\n",
        "# Iris データセットの読み込み\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Virginica とそれ以外の2クラスに限定\n",
        "y = (y == 2).astype(int)  # Virginica: 1, それ以外: 0\n",
        "\n",
        "# 特徴量を2次元に限定（Sepal Length, Sepal Width）\n",
        "X = X[:, :2]\n",
        "\n",
        "# データの標準化\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# データをトレーニングセットとテストセットに分割\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# サンプル点の可視化\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c=\"green\", marker=\"o\", label=\"Train - Not Versicolor\")\n",
        "plt.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c=\"blue\", marker=\"o\", label=\"Train - Versicolor\")\n",
        "plt.scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1], c=\"green\", marker=\"x\", label=\"Test - Not Versicolor\")\n",
        "plt.scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1], c=\"blue\", marker=\"x\", label=\"Test - Versicolor\")\n",
        "plt.title(\"Train/Test Split Visualization (Versicolor vs Others)\")\n",
        "plt.xlabel(\"Feature 1 (Standardized)\")\n",
        "plt.ylabel(\"Feature 2 (Standardized)\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kYq9M_NPTsHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習率減衰を適用する最適化関数\n",
        "def sgd_with_exp_decay(momentum=1.0):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=momentum)\n",
        "    scheduler = ExponentialLR(optimizer, gamma=0.9)  # 学習率を指数関数的に減少\n",
        "    return optimizer, scheduler\n",
        "\n",
        "# オプティマイザのリスト\n",
        "optimizers = {\n",
        "    \"SGD\": lambda: optim.SGD(model.parameters(), lr=0.1),\n",
        "    \"SGD_with_decay\":  lambda: sgd_with_exp_decay(momentum=1.0),\n",
        "    # \"SGD_with_decay_and_momentum\": lambda:\n",
        "    # 他にも 「\"名前\": lambda: 呼び出し文」 という書き方で追加してください\n",
        "}\n",
        "\n",
        "\n",
        "# シンプルなMLPモデル\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 3),  # 特徴量数: 2, 出力: 3（3クラス分類）\n",
        "    nn.Softmax(dim=1)  # 出力を確率分布に変換\n",
        ")\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()  # クロスエントロピー損失を定義"
      ],
      "metadata": {
        "id": "QoqzFyDbV04u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# トレーニング関数\n",
        "def train(optimizer_name):\n",
        "    if type(optimizers[optimizer_name]()) in [tuple, list]:\n",
        "        optimizer, scheduler = optimizers[optimizer_name]()\n",
        "    else:\n",
        "        optimizer = optimizers[optimizer_name]()\n",
        "        scheduler = None\n",
        "\n",
        "    losses = []  # ロスを記録するリスト\n",
        "    lrs = []     # 学習率を記録するリスト\n",
        "\n",
        "    for epoch in range(300):\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_train_tensor)\n",
        "        loss = criterion(y_pred, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()  # 学習率を更新\n",
        "\n",
        "        # 各エポックでのロスと学習率を記録\n",
        "        losses.append(loss.item())\n",
        "        lrs.append(optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    return losses, lrs  # ロスと学習率のリストを返す\n",
        "\n",
        "\n",
        "# トレーニングと可視化\n",
        "for optimizer_name in optimizers.keys():\n",
        "    model.apply(lambda m: m.reset_parameters() if hasattr(m, \"reset_parameters\") else None)  # 重み初期化\n",
        "    losses, lrs = train(optimizer_name)  # 修正後の train 関数\n",
        "\n",
        "    # 横並びのグラフ作成\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    # 学習曲線と学習率の変化を左側にプロット\n",
        "    ax1 = axes[0]\n",
        "    ax2 = ax1.twinx()\n",
        "    ax1.plot(losses, label=\"Loss\", color=\"blue\")\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    ax1.set_ylabel(\"Loss\", color=\"blue\")\n",
        "    ax1.tick_params(axis='y', labelcolor=\"blue\")\n",
        "    ax2.plot(lrs, label=\"Learning Rate\", color=\"red\")\n",
        "    ax2.set_ylabel(\"Learning Rate\", color=\"red\")\n",
        "    ax2.tick_params(axis='y', labelcolor=\"red\")\n",
        "    ax1.set_title(f\"Loss and Learning Rate ({optimizer_name})\")\n",
        "\n",
        "    # 決定境界を右側にプロット\n",
        "    ax3 = axes[1]\n",
        "    xx, yy = np.meshgrid(np.linspace(-3, 3, 100), np.linspace(-3, 3, 100))\n",
        "    grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
        "\n",
        "    # Get the class with the maximum probability for each grid point\n",
        "    preds = model(grid).detach().numpy()\n",
        "    # predicted_classes = np.argmax(preds, axis=1)\n",
        "    predicted_classes = preds[:, 1]\n",
        "\n",
        "    # Reshape the predictions to match the grid shape\n",
        "    predicted_classes = predicted_classes.reshape(xx.shape)\n",
        "\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    ax3.contourf(xx, yy, predicted_classes, levels=50, cmap=\"RdBu\", alpha=0.3)\n",
        "    ax3.scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1], c=\"red\", marker=\"o\", label=\"Not Virginica\")\n",
        "    ax3.scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1], c=\"blue\", marker=\"s\", label=\"Virginica\")\n",
        "    ax3.set_title(f\"Decision Boundary ({optimizer_name})\")\n",
        "    ax3.legend()\n",
        "\n",
        "    ax3.legend()\n",
        "\n",
        "    # レイアウト調整して表示\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "02EvQsaXVOmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 演習３\n",
        "\n",
        "SGD 以外にも、いくつか有名なオプティマイザがあります。optimizers に追加して実行し、SGD との速度や結果の違いを見てみましょう。\n",
        "\n",
        "| オプティマイザ名   | 特徴                                                                 | PyTorchの関数名                |\n",
        "|--------------------|----------------------------------------------------------------------|--------------------------------|\n",
        "| SGD               | 確率的勾配降下法。シンプルで計算コストが低いが、収束が遅いことがある。  | `torch.optim.SGD`             |\n",
        "| SGD + Momentum          | SGD の改良版。前回の更新方向を加味して振動を抑え、安定した収束を実現。 | `torch.optim.SGD`（`momentum` オプションを使用） |\n",
        "| AdaGrad           | パラメータごとに学習率を調整。学習率が小さくなりすぎることが課題。      | `torch.optim.Adagrad`         |\n",
        "| RMSprop           | AdaGrad の学習率低下問題を解決。適応的な学習率を維持し、安定した学習。  | `torch.optim.RMSprop`         |\n",
        "| Adam              | Momentum と RMSprop を組み合わせたもの。高速収束と安定性が特徴。       | `torch.optim.Adam`            |\n"
      ],
      "metadata": {
        "id": "3LvfIcodaQMR"
      }
    }
  ]
}