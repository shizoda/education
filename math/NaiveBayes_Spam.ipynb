{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shizoda/education/blob/main/machine_learning/basics/spam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R073MaEbHubX"
      },
      "source": [
        "# ベイズの定理を使ったスパムフィルタリング\n",
        "\n",
        "ここではベイズの定理を用いて、届いたメールがスパムか否かを判定する AI をつくってみましょう。AI という語はあまり技術的な語ではありませんが、最新の AI もこのような考え方に基づいていますので、ここでは敢えて AI という語を使っています。\n",
        "\n",
        "### 🤔 「ベイズの定理」とは\n",
        "\n",
        "ベイズの定理は、一言でいうと**「自分の『思い込み』を、新しいデータ（事実）で更新していく方法」**です。\n",
        "\n",
        "例えば、あなたが「Aさんは時間にルーズだ」という思い込み（最初の確率）を持っていたとします。でも、最近Aさんが5回連続で約束の時間ぴったりに来た、という新しいデータを観測したらどうでしょう？\n",
        "\n",
        "「あれ、もしかしてAさんは実は真面目なのかも…？」と、思い込みが更新されますね。この「思い込みの更新」を、数学的にきっちり計算できるようにしたのがベイズの定理です。\n",
        "\n",
        "$$ P(H∣D)=P(D)P(D∣H)⋅P(H) $$ ​\n",
        "\n",
        "この式は、まさにその考え方を表しています。\n",
        "\n",
        "- 事前確率 $ P(H)$ ：最初の思い込み（Aさんはルーズだ！）\n",
        "- 尤度 $ P(D∣H) $：もし思い込みが正しかったら、このデータ（5回連続で時間通り）が起こる確からしさ\n",
        "- 事後確率 $ P(H∣D) $：データを踏まえた後の、更新された思い込み（やっぱりAさんは真面目かも！）\n",
        "\n",
        "### 🤖機械学習への応用\n",
        "\n",
        "そして、この「データで思い込みを更新する」仕組みをコンピューターにやらせるのが、機械学習のひとつの考え方です。今回のテーマである「ナイーブベイズ」によるスパムフィルターも、まさにこの仕組みを使っています。\n",
        "\n",
        "- 最初の思い込み：「『当選』『無料』みたいな単語が入ってるメールは、たぶんスパムだろうな〜」\n",
        "- データで学習：たくさんのスパムメールと普通のメール（教師データ）を AI に読み込ませる。\n",
        "- 思い込みの更新：AIはデータから、「『当選』という単語は、普通のメールよりスパムメールに XX 倍多く出現するな」といったことを学習します。\n",
        "\n",
        "こうして、新しいメールが届くたびに、AI は学習済みの知識を使って「このメールはスパムらしいか、らしくないか」を判断できるのです。それでは、実際にPythonのコードを見ながら、このスパムフィルターがどう作られるのか体験していきましょう。\n",
        "\n",
        "### ナイーブベイズ\n",
        "\n",
        "今回使う「ナイーブベイズ」という手法の「ナイーブ（Naive）」には、「単純な、うぶな」といった意味があります。\n",
        "\n",
        "メールに含まれる単語たちの関係性を**「あえて単純に（ナイーブに）考える」**ということが意味です。本当は「当選」と「賞金」のように、一緒に出てきやすい単語の組み合わせはあります。でも、その複雑な関係を全部計算しようとすると、ものすごく大変です。そこでナイーブベイズは、「それぞれの単語は、他の単語とは関係なく独立して登場する」と割り切って、シンプルに計算します。\n",
        "\n",
        "### スパムフィルタにおけるベイズの定理の適用\n",
        "スパムフィルタリングにおいて、次のように解釈します：\n",
        "- 仮説 $ H $：メールがスパムであること\n",
        "- データ $ D $：メールに特定の単語が含まれていること\n",
        "\n",
        "これを用いて、メールがスパムである確率 $ P(\\text{spam}|\\text{email}) $ を計算します。\n",
        "\n",
        "## ステップ1: 教師データを用意 📧\n",
        "\n",
        "まずは、AIにとっての「教師」となるデータ（教師データ）を準備します。何が「スパム」で、何が「スパムじゃない（ハム）」なのかを教えるための、お手本メール集です。メールの文面（データ）と、それがスパムかハムか（正解）のペアが多数あります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpYWBWWwGtkQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# サンプルデータセットの作成\n",
        "data = {\n",
        "    'email': [\n",
        "        'Win a million dollars now',   # スパム\n",
        "        'Lowest prices in pharmacy',    # スパム\n",
        "        'Hello, how are you?',          # 非スパム\n",
        "        'Meeting tomorrow at 10am',     # 非スパム\n",
        "        'Congratulations, you won a prize', # スパム\n",
        "        'Get cheap meds online',        # スパム\n",
        "        'Can we reschedule our appointment?', # 非スパム\n",
        "        'Your account has been hacked'  # スパム\n",
        "    ],\n",
        "    'label': ['spam', 'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、8通の短いメールと、それぞれが「spam」か「ham」かという正解ラベルを用意しました。これをもとに学習を進めていきます。\n",
        "\n",
        "#### 📝課題 1\n",
        "\n",
        "あなたが普段受け取るメールやメッセージで、「これはスパムっぽいな」と感じるものに含まれがちな単語を 3 個あげてください。日本語でも英語でも構いません。"
      ],
      "metadata": {
        "id": "VyVeW_REW5oQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "（回答欄）"
      ],
      "metadata": {
        "id": "ufRLm5knW97t"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQqcrRZkH5hn"
      },
      "source": [
        "## ステップ2: データの前処理\n",
        "\n",
        "次に、メールのテキストを前処理し、単語の出現回数をカウントします。\n",
        "\n",
        "各行は１通のメールに相当します。横軸の大半（label列を除く）は単語で、存在回数を表します。label列は、そのメールがスパムか非スパムかを表します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAYwXmBNGuUj"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# CountVectorizerインスタンスを作成\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "# メールテキストをフィットし、変換する\n",
        "X = vectorizer.fit_transform(df['email'])\n",
        "\n",
        "# 特徴量（単語）の名前を取得 (修正点)\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "# 単語の出現回数をデータフレームに変換\n",
        "word_count_df = pd.DataFrame(X.toarray(), columns=feature_names)\n",
        "\n",
        "# データフレームにラベル列を追加\n",
        "word_count_df['label'] = df['label']\n",
        "\n",
        "# 結果のデータフレームを表示\n",
        "word_count_df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "実行すると、巨大な表ができますね。各行が1通のメール、各列がメールに出てきた全単語を表しています。そして、数字はそのメールでその単語が何回使われたか、という回数です。\n",
        "\n",
        "これで、コンピューターが計算できる形のデータが整いました！\n",
        "\n",
        "### 📝 課題\n",
        "\n",
        "もし、新しく「congratulations you won」というメールが来て、それがスパムだったとしたら、上の表はどのようになるでしょうか？"
      ],
      "metadata": {
        "id": "Xdw9FP0UYVVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "（回答欄）"
      ],
      "metadata": {
        "id": "0yNnMtkyYk_K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cQi2-__H9-D"
      },
      "source": [
        "## ステップ3: 🎩 いよいよベイズの定理でスパム確率を計算\n",
        "\n",
        "さあ、いよいよベイズの定理を使って、スパムかどうかを判定する仕組みを作っていきます。\n",
        "\n",
        "まずは、ステップ2で作った単語の数カウンターを使って、「スパムメール」と「ハムメール」それぞれで、各単語がどれくらいの頻度で現れるかを計算します。\n",
        "\n",
        "これが、新しいメールを判定するための**「証拠」**になります。例えば、「win」や「prize」という単語は、スパムメールによく出てきそうですよね。逆に「meeting」や「reschedule」は、ハムメールで使われそうです。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oy9Eh7SWG1BC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# スパムと非スパムの頻度を計算\n",
        "spam_emails = word_count_df[word_count_df['label'] == 'spam']\n",
        "ham_emails = word_count_df[word_count_df['label'] == 'ham']\n",
        "\n",
        "# 各単語のスパムおよび非スパムの確率を計算\n",
        "spam_word_probs = (spam_emails.drop('label', axis=1).sum() + 1) / (spam_emails.drop('label', axis=1).sum().sum() + len(feature_names))\n",
        "ham_word_probs = (ham_emails.drop('label', axis=1).sum() + 1) / (ham_emails.drop('label', axis=1).sum().sum() + len(feature_names))\n",
        "\n",
        "# 例示用。スパムらしい単語とスパムらしくない単語を挙げています\n",
        "selected_words = ['win', 'prize', 'pharmacy', 'meeting', 'reschedule']\n",
        "for word in selected_words:\n",
        "    spam_count = spam_emails[word].sum()\n",
        "    ham_count = ham_emails[word].sum()\n",
        "    spam_prob = spam_word_probs[word]\n",
        "    ham_prob = ham_word_probs[word]\n",
        "\n",
        "    print(f\"Word: '{word}'\")\n",
        "    print(f\"  Spam count: {spam_count}, Ham count: {ham_count}\")\n",
        "    print(f\"  P(word|spam): {spam_prob:.4f}, P(word|ham): {ham_prob:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(\\textrm{word}|\\textrm{spam})$ は、「そのメールがスパムだと分かっている場合に、その単語が含まれている確率」です。winはスパムメールでの確率が高い（スパムっぽい証拠）、meetingはハムメールでの確率が高い（ハムっぽい証拠）ことが分かりますね。"
      ],
      "metadata": {
        "id": "XBxRAOwZXTmn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv9pblIeNPA-"
      },
      "source": [
        "#### 事前確率の計算\n",
        "\n",
        "事前確率 $P(\\text{spam})$ と $P(\\text{ham})$ は、スパムメールおよび非スパムメールの全体に対する割合です。\n",
        "\n",
        "$$ P(\\text{spam}) = \\frac{\\text{スパムメールの数}}{\\text{全メールの数}} $$\n",
        "$$ P(\\text{ham}) = \\frac{\\text{ハムメールの数}}{\\text{全メールの数}} $$\n",
        "\n",
        "📝 課題\n",
        "\n",
        "上記の式を Python コードとして記述し、スパムとハムの事前確率をそれぞれ計算してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPLk5gJFNMYL"
      },
      "outputs": [],
      "source": [
        "n_spam  = len(spam_emails)    # スパムメールの数\n",
        "n_ham   = len(ham_emails)      # 非スパムメールの数\n",
        "n_total = len(word_count_df) # 全メールの数\n",
        "\n",
        "P_spam =                 # ←スパムの事前確率の計算\n",
        "P_ham  =                 # ←　ハムの事前確率の計算\n",
        "print(\"スパムの事前確率　\", P_spam)\n",
        "print(\"非スパムの事前確率\", P_ham)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZP9XUMFrID0M"
      },
      "source": [
        "### 推論：新しいメールを判定してみよう\n",
        "\n",
        "それでは、学習した結果を使って、新しいメールを判定する関数を作ります。\n",
        "\n",
        "この関数の中では、ベイズの定理を使って、以下の計算をしています。\n",
        "\n",
        "- __事前確率__（最初の思い込み）を設定\n",
        "\n",
        " - log_P_spam: そもそもスパムメールは全体のどれくらいの割合か？\n",
        " - log_P_ham: そもそもハムメールは全体のどれくらいの割合か？\n",
        "\n",
        "- __尤度（証拠）__を掛け合わせる:\n",
        "\n",
        "新しいメールに含まれる単語を一つずつチェックします。\n",
        "\n",
        "その単語の「スパムっぽさ（P(word|spam)）」と「ハムっぽさ（P(word|ham)）」を、1.の確率にどんどん掛け合わせていきます。（※実際には、計算を簡単にするために対数を使って足し算します）\n",
        "\n",
        "- __事後確率__ を比較:\n",
        "最終的に計算された「総合的なスパムっぽさ」と「総合的なハムっぽさ」を比較します。\n",
        "スパムっぽさのスコアが高ければ「スパム」、ハムっぽさのスコアが高ければ「非スパム（ハム）」と判定します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数式での説明（難しいと感じる方はスキップしてください）\n",
        "\n",
        "#### 事前確率の対数の初期化\n",
        "\n",
        "初期値として事前確率の対数を設定します。対数を取ることで計算の安定性を保ちます。\n",
        "\n",
        "$$ \\log P(\\text{spam})$$\n",
        "$$ \\log P(\\text{ham}) $$\n",
        "\n",
        "#### 尤度の累積計算\n",
        "\n",
        "メール内の各単語について、スパムメールおよび非スパムメールにその単語が含まれる確率（尤度）を累積して計算します。\n",
        "\n",
        "各単語 $w_i$ について、尤度 $P(w_i|\\text{spam})$ および $P(w_i|\\text{ham})$ を累積します。\n",
        "\n",
        "$$ \\log P(\\text{email}|\\text{spam}) = \\sum_{i} \\log P(w_i|\\text{spam}) $$\n",
        "$$ \\log P(\\text{email}|\\text{ham}) = \\sum_{i} \\log P(w_i|\\text{ham}) $$\n",
        "\n",
        "##### 対数を取る理由\n",
        "\n",
        "対数を取ることで、確率の掛け算を足し算に変えることができます。確率の積は非常に小さくなることが多いため、一般的に行われます。\n",
        "\n",
        "$$ P(w_1|\\text{spam}) \\cdot P(w_2|\\text{spam}) \\cdot \\ldots \\cdot P(w_n|\\text{spam}) $$\n",
        "は、\n",
        "$$ \\log P(w_1|\\text{spam}) + \\log P(w_2|\\text{spam}) + \\ldots + \\log P(w_n|\\text{spam}) $$\n",
        "に変換されます。\n",
        "\n",
        "#### 事後確率の比較\n",
        "\n",
        "累積した確率の対数を比較し、スパム確率が非スパム確率より高ければ「spam」、そうでなければ「ham」を返します。\n",
        "\n",
        "$$ P(\\text{spam}|\\text{email}) > P(\\text{ham}|\\text{email}) \\Rightarrow \\text{spam} $$\n",
        "$$ P(\\text{spam}|\\text{email}) \\leq P(\\text{ham}|\\text{email}) \\Rightarrow \\text{ham} $$\n",
        "\n",
        "この関数では、ベイズの定理に基づいて新しいメールがスパムである確率を計算し、スパムか非スパムかを予測します。"
      ],
      "metadata": {
        "id": "JqrYFum5X7Oe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TARuIbW_G4WF"
      },
      "outputs": [],
      "source": [
        "# 新しいメールのスパム確率を計算する関数\n",
        "def predict_spam(email):\n",
        "\n",
        "    # 事前確率の計算\n",
        "    P_spam = len(spam_emails) / len(word_count_df)\n",
        "    P_ham  = len(ham_emails) / len(word_count_df)\n",
        "\n",
        "    # 対数をとる\n",
        "    # 対数の底はネイピア数 e (約 2.7) です\n",
        "    log_P_spam = np.log(P_spam)\n",
        "    log_P_ham  = np.log(P_ham)\n",
        "\n",
        "    print(\"　スパムの事前確率\", f\"{np.exp(log_P_spam):.8f}\", f\"（対数 {log_P_spam:.4f}）\")\n",
        "    print(\"非スパムの事前確率\", f\"{np.exp(log_P_ham):.8f}\", f\"（対数 {log_P_ham:.4f}）\")\n",
        "    print(\"...\")\n",
        "\n",
        "    # ベイズの定理に従って更新する\n",
        "    words = email.split()\n",
        "    for word in words:\n",
        "        if word in spam_word_probs:\n",
        "            log_P_spam += np.log(spam_word_probs[word])\n",
        "            print(f\"   単語 {word} -->    スパムの確率更新 ：対数尤度 {np.log(spam_word_probs[word]):.4f} を加算\")\n",
        "        if word in ham_word_probs:\n",
        "            log_P_ham += np.log(ham_word_probs[word])\n",
        "            print(f\"   単語 {word} -->  非スパムの確率更新 ：対数尤度 {np.log(ham_word_probs[word]):.4f} を加算\")\n",
        "\n",
        "    print(f\"　このメールがスパムである事後確率 {np.exp(log_P_spam):.8f}\", f\"（対数 {log_P_spam:.4f}）\")\n",
        "    print(f\"このメールが非スパムである事後確率 {np.exp(log_P_ham):.8f}\", f\"（対数 {log_P_ham:.4f}）\")\n",
        "\n",
        "    if log_P_spam > log_P_ham:\n",
        "      return 'スパム'\n",
        "    else:\n",
        "      return '非スパム'\n",
        "\n",
        "# テスト用のメール\n",
        "test_email = 'Can we win a meeting?'\n",
        "print(f'→メール \"{test_email}\" は {predict_spam(test_email)} と判別されました')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "このコードは、Win a free prize now という新しいメールを判定しています。「win」や「prize」といった、スパムっぽい証拠がたくさん含まれているため、見事に「スパム」と判定されました。\n",
        "\n",
        "### 📝 課題\n",
        "\n",
        "`Can we win a meeting?` という少し奇妙なメールが届いたとします。\n",
        "\n",
        "このメールには、「スパムっぽい単語」と「ハムっぽい単語」が混ざっています。すると、`we` と `win` の 2 単語がそれぞれ確率を更新するはずです。"
      ],
      "metadata": {
        "id": "MFaonPwkY-Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "（質問及び回答欄）\n",
        "\n",
        "- `we` は、「スパムらしさ」と「ハムらしさ」のどちらをより強く上げましたか？\n",
        "- `win` は、「スパムらしさ」と「ハムらしさ」のどちらをより強く上げましたか？\n",
        "- 最終的な事後確率は、スパムとハムのどちらが大きいですか？"
      ],
      "metadata": {
        "id": "5P4dlnHQ8N1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ✍️ 総括課題\n",
        "\n",
        "今回は、ベイズの定理という考え方を使って、AIが迷惑メールを見分ける仕組みを体験しました。教師データから確率を学習し、新しいデータに対して予測を行う、という機械学習の基本的な流れのイメージが重要です。\n",
        "\n",
        "そこで 「教師あり学習」「教師データ」「ベイズの定理」「ナイーブベイズ」の3つの言葉をすべて使って、今回のスパムフィルターの仕組みを 2～4 行くらいで説明してください。"
      ],
      "metadata": {
        "id": "TsRcHNL7cT4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "（回答欄）"
      ],
      "metadata": {
        "id": "7hSrGpBcctgf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}